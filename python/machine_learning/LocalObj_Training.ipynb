{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double check the Path for storing trajectories is correct\n"
     ]
    }
   ],
   "source": [
    "#Import Packages\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from multicontact_learning_local_objectives.python.machine_learning.ml_utils import *\n",
    "import matplotlib.pyplot as plt #Matplotlib\n",
    "import shutil\n",
    "\n",
    "print(\"Double check the Path for storing trajectories is correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Check we provide the Correct Traj Path: \n",
      " /home/jiayu/Desktop/MLP_DataSet/Rubbles/\n"
     ]
    }
   ],
   "source": [
    "#Define Path for Storing Trajectories\n",
    "#Collect Data Points Path\n",
    "#workingDirectory = \"/home/jiayu/Desktop/multicontact_learning_local_objectives/data/large_slope_flat_patches/\"\n",
    "#workingDirectory = \"/home/jiayu/Desktop/MLP_DataSet/Rubbles\"\n",
    "#workingDirectory = \"/home/jiayu/Desktop/MLP_DataSet/Rubbles_Standarized_Data/\"\n",
    "workingDirectory = \"/home/jiayu/Desktop/MLP_DataSet/Rubbles/\"\n",
    "#NOTE: need to have \"/\" at the end\n",
    "print(\"Double Check we provide the Correct Traj Path: \\n\", workingDirectory)\n",
    "\n",
    "#Define dataset folder\n",
    "#DataSetPath = workingDirectory + \"/DataSet_Standarization\"\n",
    "#DataSetPath = workingDirectory + \"/DataSet_OriginalForm\"\n",
    "TrainingSetPath = workingDirectory + \"/DataSet/\"+\"TrainingSet_OriginalForm\"\n",
    "ValidationSetPath = workingDirectory + \"/DataSet/\"+\"ValidationSet_OriginalForm\"\n",
    "TestSetPath = workingDirectory + \"/DataSet/\"+\"TestSet_OriginalForm\"\n",
    "\n",
    "#Path to store ML Model, create one if we dont have\n",
    "ML_Model_Path = workingDirectory + \"/ML_Models/\"\n",
    "if not (os.path.isdir(ML_Model_Path)):\n",
    "    os.mkdir(ML_Model_Path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning Code\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set Up for Training Set\n",
      "World Frame Shift:  StanceFoot\n",
      "Contact Location Representation Type:  FollowRectangelBorder\n",
      "Scaling Factor of Variables:  1.0\n",
      "Number of Preview Steps:  4\n",
      "Pre Process Mode:  OriginalForm\n",
      " \n",
      "Set Up for Validation Set\n",
      "World Frame Shift:  StanceFoot\n",
      "Contact Location Representation Type:  FollowRectangelBorder\n",
      "Scaling Factor of Variables:  1.0\n",
      "Number of Preview Steps:  4\n",
      "Pre Process Mode:  OriginalForm\n",
      " \n",
      "Set Up for Test Set\n",
      "World Frame Shift:  StanceFoot\n",
      "Contact Location Representation Type:  FollowRectangelBorder\n",
      "Scaling Factor of Variables:  1.0\n",
      "Number of Preview Steps:  4\n",
      "Pre Process Mode:  OriginalForm\n"
     ]
    }
   ],
   "source": [
    "#Load DataSet File\n",
    "\n",
    "#dataset_file = DataSetPath + \"/data_rubbles\"+'.p'\n",
    "trainingset_file = TrainingSetPath + \"/data\"+'.p'\n",
    "trainingset = pickle.load(open(trainingset_file,\"rb\"))\n",
    "\n",
    "validationset_file = ValidationSetPath + \"/data\"+'.p'\n",
    "validationset = pickle.load(open(validationset_file,\"rb\"))\n",
    "\n",
    "testset_file = TestSetPath + \"/data\"+'.p'\n",
    "testset = pickle.load(open(testset_file,\"rb\"))\n",
    "\n",
    "print(\"Set Up for Training Set\")\n",
    "print(\"World Frame Shift: \", trainingset[\"Shift_World_Frame_Type\"])\n",
    "print(\"Contact Location Representation Type: \",trainingset[\"Contact_Representation_Type\"])\n",
    "print(\"Scaling Factor of Variables: \",trainingset[\"VectorScaleFactor\"])\n",
    "print(\"Number of Preview Steps: \", trainingset[\"NumPreviewSteps\"])\n",
    "print(\"Pre Process Mode: \",trainingset[\"PreProcessMode\"])\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print(\"Set Up for Validation Set\")\n",
    "print(\"World Frame Shift: \", validationset[\"Shift_World_Frame_Type\"])\n",
    "print(\"Contact Location Representation Type: \",validationset[\"Contact_Representation_Type\"])\n",
    "print(\"Scaling Factor of Variables: \",validationset[\"VectorScaleFactor\"])\n",
    "print(\"Number of Preview Steps: \", validationset[\"NumPreviewSteps\"])\n",
    "print(\"Pre Process Mode: \",validationset[\"PreProcessMode\"])\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print(\"Set Up for Test Set\")\n",
    "print(\"World Frame Shift: \", testset[\"Shift_World_Frame_Type\"])\n",
    "print(\"Contact Location Representation Type: \",testset[\"Contact_Representation_Type\"])\n",
    "print(\"Scaling Factor of Variables: \",testset[\"VectorScaleFactor\"])\n",
    "print(\"Number of Preview Steps: \", testset[\"NumPreviewSteps\"])\n",
    "print(\"Pre Process Mode: \",testset[\"PreProcessMode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim:  85\n",
      "output dim: 11\n",
      " \n",
      "Num of Data Points:  121200\n"
     ]
    }
   ],
   "source": [
    "#Test Train Split, for now No Test data\n",
    "#x_train, x_test, y_train, y_test = train_test_split(dataset[\"input\"], dataset[\"output\"], test_size = 0.01)\n",
    "x_train = trainingset[\"input\"]\n",
    "y_train = trainingset[\"output\"]\n",
    "\n",
    "x_valid = validationset[\"input\"]\n",
    "y_valid = validationset[\"output\"]\n",
    "\n",
    "x_test = testset[\"input\"]\n",
    "y_test = testset[\"output\"]\n",
    "\n",
    "#Get Left Foot to see\n",
    "#x_train=x_train[::2]\n",
    "#y_train=y_train[::2]\n",
    "\n",
    "\n",
    "#Decide input and outpu dimensionality\n",
    "d_in = x_train[0].shape[0]\n",
    "print(\"input dim: \", d_in)\n",
    "d_out = y_train[0].shape[0]\n",
    "print(\"output dim:\", d_out)\n",
    "print(\" \")\n",
    "\n",
    "print(\"Num of Data Points: \", x_train.shape[0])\n",
    "\n",
    "# #Double check with mean and std\n",
    "# print(\"Inputs: \")\n",
    "# print(\"Input Mean: \", x_train.mean(axis=0))\n",
    "# print(\"Input Std: \", x_train.std(axis=0))\n",
    "# print(\"Input Max: \", x_train.max(axis=0))\n",
    "# print(\"Input Min: \", x_train.min(axis=0))\n",
    "# print(\" \")\n",
    "\n",
    "\n",
    "# print(\"Output Mean: \", y_train.mean(axis=0))\n",
    "# print(\"Output Std: \", y_train.std(axis=0))\n",
    "# print(\"Output Max: \", y_train.max(axis=0))\n",
    "# print(\"Output Min: \", y_train.min(axis=0))\n",
    "\n",
    "# print(\"X shape: \", x_train.shape)\n",
    "# print(\"y shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define learning model\n",
    "# model = Sequential([\n",
    "#     Dense(256, activation='relu', input_shape=(d_in,)),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dense(d_out)\n",
    "# ])\n",
    "# loss: 4.6886e-04 - val_loss: 5.4786e-04\n",
    "\n",
    "# #True code\n",
    "# model = Sequential([\n",
    "#     Dense(256, activation='relu', input_shape=(d_in,)), #tanh\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dense(d_out, activation='linear')\n",
    "# ])\n",
    "\n",
    "#True code\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(d_in,)), #tanh\n",
    "    Dense(256, activation='relu', ),\n",
    "    Dense(256, activation='relu', ),\n",
    "    Dense(256, activation='relu', ),\n",
    "    Dense(d_out, activation='linear')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 0.0066 - val_loss: 5.1753e-04\n",
      "Epoch 2/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.3657e-04 - val_loss: 3.7070e-04\n",
      "Epoch 3/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 3.3677e-04 - val_loss: 3.0811e-04\n",
      "Epoch 4/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 2.9257e-04 - val_loss: 2.7600e-04\n",
      "Epoch 5/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 2.6550e-04 - val_loss: 2.5348e-04\n",
      "Epoch 6/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 2.4600e-04 - val_loss: 2.3739e-04\n",
      "Epoch 7/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 2.3119e-04 - val_loss: 2.2370e-04\n",
      "Epoch 8/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 2.1911e-04 - val_loss: 2.1227e-04\n",
      "Epoch 9/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 2.0796e-04 - val_loss: 2.0217e-04\n",
      "Epoch 10/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.9757e-04 - val_loss: 1.9135e-04\n",
      "Epoch 11/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.8782e-04 - val_loss: 1.8208e-04\n",
      "Epoch 12/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.7801e-04 - val_loss: 1.7261e-04\n",
      "Epoch 13/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.6896e-04 - val_loss: 1.6382e-04\n",
      "Epoch 14/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.6107e-04 - val_loss: 1.5694e-04\n",
      "Epoch 15/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.5424e-04 - val_loss: 1.5105e-04\n",
      "Epoch 16/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.4839e-04 - val_loss: 1.4464e-04\n",
      "Epoch 17/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.4276e-04 - val_loss: 1.3930e-04\n",
      "Epoch 18/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.3767e-04 - val_loss: 1.3379e-04\n",
      "Epoch 19/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.3301e-04 - val_loss: 1.3031e-04\n",
      "Epoch 20/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.2932e-04 - val_loss: 1.2655e-04\n",
      "Epoch 21/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.2572e-04 - val_loss: 1.2303e-04\n",
      "Epoch 22/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.2258e-04 - val_loss: 1.2049e-04\n",
      "Epoch 23/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.1939e-04 - val_loss: 1.1747e-04\n",
      "Epoch 24/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.1734e-04 - val_loss: 1.1561e-04\n",
      "Epoch 25/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.1496e-04 - val_loss: 1.1337e-04\n",
      "Epoch 26/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.1254e-04 - val_loss: 1.1059e-04\n",
      "Epoch 27/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.1097e-04 - val_loss: 1.0884e-04\n",
      "Epoch 28/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.0914e-04 - val_loss: 1.0789e-04\n",
      "Epoch 29/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.0821e-04 - val_loss: 1.0634e-04\n",
      "Epoch 30/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.0668e-04 - val_loss: 1.0573e-04\n",
      "Epoch 31/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.0514e-04 - val_loss: 1.0557e-04\n",
      "Epoch 32/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.0410e-04 - val_loss: 1.0280e-04\n",
      "Epoch 33/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.0285e-04 - val_loss: 1.0160e-04\n",
      "Epoch 34/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.0182e-04 - val_loss: 1.0208e-04\n",
      "Epoch 35/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.0141e-04 - val_loss: 1.0073e-04\n",
      "Epoch 36/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 1.0043e-04 - val_loss: 9.8659e-05\n",
      "Epoch 37/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 9.9424e-05 - val_loss: 9.8138e-05\n",
      "Epoch 38/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 9.8800e-05 - val_loss: 9.7489e-05\n",
      "Epoch 39/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 9.7905e-05 - val_loss: 9.7235e-05\n",
      "Epoch 40/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 9.7124e-05 - val_loss: 9.7857e-05\n",
      "Epoch 41/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 9.7149e-05 - val_loss: 9.5935e-05\n",
      "Epoch 42/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 9.6161e-05 - val_loss: 9.5007e-05\n",
      "Epoch 43/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 9.5257e-05 - val_loss: 9.4472e-05\n",
      "Epoch 44/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 9.4679e-05 - val_loss: 9.5147e-05\n",
      "Epoch 45/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 9.4299e-05 - val_loss: 9.3950e-05\n",
      "Epoch 46/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 9.4123e-05 - val_loss: 9.4308e-05\n",
      "Epoch 47/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 9.3337e-05 - val_loss: 9.2603e-05\n",
      "Epoch 48/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 9.2865e-05 - val_loss: 9.1915e-05\n",
      "Epoch 49/1000\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 9.2259e-05 - val_loss: 9.1549e-05\n",
      "Epoch 50/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 9.1483e-05 - val_loss: 9.2081e-05\n",
      "Epoch 51/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 9.1879e-05 - val_loss: 9.1863e-05\n",
      "Epoch 52/1000\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 9.0540e-05 - val_loss: 9.0890e-05\n",
      "Epoch 53/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 9.0735e-05 - val_loss: 8.9238e-05\n",
      "Epoch 54/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 9.0030e-05 - val_loss: 8.8813e-05\n",
      "Epoch 55/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.9833e-05 - val_loss: 9.0864e-05\n",
      "Epoch 56/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.9124e-05 - val_loss: 9.0192e-05\n",
      "Epoch 57/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.9482e-05 - val_loss: 8.9021e-05\n",
      "Epoch 58/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.8486e-05 - val_loss: 8.7717e-05\n",
      "Epoch 59/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.8378e-05 - val_loss: 8.7738e-05\n",
      "Epoch 60/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.7774e-05 - val_loss: 8.6992e-05\n",
      "Epoch 61/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.7413e-05 - val_loss: 8.6810e-05\n",
      "Epoch 62/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.7141e-05 - val_loss: 8.7569e-05\n",
      "Epoch 63/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.7022e-05 - val_loss: 8.7887e-05\n",
      "Epoch 64/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.6803e-05 - val_loss: 8.5754e-05\n",
      "Epoch 65/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.6483e-05 - val_loss: 8.5623e-05\n",
      "Epoch 66/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.5857e-05 - val_loss: 8.6109e-05\n",
      "Epoch 67/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.5974e-05 - val_loss: 8.5414e-05\n",
      "Epoch 68/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.5331e-05 - val_loss: 8.4768e-05\n",
      "Epoch 69/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.5078e-05 - val_loss: 8.6000e-05\n",
      "Epoch 70/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.4902e-05 - val_loss: 8.4999e-05\n",
      "Epoch 71/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.5174e-05 - val_loss: 8.6596e-05\n",
      "Epoch 72/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.4475e-05 - val_loss: 8.4686e-05\n",
      "Epoch 73/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.4183e-05 - val_loss: 8.4532e-05\n",
      "Epoch 74/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.4003e-05 - val_loss: 8.3737e-05\n",
      "Epoch 75/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 8.3868e-05 - val_loss: 8.4831e-05\n",
      "Epoch 76/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 5ms/step - loss: 8.3518e-05 - val_loss: 8.2578e-05\n",
      "Epoch 77/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 8.3239e-05 - val_loss: 8.2282e-05\n",
      "Epoch 78/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 8.3178e-05 - val_loss: 8.3144e-05\n",
      "Epoch 79/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 8.2626e-05 - val_loss: 8.2741e-05\n",
      "Epoch 80/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.2146e-05 - val_loss: 8.6205e-05\n",
      "Epoch 81/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.2474e-05 - val_loss: 8.1149e-05\n",
      "Epoch 82/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.1809e-05 - val_loss: 8.2531e-05\n",
      "Epoch 83/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 8.2020e-05 - val_loss: 8.2727e-05\n",
      "Epoch 84/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 8.1652e-05 - val_loss: 8.1521e-05\n",
      "Epoch 85/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 8.1067e-05 - val_loss: 8.1368e-05\n",
      "Epoch 86/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.0911e-05 - val_loss: 8.0452e-05\n",
      "Epoch 87/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 8.0512e-05 - val_loss: 8.0066e-05\n",
      "Epoch 88/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.9948e-05 - val_loss: 8.0940e-05\n",
      "Epoch 89/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 8.0005e-05 - val_loss: 8.0017e-05\n",
      "Epoch 90/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.9940e-05 - val_loss: 7.9775e-05\n",
      "Epoch 91/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 8.0017e-05 - val_loss: 8.1246e-05\n",
      "Epoch 92/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.9702e-05 - val_loss: 7.9999e-05\n",
      "Epoch 93/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.9375e-05 - val_loss: 7.9922e-05\n",
      "Epoch 94/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.9398e-05 - val_loss: 7.9229e-05\n",
      "Epoch 95/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.9371e-05 - val_loss: 7.8518e-05\n",
      "Epoch 96/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.9017e-05 - val_loss: 8.1853e-05\n",
      "Epoch 97/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.8989e-05 - val_loss: 7.9458e-05\n",
      "Epoch 98/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.8833e-05 - val_loss: 8.3388e-05\n",
      "Epoch 99/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.8257e-05 - val_loss: 7.8071e-05\n",
      "Epoch 100/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.8381e-05 - val_loss: 7.7975e-05\n",
      "Epoch 101/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.7511e-05 - val_loss: 7.7712e-05\n",
      "Epoch 102/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.7879e-05 - val_loss: 7.8082e-05\n",
      "Epoch 103/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.7599e-05 - val_loss: 7.7813e-05\n",
      "Epoch 104/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.7863e-05 - val_loss: 7.7882e-05\n",
      "Epoch 105/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.7636e-05 - val_loss: 7.7391e-05\n",
      "Epoch 106/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.7070e-05 - val_loss: 7.7736e-05\n",
      "Epoch 107/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.7337e-05 - val_loss: 7.8242e-05\n",
      "Epoch 108/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.7031e-05 - val_loss: 7.7620e-05\n",
      "Epoch 109/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.6681e-05 - val_loss: 7.7226e-05\n",
      "Epoch 110/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.6537e-05 - val_loss: 7.6247e-05\n",
      "Epoch 111/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.6179e-05 - val_loss: 7.6017e-05\n",
      "Epoch 112/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.6253e-05 - val_loss: 7.7361e-05\n",
      "Epoch 113/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.6002e-05 - val_loss: 7.8262e-05\n",
      "Epoch 114/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.5782e-05 - val_loss: 7.5874e-05\n",
      "Epoch 115/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.5560e-05 - val_loss: 7.6918e-05\n",
      "Epoch 116/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.5355e-05 - val_loss: 7.6575e-05\n",
      "Epoch 117/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.5902e-05 - val_loss: 7.6433e-05\n",
      "Epoch 118/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.5271e-05 - val_loss: 7.6938e-05\n",
      "Epoch 119/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.5597e-05 - val_loss: 7.4754e-05\n",
      "Epoch 120/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.5077e-05 - val_loss: 7.5171e-05\n",
      "Epoch 121/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.5029e-05 - val_loss: 7.6986e-05\n",
      "Epoch 122/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.4873e-05 - val_loss: 7.6069e-05\n",
      "Epoch 123/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.5122e-05 - val_loss: 7.8798e-05\n",
      "Epoch 124/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.4618e-05 - val_loss: 7.4723e-05\n",
      "Epoch 125/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.4839e-05 - val_loss: 7.6116e-05\n",
      "Epoch 126/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.4505e-05 - val_loss: 7.4624e-05\n",
      "Epoch 127/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.4298e-05 - val_loss: 7.5722e-05\n",
      "Epoch 128/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.4162e-05 - val_loss: 7.6996e-05\n",
      "Epoch 129/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.4112e-05 - val_loss: 7.4203e-05\n",
      "Epoch 130/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.3871e-05 - val_loss: 7.5040e-05\n",
      "Epoch 131/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.3990e-05 - val_loss: 7.3494e-05\n",
      "Epoch 132/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.3777e-05 - val_loss: 7.3775e-05\n",
      "Epoch 133/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.3311e-05 - val_loss: 7.5836e-05\n",
      "Epoch 134/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.3164e-05 - val_loss: 7.4249e-05\n",
      "Epoch 135/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.3365e-05 - val_loss: 7.5123e-05\n",
      "Epoch 136/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.3250e-05 - val_loss: 7.3739e-05\n",
      "Epoch 137/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.3166e-05 - val_loss: 7.5796e-05\n",
      "Epoch 138/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.3094e-05 - val_loss: 7.3588e-05\n",
      "Epoch 139/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.3095e-05 - val_loss: 7.3675e-05\n",
      "Epoch 140/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.2635e-05 - val_loss: 7.4551e-05\n",
      "Epoch 141/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.2822e-05 - val_loss: 7.3400e-05\n",
      "Epoch 142/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.3050e-05 - val_loss: 7.3134e-05\n",
      "Epoch 143/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.2391e-05 - val_loss: 7.4453e-05\n",
      "Epoch 144/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.2219e-05 - val_loss: 7.2638e-05\n",
      "Epoch 145/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.2378e-05 - val_loss: 7.2024e-05\n",
      "Epoch 146/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.1894e-05 - val_loss: 7.2750e-05\n",
      "Epoch 147/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.2050e-05 - val_loss: 7.2096e-05\n",
      "Epoch 148/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.1996e-05 - val_loss: 7.3131e-05\n",
      "Epoch 149/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.1854e-05 - val_loss: 7.2457e-05\n",
      "Epoch 150/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.1583e-05 - val_loss: 7.1947e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.1278e-05 - val_loss: 7.3101e-05\n",
      "Epoch 152/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.1592e-05 - val_loss: 7.2769e-05\n",
      "Epoch 153/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.1577e-05 - val_loss: 7.4578e-05\n",
      "Epoch 154/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.1178e-05 - val_loss: 7.1896e-05\n",
      "Epoch 155/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.1286e-05 - val_loss: 7.2080e-05\n",
      "Epoch 156/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.0776e-05 - val_loss: 7.2285e-05\n",
      "Epoch 157/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.0930e-05 - val_loss: 7.1282e-05\n",
      "Epoch 158/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.1366e-05 - val_loss: 7.0947e-05\n",
      "Epoch 159/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.0687e-05 - val_loss: 7.2196e-05\n",
      "Epoch 160/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.0737e-05 - val_loss: 7.2472e-05\n",
      "Epoch 161/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.0574e-05 - val_loss: 7.2517e-05\n",
      "Epoch 162/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.0791e-05 - val_loss: 7.0967e-05\n",
      "Epoch 163/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.0480e-05 - val_loss: 7.1398e-05\n",
      "Epoch 164/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.0360e-05 - val_loss: 7.1315e-05\n",
      "Epoch 165/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.0102e-05 - val_loss: 7.0546e-05\n",
      "Epoch 166/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.0572e-05 - val_loss: 7.0899e-05\n",
      "Epoch 167/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 7.0088e-05 - val_loss: 7.2959e-05\n",
      "Epoch 168/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.9798e-05 - val_loss: 7.1871e-05\n",
      "Epoch 169/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.0155e-05 - val_loss: 7.0308e-05\n",
      "Epoch 170/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.0018e-05 - val_loss: 7.1756e-05\n",
      "Epoch 171/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 7.0116e-05 - val_loss: 7.3192e-05\n",
      "Epoch 172/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.9818e-05 - val_loss: 7.0748e-05\n",
      "Epoch 173/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.9566e-05 - val_loss: 7.0333e-05\n",
      "Epoch 174/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.9243e-05 - val_loss: 7.0784e-05\n",
      "Epoch 175/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.9344e-05 - val_loss: 7.0740e-05\n",
      "Epoch 176/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.9241e-05 - val_loss: 7.0052e-05\n",
      "Epoch 177/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.9449e-05 - val_loss: 7.0494e-05\n",
      "Epoch 178/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.9040e-05 - val_loss: 7.0011e-05\n",
      "Epoch 179/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.8973e-05 - val_loss: 7.0114e-05\n",
      "Epoch 180/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.8919e-05 - val_loss: 6.9633e-05\n",
      "Epoch 181/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.8518e-05 - val_loss: 7.0840e-05\n",
      "Epoch 182/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.8681e-05 - val_loss: 6.9546e-05\n",
      "Epoch 183/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.8375e-05 - val_loss: 6.9791e-05\n",
      "Epoch 184/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.8609e-05 - val_loss: 7.1069e-05\n",
      "Epoch 185/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.8879e-05 - val_loss: 6.9089e-05\n",
      "Epoch 186/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.8423e-05 - val_loss: 7.0432e-05\n",
      "Epoch 187/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.8267e-05 - val_loss: 6.9223e-05\n",
      "Epoch 188/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.7982e-05 - val_loss: 6.8413e-05\n",
      "Epoch 189/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.8425e-05 - val_loss: 7.0010e-05\n",
      "Epoch 190/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.8026e-05 - val_loss: 6.9437e-05\n",
      "Epoch 191/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.7626e-05 - val_loss: 6.9499e-05\n",
      "Epoch 192/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.7746e-05 - val_loss: 6.8206e-05\n",
      "Epoch 193/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.7823e-05 - val_loss: 6.9511e-05\n",
      "Epoch 194/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.7407e-05 - val_loss: 6.9703e-05\n",
      "Epoch 195/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.7656e-05 - val_loss: 6.8971e-05\n",
      "Epoch 196/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.7666e-05 - val_loss: 6.8551e-05\n",
      "Epoch 197/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.7861e-05 - val_loss: 6.9470e-05\n",
      "Epoch 198/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.7207e-05 - val_loss: 6.9153e-05\n",
      "Epoch 199/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.7128e-05 - val_loss: 6.8621e-05\n",
      "Epoch 200/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.7397e-05 - val_loss: 6.8736e-05\n",
      "Epoch 201/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.7306e-05 - val_loss: 6.8964e-05\n",
      "Epoch 202/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.7060e-05 - val_loss: 6.7941e-05\n",
      "Epoch 203/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.6983e-05 - val_loss: 6.8104e-05\n",
      "Epoch 204/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.7189e-05 - val_loss: 6.9713e-05\n",
      "Epoch 205/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.6681e-05 - val_loss: 6.8575e-05\n",
      "Epoch 206/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.7039e-05 - val_loss: 6.8722e-05\n",
      "Epoch 207/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.6492e-05 - val_loss: 6.7519e-05\n",
      "Epoch 208/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.6603e-05 - val_loss: 7.0358e-05\n",
      "Epoch 209/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.6832e-05 - val_loss: 6.7434e-05\n",
      "Epoch 210/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.6781e-05 - val_loss: 6.7287e-05\n",
      "Epoch 211/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.6398e-05 - val_loss: 6.7242e-05\n",
      "Epoch 212/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.5987e-05 - val_loss: 6.7859e-05\n",
      "Epoch 213/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.6575e-05 - val_loss: 6.7286e-05\n",
      "Epoch 214/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.6617e-05 - val_loss: 6.9006e-05\n",
      "Epoch 215/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.5947e-05 - val_loss: 6.7928e-05\n",
      "Epoch 216/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.5869e-05 - val_loss: 6.6603e-05\n",
      "Epoch 217/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.5868e-05 - val_loss: 6.7553e-05\n",
      "Epoch 218/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.5670e-05 - val_loss: 6.6861e-05\n",
      "Epoch 219/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.5663e-05 - val_loss: 6.6833e-05\n",
      "Epoch 220/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.5851e-05 - val_loss: 6.7405e-05\n",
      "Epoch 221/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.5810e-05 - val_loss: 6.6025e-05\n",
      "Epoch 222/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.5402e-05 - val_loss: 6.6286e-05\n",
      "Epoch 223/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.5724e-05 - val_loss: 6.7931e-05\n",
      "Epoch 224/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.5673e-05 - val_loss: 6.6406e-05\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 5ms/step - loss: 6.5640e-05 - val_loss: 6.7237e-05\n",
      "Epoch 226/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.5233e-05 - val_loss: 6.7062e-05\n",
      "Epoch 227/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.5268e-05 - val_loss: 6.6437e-05\n",
      "Epoch 228/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.5183e-05 - val_loss: 6.6221e-05\n",
      "Epoch 229/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.4777e-05 - val_loss: 6.6175e-05\n",
      "Epoch 230/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.5237e-05 - val_loss: 6.6060e-05\n",
      "Epoch 231/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.4923e-05 - val_loss: 6.7121e-05\n",
      "Epoch 232/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.4866e-05 - val_loss: 6.5923e-05\n",
      "Epoch 233/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.4584e-05 - val_loss: 6.6121e-05\n",
      "Epoch 234/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.4854e-05 - val_loss: 6.5755e-05\n",
      "Epoch 235/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.4767e-05 - val_loss: 6.6860e-05\n",
      "Epoch 236/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.4630e-05 - val_loss: 6.6949e-05\n",
      "Epoch 237/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.4624e-05 - val_loss: 6.5839e-05\n",
      "Epoch 238/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.4337e-05 - val_loss: 6.8346e-05\n",
      "Epoch 239/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.4399e-05 - val_loss: 6.6375e-05\n",
      "Epoch 240/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.4490e-05 - val_loss: 6.5556e-05\n",
      "Epoch 241/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.4195e-05 - val_loss: 6.7122e-05\n",
      "Epoch 242/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.4324e-05 - val_loss: 6.7258e-05\n",
      "Epoch 243/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.4548e-05 - val_loss: 6.5644e-05\n",
      "Epoch 244/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.4180e-05 - val_loss: 6.6862e-05\n",
      "Epoch 245/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.4027e-05 - val_loss: 6.5428e-05\n",
      "Epoch 246/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.4127e-05 - val_loss: 6.5607e-05\n",
      "Epoch 247/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.3699e-05 - val_loss: 6.5732e-05\n",
      "Epoch 248/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.3750e-05 - val_loss: 6.5292e-05\n",
      "Epoch 249/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.3825e-05 - val_loss: 6.5519e-05\n",
      "Epoch 250/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.3806e-05 - val_loss: 6.4980e-05\n",
      "Epoch 251/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.3752e-05 - val_loss: 6.4235e-05\n",
      "Epoch 252/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.3727e-05 - val_loss: 6.4855e-05\n",
      "Epoch 253/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.3480e-05 - val_loss: 6.4376e-05\n",
      "Epoch 254/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.3659e-05 - val_loss: 6.5892e-05\n",
      "Epoch 255/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.3568e-05 - val_loss: 6.4651e-05\n",
      "Epoch 256/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.3571e-05 - val_loss: 6.5970e-05\n",
      "Epoch 257/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.3321e-05 - val_loss: 6.5777e-05\n",
      "Epoch 258/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.3103e-05 - val_loss: 6.6017e-05\n",
      "Epoch 259/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.3307e-05 - val_loss: 6.4794e-05\n",
      "Epoch 260/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.3126e-05 - val_loss: 6.4383e-05\n",
      "Epoch 261/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.3672e-05 - val_loss: 6.4271e-05\n",
      "Epoch 262/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.3018e-05 - val_loss: 6.4452e-05\n",
      "Epoch 263/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.3096e-05 - val_loss: 6.4425e-05\n",
      "Epoch 264/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.2965e-05 - val_loss: 6.4720e-05\n",
      "Epoch 265/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.2962e-05 - val_loss: 6.3990e-05\n",
      "Epoch 266/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.2634e-05 - val_loss: 6.4316e-05\n",
      "Epoch 267/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.2620e-05 - val_loss: 6.3695e-05\n",
      "Epoch 268/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.2406e-05 - val_loss: 6.5138e-05\n",
      "Epoch 269/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.2393e-05 - val_loss: 6.3758e-05\n",
      "Epoch 270/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.2548e-05 - val_loss: 6.3578e-05\n",
      "Epoch 271/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.2382e-05 - val_loss: 6.3413e-05\n",
      "Epoch 272/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.2219e-05 - val_loss: 6.4041e-05\n",
      "Epoch 273/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.2597e-05 - val_loss: 6.4199e-05\n",
      "Epoch 274/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.2178e-05 - val_loss: 6.3769e-05\n",
      "Epoch 275/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.2219e-05 - val_loss: 6.4087e-05\n",
      "Epoch 276/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.2003e-05 - val_loss: 6.4245e-05\n",
      "Epoch 277/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.1886e-05 - val_loss: 6.3748e-05\n",
      "Epoch 278/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.2155e-05 - val_loss: 6.3423e-05\n",
      "Epoch 279/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.2038e-05 - val_loss: 6.3631e-05\n",
      "Epoch 280/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.1761e-05 - val_loss: 6.4009e-05\n",
      "Epoch 281/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.2041e-05 - val_loss: 6.4430e-05\n",
      "Epoch 282/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.1785e-05 - val_loss: 6.3104e-05\n",
      "Epoch 283/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.1506e-05 - val_loss: 6.2939e-05\n",
      "Epoch 284/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.1365e-05 - val_loss: 6.3426e-05\n",
      "Epoch 285/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.1736e-05 - val_loss: 6.2630e-05\n",
      "Epoch 286/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.1447e-05 - val_loss: 6.4160e-05\n",
      "Epoch 287/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.1541e-05 - val_loss: 6.3483e-05\n",
      "Epoch 288/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.1477e-05 - val_loss: 6.2579e-05\n",
      "Epoch 289/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.1297e-05 - val_loss: 6.4748e-05\n",
      "Epoch 290/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.1279e-05 - val_loss: 6.3509e-05\n",
      "Epoch 291/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.1100e-05 - val_loss: 6.3208e-05\n",
      "Epoch 292/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.1159e-05 - val_loss: 6.2252e-05\n",
      "Epoch 293/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.1164e-05 - val_loss: 6.2804e-05\n",
      "Epoch 294/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.1043e-05 - val_loss: 6.2620e-05\n",
      "Epoch 295/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.1006e-05 - val_loss: 6.2477e-05\n",
      "Epoch 296/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.1043e-05 - val_loss: 6.2327e-05\n",
      "Epoch 297/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.0861e-05 - val_loss: 6.3276e-05\n",
      "Epoch 298/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.1012e-05 - val_loss: 6.2356e-05\n",
      "Epoch 299/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 4ms/step - loss: 6.0755e-05 - val_loss: 6.1997e-05\n",
      "Epoch 300/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.0901e-05 - val_loss: 6.1574e-05\n",
      "Epoch 301/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.0488e-05 - val_loss: 6.2124e-05\n",
      "Epoch 302/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.0574e-05 - val_loss: 6.3418e-05\n",
      "Epoch 303/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.0786e-05 - val_loss: 6.2875e-05\n",
      "Epoch 304/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.1073e-05 - val_loss: 6.2231e-05\n",
      "Epoch 305/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.0387e-05 - val_loss: 6.3301e-05\n",
      "Epoch 306/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.0593e-05 - val_loss: 6.1594e-05\n",
      "Epoch 307/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.0365e-05 - val_loss: 6.2062e-05\n",
      "Epoch 308/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.0395e-05 - val_loss: 6.1484e-05\n",
      "Epoch 309/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.0195e-05 - val_loss: 6.1924e-05\n",
      "Epoch 310/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.0085e-05 - val_loss: 6.1700e-05\n",
      "Epoch 311/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.0275e-05 - val_loss: 6.2236e-05\n",
      "Epoch 312/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.9930e-05 - val_loss: 6.1267e-05\n",
      "Epoch 313/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.0021e-05 - val_loss: 6.2192e-05\n",
      "Epoch 314/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.0092e-05 - val_loss: 6.1154e-05\n",
      "Epoch 315/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.0193e-05 - val_loss: 6.1751e-05\n",
      "Epoch 316/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.9582e-05 - val_loss: 6.0994e-05\n",
      "Epoch 317/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.9841e-05 - val_loss: 6.2367e-05\n",
      "Epoch 318/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.0007e-05 - val_loss: 6.2482e-05\n",
      "Epoch 319/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 6.0190e-05 - val_loss: 6.3073e-05\n",
      "Epoch 320/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 6.0207e-05 - val_loss: 6.0911e-05\n",
      "Epoch 321/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.9474e-05 - val_loss: 6.1399e-05\n",
      "Epoch 322/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.9772e-05 - val_loss: 6.1226e-05\n",
      "Epoch 323/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.9351e-05 - val_loss: 6.1704e-05\n",
      "Epoch 324/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.9222e-05 - val_loss: 6.1090e-05\n",
      "Epoch 325/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.9683e-05 - val_loss: 6.3325e-05\n",
      "Epoch 326/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.9616e-05 - val_loss: 6.1609e-05\n",
      "Epoch 327/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.9299e-05 - val_loss: 6.1306e-05\n",
      "Epoch 328/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.9383e-05 - val_loss: 6.0758e-05\n",
      "Epoch 329/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.9157e-05 - val_loss: 6.1309e-05\n",
      "Epoch 330/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.9345e-05 - val_loss: 6.0902e-05\n",
      "Epoch 331/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.9130e-05 - val_loss: 6.1470e-05\n",
      "Epoch 332/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.8935e-05 - val_loss: 6.0398e-05\n",
      "Epoch 333/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.8978e-05 - val_loss: 6.2455e-05\n",
      "Epoch 334/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.9306e-05 - val_loss: 6.1374e-05\n",
      "Epoch 335/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.8746e-05 - val_loss: 6.0359e-05\n",
      "Epoch 336/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.9227e-05 - val_loss: 6.0574e-05\n",
      "Epoch 337/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.9249e-05 - val_loss: 6.1350e-05\n",
      "Epoch 338/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.8973e-05 - val_loss: 6.1350e-05\n",
      "Epoch 339/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.8635e-05 - val_loss: 6.1234e-05\n",
      "Epoch 340/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.9008e-05 - val_loss: 6.1383e-05\n",
      "Epoch 341/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.8913e-05 - val_loss: 6.1645e-05\n",
      "Epoch 342/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.8885e-05 - val_loss: 6.1084e-05\n",
      "Epoch 343/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.8795e-05 - val_loss: 6.0665e-05\n",
      "Epoch 344/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.8900e-05 - val_loss: 6.1668e-05\n",
      "Epoch 345/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.8511e-05 - val_loss: 6.0317e-05\n",
      "Epoch 346/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.8685e-05 - val_loss: 6.0439e-05\n",
      "Epoch 347/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.8564e-05 - val_loss: 5.9576e-05\n",
      "Epoch 348/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.8427e-05 - val_loss: 5.9820e-05\n",
      "Epoch 349/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.8306e-05 - val_loss: 6.0248e-05\n",
      "Epoch 350/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.8422e-05 - val_loss: 6.0579e-05\n",
      "Epoch 351/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.8503e-05 - val_loss: 6.0036e-05\n",
      "Epoch 352/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.8263e-05 - val_loss: 5.9857e-05\n",
      "Epoch 353/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.8143e-05 - val_loss: 6.0280e-05\n",
      "Epoch 354/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.8259e-05 - val_loss: 6.0337e-05\n",
      "Epoch 355/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.8502e-05 - val_loss: 6.0315e-05\n",
      "Epoch 356/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.8356e-05 - val_loss: 6.0570e-05\n",
      "Epoch 357/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.7979e-05 - val_loss: 6.0039e-05\n",
      "Epoch 358/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.8173e-05 - val_loss: 6.0865e-05\n",
      "Epoch 359/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.7951e-05 - val_loss: 5.9873e-05\n",
      "Epoch 360/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.8132e-05 - val_loss: 6.0087e-05\n",
      "Epoch 361/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.8034e-05 - val_loss: 6.0869e-05\n",
      "Epoch 362/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.7910e-05 - val_loss: 5.9819e-05\n",
      "Epoch 363/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.8075e-05 - val_loss: 6.0783e-05\n",
      "Epoch 364/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.7872e-05 - val_loss: 6.0237e-05\n",
      "Epoch 365/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.7901e-05 - val_loss: 5.9600e-05\n",
      "Epoch 366/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.7803e-05 - val_loss: 6.0245e-05\n",
      "Epoch 367/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.7773e-05 - val_loss: 6.0159e-05\n",
      "Epoch 368/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.7928e-05 - val_loss: 6.0919e-05\n",
      "Epoch 369/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.7834e-05 - val_loss: 5.9927e-05\n",
      "Epoch 370/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.7500e-05 - val_loss: 6.0377e-05\n",
      "Epoch 371/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.7639e-05 - val_loss: 5.9086e-05\n",
      "Epoch 372/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.7554e-05 - val_loss: 5.9282e-05\n",
      "Epoch 373/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 5ms/step - loss: 5.7784e-05 - val_loss: 5.9570e-05\n",
      "Epoch 374/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.7414e-05 - val_loss: 5.8925e-05\n",
      "Epoch 375/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.7919e-05 - val_loss: 6.0629e-05\n",
      "Epoch 376/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.7949e-05 - val_loss: 5.9747e-05\n",
      "Epoch 377/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.7079e-05 - val_loss: 5.9332e-05\n",
      "Epoch 378/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.7562e-05 - val_loss: 5.9306e-05\n",
      "Epoch 379/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.7324e-05 - val_loss: 5.9755e-05\n",
      "Epoch 380/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.7137e-05 - val_loss: 5.9194e-05\n",
      "Epoch 381/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.7060e-05 - val_loss: 5.8885e-05\n",
      "Epoch 382/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.7110e-05 - val_loss: 5.9474e-05\n",
      "Epoch 383/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.6850e-05 - val_loss: 5.8620e-05\n",
      "Epoch 384/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.6805e-05 - val_loss: 5.9119e-05\n",
      "Epoch 385/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.6978e-05 - val_loss: 5.9871e-05\n",
      "Epoch 386/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.6939e-05 - val_loss: 5.9774e-05\n",
      "Epoch 387/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.7194e-05 - val_loss: 5.9381e-05\n",
      "Epoch 388/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.6752e-05 - val_loss: 5.9140e-05\n",
      "Epoch 389/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.6710e-05 - val_loss: 5.9774e-05\n",
      "Epoch 390/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.6724e-05 - val_loss: 5.8813e-05\n",
      "Epoch 391/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.6948e-05 - val_loss: 6.0880e-05\n",
      "Epoch 392/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.7153e-05 - val_loss: 5.9087e-05\n",
      "Epoch 393/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.6694e-05 - val_loss: 5.9887e-05\n",
      "Epoch 394/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.6827e-05 - val_loss: 5.8612e-05\n",
      "Epoch 395/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.6853e-05 - val_loss: 5.8559e-05\n",
      "Epoch 396/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.6527e-05 - val_loss: 5.9675e-05\n",
      "Epoch 397/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.6764e-05 - val_loss: 5.8898e-05\n",
      "Epoch 398/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.6582e-05 - val_loss: 5.8680e-05\n",
      "Epoch 399/1000\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 5.6554e-05 - val_loss: 5.8074e-05\n",
      "Epoch 400/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.6662e-05 - val_loss: 5.8782e-05\n",
      "Epoch 401/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.6480e-05 - val_loss: 5.8403e-05\n",
      "Epoch 402/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.6575e-05 - val_loss: 5.9279e-05\n",
      "Epoch 403/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.6326e-05 - val_loss: 5.8415e-05\n",
      "Epoch 404/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.6419e-05 - val_loss: 5.8351e-05\n",
      "Epoch 405/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.6212e-05 - val_loss: 5.8626e-05\n",
      "Epoch 406/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.6508e-05 - val_loss: 5.8038e-05\n",
      "Epoch 407/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.6086e-05 - val_loss: 5.8973e-05\n",
      "Epoch 408/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.6413e-05 - val_loss: 5.7787e-05\n",
      "Epoch 409/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.6247e-05 - val_loss: 5.8215e-05\n",
      "Epoch 410/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.5983e-05 - val_loss: 5.8283e-05\n",
      "Epoch 411/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.6213e-05 - val_loss: 5.8674e-05\n",
      "Epoch 412/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.6185e-05 - val_loss: 5.9633e-05\n",
      "Epoch 413/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.6276e-05 - val_loss: 5.9211e-05\n",
      "Epoch 414/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.6243e-05 - val_loss: 5.8369e-05\n",
      "Epoch 415/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.6088e-05 - val_loss: 5.8348e-05\n",
      "Epoch 416/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.6047e-05 - val_loss: 5.7817e-05\n",
      "Epoch 417/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.5944e-05 - val_loss: 5.8209e-05\n",
      "Epoch 418/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.6237e-05 - val_loss: 5.8427e-05\n",
      "Epoch 419/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.5878e-05 - val_loss: 5.7577e-05\n",
      "Epoch 420/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.5870e-05 - val_loss: 5.7724e-05\n",
      "Epoch 421/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.5713e-05 - val_loss: 5.8826e-05\n",
      "Epoch 422/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.5663e-05 - val_loss: 5.7820e-05\n",
      "Epoch 423/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.5987e-05 - val_loss: 5.8105e-05\n",
      "Epoch 424/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.5904e-05 - val_loss: 5.8223e-05\n",
      "Epoch 425/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.5944e-05 - val_loss: 5.8220e-05\n",
      "Epoch 426/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.5702e-05 - val_loss: 5.7324e-05\n",
      "Epoch 427/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.5486e-05 - val_loss: 5.7542e-05\n",
      "Epoch 428/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.5587e-05 - val_loss: 5.7746e-05\n",
      "Epoch 429/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.5476e-05 - val_loss: 5.8565e-05\n",
      "Epoch 430/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.5498e-05 - val_loss: 5.7420e-05\n",
      "Epoch 431/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.5398e-05 - val_loss: 5.7540e-05\n",
      "Epoch 432/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.5308e-05 - val_loss: 5.7762e-05\n",
      "Epoch 433/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.5302e-05 - val_loss: 5.7478e-05\n",
      "Epoch 434/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.5588e-05 - val_loss: 6.0080e-05\n",
      "Epoch 435/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.5438e-05 - val_loss: 5.8700e-05\n",
      "Epoch 436/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.5087e-05 - val_loss: 5.7886e-05\n",
      "Epoch 437/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.5464e-05 - val_loss: 5.8437e-05\n",
      "Epoch 438/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.5492e-05 - val_loss: 5.7985e-05\n",
      "Epoch 439/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.5630e-05 - val_loss: 5.7194e-05\n",
      "Epoch 440/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.5005e-05 - val_loss: 5.7407e-05\n",
      "Epoch 441/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.4952e-05 - val_loss: 5.7022e-05\n",
      "Epoch 442/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.5310e-05 - val_loss: 5.7198e-05\n",
      "Epoch 443/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.5080e-05 - val_loss: 5.8293e-05\n",
      "Epoch 444/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.4899e-05 - val_loss: 5.7584e-05\n",
      "Epoch 445/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.5083e-05 - val_loss: 5.7521e-05\n",
      "Epoch 446/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.5169e-05 - val_loss: 5.6799e-05\n",
      "Epoch 447/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 4ms/step - loss: 5.4794e-05 - val_loss: 5.7263e-05\n",
      "Epoch 448/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.5029e-05 - val_loss: 5.9467e-05\n",
      "Epoch 449/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.4970e-05 - val_loss: 5.7478e-05\n",
      "Epoch 450/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.4962e-05 - val_loss: 5.7741e-05\n",
      "Epoch 451/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.5097e-05 - val_loss: 5.8977e-05\n",
      "Epoch 452/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.4939e-05 - val_loss: 5.7168e-05\n",
      "Epoch 453/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.4814e-05 - val_loss: 5.6706e-05\n",
      "Epoch 454/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.5349e-05 - val_loss: 5.7986e-05\n",
      "Epoch 455/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.4581e-05 - val_loss: 5.7617e-05\n",
      "Epoch 456/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.4693e-05 - val_loss: 5.6936e-05\n",
      "Epoch 457/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.4514e-05 - val_loss: 5.6553e-05\n",
      "Epoch 458/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.4690e-05 - val_loss: 5.6787e-05\n",
      "Epoch 459/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.4488e-05 - val_loss: 5.7394e-05\n",
      "Epoch 460/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.4713e-05 - val_loss: 5.7473e-05\n",
      "Epoch 461/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.4511e-05 - val_loss: 5.6912e-05\n",
      "Epoch 462/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.4799e-05 - val_loss: 5.6744e-05\n",
      "Epoch 463/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.4519e-05 - val_loss: 5.7950e-05\n",
      "Epoch 464/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.4260e-05 - val_loss: 5.6525e-05\n",
      "Epoch 465/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.4429e-05 - val_loss: 5.6616e-05\n",
      "Epoch 466/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.4520e-05 - val_loss: 5.7062e-05\n",
      "Epoch 467/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.4717e-05 - val_loss: 5.6463e-05\n",
      "Epoch 468/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.4534e-05 - val_loss: 5.7466e-05\n",
      "Epoch 469/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.4538e-05 - val_loss: 5.7093e-05\n",
      "Epoch 470/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.4219e-05 - val_loss: 5.6203e-05\n",
      "Epoch 471/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.4370e-05 - val_loss: 5.6629e-05\n",
      "Epoch 472/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.4369e-05 - val_loss: 5.5966e-05\n",
      "Epoch 473/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.4401e-05 - val_loss: 5.6009e-05\n",
      "Epoch 474/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.4159e-05 - val_loss: 5.5837e-05\n",
      "Epoch 475/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.4197e-05 - val_loss: 5.6319e-05\n",
      "Epoch 476/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.4143e-05 - val_loss: 5.7084e-05\n",
      "Epoch 477/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.4215e-05 - val_loss: 5.7437e-05\n",
      "Epoch 478/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.4175e-05 - val_loss: 5.6554e-05\n",
      "Epoch 479/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.4071e-05 - val_loss: 5.6323e-05\n",
      "Epoch 480/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.4111e-05 - val_loss: 5.7580e-05\n",
      "Epoch 481/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.4053e-05 - val_loss: 5.6177e-05\n",
      "Epoch 482/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.4253e-05 - val_loss: 5.6493e-05\n",
      "Epoch 483/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.3728e-05 - val_loss: 5.6818e-05\n",
      "Epoch 484/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.4039e-05 - val_loss: 5.6220e-05\n",
      "Epoch 485/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.4002e-05 - val_loss: 5.5759e-05\n",
      "Epoch 486/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.4112e-05 - val_loss: 5.6870e-05\n",
      "Epoch 487/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.3896e-05 - val_loss: 5.6970e-05\n",
      "Epoch 488/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.3805e-05 - val_loss: 5.6404e-05\n",
      "Epoch 489/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.3977e-05 - val_loss: 5.6543e-05\n",
      "Epoch 490/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.3874e-05 - val_loss: 5.6439e-05\n",
      "Epoch 491/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.3699e-05 - val_loss: 5.6575e-05\n",
      "Epoch 492/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.3857e-05 - val_loss: 5.6574e-05\n",
      "Epoch 493/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.4034e-05 - val_loss: 5.5523e-05\n",
      "Epoch 494/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.3490e-05 - val_loss: 5.5845e-05\n",
      "Epoch 495/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.3633e-05 - val_loss: 5.6670e-05\n",
      "Epoch 496/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.3526e-05 - val_loss: 5.5778e-05\n",
      "Epoch 497/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.3761e-05 - val_loss: 5.5453e-05\n",
      "Epoch 498/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.3424e-05 - val_loss: 5.7277e-05\n",
      "Epoch 499/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.3606e-05 - val_loss: 5.6229e-05\n",
      "Epoch 500/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.3395e-05 - val_loss: 5.5986e-05\n",
      "Epoch 501/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.3478e-05 - val_loss: 5.6553e-05\n",
      "Epoch 502/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.3666e-05 - val_loss: 5.5816e-05\n",
      "Epoch 503/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.3358e-05 - val_loss: 5.6508e-05\n",
      "Epoch 504/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.3728e-05 - val_loss: 5.6018e-05\n",
      "Epoch 505/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.3506e-05 - val_loss: 5.5507e-05\n",
      "Epoch 506/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.3024e-05 - val_loss: 5.5587e-05\n",
      "Epoch 507/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.3571e-05 - val_loss: 5.5616e-05\n",
      "Epoch 508/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.3406e-05 - val_loss: 5.6014e-05\n",
      "Epoch 509/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.3345e-05 - val_loss: 5.5646e-05\n",
      "Epoch 510/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.3346e-05 - val_loss: 5.5707e-05\n",
      "Epoch 511/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.3219e-05 - val_loss: 5.6301e-05\n",
      "Epoch 512/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.3292e-05 - val_loss: 5.6289e-05\n",
      "Epoch 513/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.3424e-05 - val_loss: 5.6498e-05\n",
      "Epoch 514/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.3011e-05 - val_loss: 5.5721e-05\n",
      "Epoch 515/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.3013e-05 - val_loss: 5.5562e-05\n",
      "Epoch 516/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.2878e-05 - val_loss: 5.5832e-05\n",
      "Epoch 517/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.3059e-05 - val_loss: 5.5694e-05\n",
      "Epoch 518/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.3475e-05 - val_loss: 5.5821e-05\n",
      "Epoch 519/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.3222e-05 - val_loss: 5.5477e-05\n",
      "Epoch 520/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.2865e-05 - val_loss: 5.6225e-05\n",
      "Epoch 521/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 5ms/step - loss: 5.2909e-05 - val_loss: 5.5667e-05\n",
      "Epoch 522/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.3020e-05 - val_loss: 5.6060e-05\n",
      "Epoch 523/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.2852e-05 - val_loss: 5.5973e-05\n",
      "Epoch 524/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.3107e-05 - val_loss: 5.5173e-05\n",
      "Epoch 525/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.2821e-05 - val_loss: 5.6003e-05\n",
      "Epoch 526/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.3035e-05 - val_loss: 5.5568e-05\n",
      "Epoch 527/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.2752e-05 - val_loss: 5.5544e-05\n",
      "Epoch 528/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.3100e-05 - val_loss: 5.5405e-05\n",
      "Epoch 529/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.2719e-05 - val_loss: 5.5833e-05\n",
      "Epoch 530/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.3043e-05 - val_loss: 5.5151e-05\n",
      "Epoch 531/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.2720e-05 - val_loss: 5.4869e-05\n",
      "Epoch 532/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.2592e-05 - val_loss: 5.5474e-05\n",
      "Epoch 533/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.2459e-05 - val_loss: 5.6218e-05\n",
      "Epoch 534/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.2582e-05 - val_loss: 5.4620e-05\n",
      "Epoch 535/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.2422e-05 - val_loss: 5.5094e-05\n",
      "Epoch 536/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.2808e-05 - val_loss: 5.4853e-05\n",
      "Epoch 537/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.2434e-05 - val_loss: 5.4850e-05\n",
      "Epoch 538/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.2612e-05 - val_loss: 5.5245e-05\n",
      "Epoch 539/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.2277e-05 - val_loss: 5.5727e-05\n",
      "Epoch 540/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.2564e-05 - val_loss: 5.5513e-05\n",
      "Epoch 541/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.2402e-05 - val_loss: 5.5267e-05\n",
      "Epoch 542/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.2536e-05 - val_loss: 5.5930e-05\n",
      "Epoch 543/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.2456e-05 - val_loss: 5.5090e-05\n",
      "Epoch 544/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.2372e-05 - val_loss: 5.5306e-05\n",
      "Epoch 545/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.2471e-05 - val_loss: 5.6148e-05\n",
      "Epoch 546/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.2485e-05 - val_loss: 5.4554e-05\n",
      "Epoch 547/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.2293e-05 - val_loss: 5.6210e-05\n",
      "Epoch 548/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.2510e-05 - val_loss: 5.4904e-05\n",
      "Epoch 549/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.2157e-05 - val_loss: 5.5290e-05\n",
      "Epoch 550/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.2150e-05 - val_loss: 5.4543e-05\n",
      "Epoch 551/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.2099e-05 - val_loss: 5.4844e-05\n",
      "Epoch 552/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.2080e-05 - val_loss: 5.5233e-05\n",
      "Epoch 553/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.2175e-05 - val_loss: 5.4708e-05\n",
      "Epoch 554/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.2380e-05 - val_loss: 5.5587e-05\n",
      "Epoch 555/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.2242e-05 - val_loss: 5.5128e-05\n",
      "Epoch 556/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.2149e-05 - val_loss: 5.5108e-05\n",
      "Epoch 557/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.2215e-05 - val_loss: 5.4401e-05\n",
      "Epoch 558/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.2139e-05 - val_loss: 5.4923e-05\n",
      "Epoch 559/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.2435e-05 - val_loss: 5.6043e-05\n",
      "Epoch 560/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.1920e-05 - val_loss: 5.4734e-05\n",
      "Epoch 561/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1951e-05 - val_loss: 5.4467e-05\n",
      "Epoch 562/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1993e-05 - val_loss: 5.4445e-05\n",
      "Epoch 563/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.2031e-05 - val_loss: 5.4706e-05\n",
      "Epoch 564/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.1721e-05 - val_loss: 5.4350e-05\n",
      "Epoch 565/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.2123e-05 - val_loss: 5.4966e-05\n",
      "Epoch 566/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.1906e-05 - val_loss: 5.3829e-05\n",
      "Epoch 567/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.2172e-05 - val_loss: 5.4796e-05\n",
      "Epoch 568/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1881e-05 - val_loss: 5.5259e-05\n",
      "Epoch 569/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1766e-05 - val_loss: 5.4108e-05\n",
      "Epoch 570/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1510e-05 - val_loss: 5.3966e-05\n",
      "Epoch 571/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1947e-05 - val_loss: 5.4447e-05\n",
      "Epoch 572/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1764e-05 - val_loss: 5.4104e-05\n",
      "Epoch 573/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1724e-05 - val_loss: 5.4675e-05\n",
      "Epoch 574/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1963e-05 - val_loss: 5.3894e-05\n",
      "Epoch 575/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1528e-05 - val_loss: 5.4502e-05\n",
      "Epoch 576/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1409e-05 - val_loss: 5.4383e-05\n",
      "Epoch 577/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1563e-05 - val_loss: 5.3870e-05\n",
      "Epoch 578/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1731e-05 - val_loss: 5.4781e-05\n",
      "Epoch 579/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1456e-05 - val_loss: 5.4152e-05\n",
      "Epoch 580/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.1475e-05 - val_loss: 5.4004e-05\n",
      "Epoch 581/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1587e-05 - val_loss: 5.3988e-05\n",
      "Epoch 582/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.1764e-05 - val_loss: 5.4265e-05\n",
      "Epoch 583/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1327e-05 - val_loss: 5.4255e-05\n",
      "Epoch 584/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1261e-05 - val_loss: 5.4378e-05\n",
      "Epoch 585/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1388e-05 - val_loss: 5.4263e-05\n",
      "Epoch 586/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1423e-05 - val_loss: 5.4204e-05\n",
      "Epoch 587/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1346e-05 - val_loss: 5.3640e-05\n",
      "Epoch 588/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.1209e-05 - val_loss: 5.4211e-05\n",
      "Epoch 589/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1302e-05 - val_loss: 5.4802e-05\n",
      "Epoch 590/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1587e-05 - val_loss: 5.4809e-05\n",
      "Epoch 591/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.1382e-05 - val_loss: 5.4378e-05\n",
      "Epoch 592/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.1315e-05 - val_loss: 5.3984e-05\n",
      "Epoch 593/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1096e-05 - val_loss: 5.3987e-05\n",
      "Epoch 594/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1300e-05 - val_loss: 5.3999e-05\n",
      "Epoch 595/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1052e-05 - val_loss: 5.3888e-05\n",
      "Epoch 596/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.1226e-05 - val_loss: 5.4349e-05\n",
      "Epoch 597/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.1176e-05 - val_loss: 5.3844e-05\n",
      "Epoch 598/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1486e-05 - val_loss: 5.4550e-05\n",
      "Epoch 599/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1094e-05 - val_loss: 5.4532e-05\n",
      "Epoch 600/1000\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 5.1120e-05 - val_loss: 5.3937e-05\n",
      "Epoch 601/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0930e-05 - val_loss: 5.4533e-05\n",
      "Epoch 602/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0957e-05 - val_loss: 5.3854e-05\n",
      "Epoch 603/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1115e-05 - val_loss: 5.5041e-05\n",
      "Epoch 604/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1074e-05 - val_loss: 5.4490e-05\n",
      "Epoch 605/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.1071e-05 - val_loss: 5.3176e-05\n",
      "Epoch 606/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0921e-05 - val_loss: 5.3566e-05\n",
      "Epoch 607/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.0703e-05 - val_loss: 5.3587e-05\n",
      "Epoch 608/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0630e-05 - val_loss: 5.5001e-05\n",
      "Epoch 609/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.1061e-05 - val_loss: 5.3899e-05\n",
      "Epoch 610/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0886e-05 - val_loss: 5.3168e-05\n",
      "Epoch 611/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0684e-05 - val_loss: 5.4083e-05\n",
      "Epoch 612/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0739e-05 - val_loss: 5.3225e-05\n",
      "Epoch 613/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0912e-05 - val_loss: 5.4621e-05\n",
      "Epoch 614/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.0587e-05 - val_loss: 5.4326e-05\n",
      "Epoch 615/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.0804e-05 - val_loss: 5.3596e-05\n",
      "Epoch 616/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.0632e-05 - val_loss: 5.2957e-05\n",
      "Epoch 617/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0695e-05 - val_loss: 5.3147e-05\n",
      "Epoch 618/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0738e-05 - val_loss: 5.3297e-05\n",
      "Epoch 619/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0619e-05 - val_loss: 5.3707e-05\n",
      "Epoch 620/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0874e-05 - val_loss: 5.3633e-05\n",
      "Epoch 621/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.0527e-05 - val_loss: 5.2970e-05\n",
      "Epoch 622/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0608e-05 - val_loss: 5.3947e-05\n",
      "Epoch 623/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.0754e-05 - val_loss: 5.3889e-05\n",
      "Epoch 624/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.0771e-05 - val_loss: 5.3538e-05\n",
      "Epoch 625/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0492e-05 - val_loss: 5.3206e-05\n",
      "Epoch 626/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0439e-05 - val_loss: 5.3511e-05\n",
      "Epoch 627/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0728e-05 - val_loss: 5.3074e-05\n",
      "Epoch 628/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.0345e-05 - val_loss: 5.3805e-05\n",
      "Epoch 629/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0339e-05 - val_loss: 5.3007e-05\n",
      "Epoch 630/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.0491e-05 - val_loss: 5.3186e-05\n",
      "Epoch 631/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.0598e-05 - val_loss: 5.3524e-05\n",
      "Epoch 632/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0280e-05 - val_loss: 5.2882e-05\n",
      "Epoch 633/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0169e-05 - val_loss: 5.3108e-05\n",
      "Epoch 634/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.0484e-05 - val_loss: 5.3012e-05\n",
      "Epoch 635/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.0398e-05 - val_loss: 5.3540e-05\n",
      "Epoch 636/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0167e-05 - val_loss: 5.3648e-05\n",
      "Epoch 637/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0201e-05 - val_loss: 5.3297e-05\n",
      "Epoch 638/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.0107e-05 - val_loss: 5.3313e-05\n",
      "Epoch 639/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0036e-05 - val_loss: 5.3466e-05\n",
      "Epoch 640/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.0065e-05 - val_loss: 5.2945e-05\n",
      "Epoch 641/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.0205e-05 - val_loss: 5.2707e-05\n",
      "Epoch 642/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0013e-05 - val_loss: 5.3369e-05\n",
      "Epoch 643/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0228e-05 - val_loss: 5.3229e-05\n",
      "Epoch 644/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0354e-05 - val_loss: 5.2656e-05\n",
      "Epoch 645/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0003e-05 - val_loss: 5.4167e-05\n",
      "Epoch 646/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0564e-05 - val_loss: 5.3783e-05\n",
      "Epoch 647/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0194e-05 - val_loss: 5.3116e-05\n",
      "Epoch 648/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.9849e-05 - val_loss: 5.3211e-05\n",
      "Epoch 649/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 5.0419e-05 - val_loss: 5.2582e-05\n",
      "Epoch 650/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.9908e-05 - val_loss: 5.3264e-05\n",
      "Epoch 651/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0056e-05 - val_loss: 5.2933e-05\n",
      "Epoch 652/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0018e-05 - val_loss: 5.2778e-05\n",
      "Epoch 653/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 5.0037e-05 - val_loss: 5.3160e-05\n",
      "Epoch 654/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.9903e-05 - val_loss: 5.3519e-05\n",
      "Epoch 655/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.9842e-05 - val_loss: 5.3550e-05\n",
      "Epoch 656/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.9940e-05 - val_loss: 5.2295e-05\n",
      "Epoch 657/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.9819e-05 - val_loss: 5.2341e-05\n",
      "Epoch 658/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.9742e-05 - val_loss: 5.3284e-05\n",
      "Epoch 659/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.9953e-05 - val_loss: 5.2681e-05\n",
      "Epoch 660/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.9996e-05 - val_loss: 5.3299e-05\n",
      "Epoch 661/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.9735e-05 - val_loss: 5.2511e-05\n",
      "Epoch 662/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.9732e-05 - val_loss: 5.3098e-05\n",
      "Epoch 663/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.9662e-05 - val_loss: 5.2840e-05\n",
      "Epoch 664/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.9699e-05 - val_loss: 5.2654e-05\n",
      "Epoch 665/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.9524e-05 - val_loss: 5.3316e-05\n",
      "Epoch 666/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.9534e-05 - val_loss: 5.2526e-05\n",
      "Epoch 667/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.9442e-05 - val_loss: 5.2386e-05\n",
      "Epoch 668/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.9644e-05 - val_loss: 5.2302e-05\n",
      "Epoch 669/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 4ms/step - loss: 4.9726e-05 - val_loss: 5.2099e-05\n",
      "Epoch 670/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.9678e-05 - val_loss: 5.2880e-05\n",
      "Epoch 671/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.9478e-05 - val_loss: 5.2593e-05\n",
      "Epoch 672/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.9586e-05 - val_loss: 5.3235e-05\n",
      "Epoch 673/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.9396e-05 - val_loss: 5.2442e-05\n",
      "Epoch 674/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.9715e-05 - val_loss: 5.2492e-05\n",
      "Epoch 675/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.9544e-05 - val_loss: 5.4186e-05\n",
      "Epoch 676/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.9554e-05 - val_loss: 5.2687e-05\n",
      "Epoch 677/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.9327e-05 - val_loss: 5.2269e-05\n",
      "Epoch 678/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.9517e-05 - val_loss: 5.3630e-05\n",
      "Epoch 679/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.9840e-05 - val_loss: 5.2544e-05\n",
      "Epoch 680/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.9390e-05 - val_loss: 5.2843e-05\n",
      "Epoch 681/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.9309e-05 - val_loss: 5.2092e-05\n",
      "Epoch 682/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.9392e-05 - val_loss: 5.2400e-05\n",
      "Epoch 683/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.9342e-05 - val_loss: 5.2683e-05\n",
      "Epoch 684/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.9011e-05 - val_loss: 5.1955e-05\n",
      "Epoch 685/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.9012e-05 - val_loss: 5.2121e-05\n",
      "Epoch 686/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.8961e-05 - val_loss: 5.1855e-05\n",
      "Epoch 687/1000\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 4.9124e-05 - val_loss: 5.1923e-05\n",
      "Epoch 688/1000\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 4.9252e-05 - val_loss: 5.3043e-05\n",
      "Epoch 689/1000\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 4.9251e-05 - val_loss: 5.2731e-05\n",
      "Epoch 690/1000\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 4.9449e-05 - val_loss: 5.1876e-05\n",
      "Epoch 691/1000\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 4.8935e-05 - val_loss: 5.2952e-05\n",
      "Epoch 692/1000\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 4.9102e-05 - val_loss: 5.2496e-05\n",
      "Epoch 693/1000\n",
      "95/95 [==============================] - 1s 6ms/step - loss: 4.9035e-05 - val_loss: 5.3902e-05\n",
      "Epoch 694/1000\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 4.9435e-05 - val_loss: 5.1897e-05\n",
      "Epoch 695/1000\n",
      "95/95 [==============================] - 1s 5ms/step - loss: 4.9015e-05 - val_loss: 5.2163e-05\n",
      "Epoch 696/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.8829e-05 - val_loss: 5.2165e-05\n",
      "Epoch 697/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.9064e-05 - val_loss: 5.2435e-05\n",
      "Epoch 698/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.9005e-05 - val_loss: 5.2454e-05\n",
      "Epoch 699/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.9034e-05 - val_loss: 5.2037e-05\n",
      "Epoch 700/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.8869e-05 - val_loss: 5.1742e-05\n",
      "Epoch 701/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.8778e-05 - val_loss: 5.1890e-05\n",
      "Epoch 702/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.8760e-05 - val_loss: 5.2179e-05\n",
      "Epoch 703/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.8767e-05 - val_loss: 5.1769e-05\n",
      "Epoch 704/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.8884e-05 - val_loss: 5.3114e-05\n",
      "Epoch 705/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.8903e-05 - val_loss: 5.3221e-05\n",
      "Epoch 706/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.8919e-05 - val_loss: 5.2520e-05\n",
      "Epoch 707/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8831e-05 - val_loss: 5.1454e-05\n",
      "Epoch 708/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8940e-05 - val_loss: 5.1737e-05\n",
      "Epoch 709/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.8727e-05 - val_loss: 5.1757e-05\n",
      "Epoch 710/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8690e-05 - val_loss: 5.2315e-05\n",
      "Epoch 711/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8597e-05 - val_loss: 5.1905e-05\n",
      "Epoch 712/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8661e-05 - val_loss: 5.2215e-05\n",
      "Epoch 713/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8836e-05 - val_loss: 5.1531e-05\n",
      "Epoch 714/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8503e-05 - val_loss: 5.1548e-05\n",
      "Epoch 715/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8720e-05 - val_loss: 5.3148e-05\n",
      "Epoch 716/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8813e-05 - val_loss: 5.1822e-05\n",
      "Epoch 717/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8532e-05 - val_loss: 5.1984e-05\n",
      "Epoch 718/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8525e-05 - val_loss: 5.1724e-05\n",
      "Epoch 719/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8472e-05 - val_loss: 5.2106e-05\n",
      "Epoch 720/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8789e-05 - val_loss: 5.1709e-05\n",
      "Epoch 721/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8433e-05 - val_loss: 5.1589e-05\n",
      "Epoch 722/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8324e-05 - val_loss: 5.1830e-05\n",
      "Epoch 723/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8724e-05 - val_loss: 5.1524e-05\n",
      "Epoch 724/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8431e-05 - val_loss: 5.1744e-05\n",
      "Epoch 725/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8471e-05 - val_loss: 5.2424e-05\n",
      "Epoch 726/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8543e-05 - val_loss: 5.1238e-05\n",
      "Epoch 727/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8345e-05 - val_loss: 5.1957e-05\n",
      "Epoch 728/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8584e-05 - val_loss: 5.1649e-05\n",
      "Epoch 729/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8367e-05 - val_loss: 5.2331e-05\n",
      "Epoch 730/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8341e-05 - val_loss: 5.1782e-05\n",
      "Epoch 731/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8258e-05 - val_loss: 5.1571e-05\n",
      "Epoch 732/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8453e-05 - val_loss: 5.1677e-05\n",
      "Epoch 733/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8176e-05 - val_loss: 5.1517e-05\n",
      "Epoch 734/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8144e-05 - val_loss: 5.1820e-05\n",
      "Epoch 735/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8252e-05 - val_loss: 5.1623e-05\n",
      "Epoch 736/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8348e-05 - val_loss: 5.1379e-05\n",
      "Epoch 737/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8088e-05 - val_loss: 5.2532e-05\n",
      "Epoch 738/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8205e-05 - val_loss: 5.2010e-05\n",
      "Epoch 739/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8185e-05 - val_loss: 5.1055e-05\n",
      "Epoch 740/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8186e-05 - val_loss: 5.1183e-05\n",
      "Epoch 741/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8385e-05 - val_loss: 5.1236e-05\n",
      "Epoch 742/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8121e-05 - val_loss: 5.1140e-05\n",
      "Epoch 743/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8093e-05 - val_loss: 5.1706e-05\n",
      "Epoch 744/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8055e-05 - val_loss: 5.1049e-05\n",
      "Epoch 745/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8349e-05 - val_loss: 5.1439e-05\n",
      "Epoch 746/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7899e-05 - val_loss: 5.1641e-05\n",
      "Epoch 747/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8055e-05 - val_loss: 5.1782e-05\n",
      "Epoch 748/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8194e-05 - val_loss: 5.1491e-05\n",
      "Epoch 749/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7977e-05 - val_loss: 5.1406e-05\n",
      "Epoch 750/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7975e-05 - val_loss: 5.2301e-05\n",
      "Epoch 751/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7888e-05 - val_loss: 5.1489e-05\n",
      "Epoch 752/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7811e-05 - val_loss: 5.2210e-05\n",
      "Epoch 753/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.8129e-05 - val_loss: 5.2556e-05\n",
      "Epoch 754/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7813e-05 - val_loss: 5.1242e-05\n",
      "Epoch 755/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7922e-05 - val_loss: 5.2990e-05\n",
      "Epoch 756/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7957e-05 - val_loss: 5.1718e-05\n",
      "Epoch 757/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7888e-05 - val_loss: 5.0849e-05\n",
      "Epoch 758/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7900e-05 - val_loss: 5.1893e-05\n",
      "Epoch 759/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7819e-05 - val_loss: 5.1281e-05\n",
      "Epoch 760/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7892e-05 - val_loss: 5.1646e-05\n",
      "Epoch 761/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7807e-05 - val_loss: 5.0786e-05\n",
      "Epoch 762/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7732e-05 - val_loss: 5.1785e-05\n",
      "Epoch 763/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7798e-05 - val_loss: 5.1480e-05\n",
      "Epoch 764/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7681e-05 - val_loss: 5.1211e-05\n",
      "Epoch 765/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7860e-05 - val_loss: 5.1345e-05\n",
      "Epoch 766/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7659e-05 - val_loss: 5.0871e-05\n",
      "Epoch 767/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7402e-05 - val_loss: 5.1047e-05\n",
      "Epoch 768/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7532e-05 - val_loss: 5.1080e-05\n",
      "Epoch 769/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7550e-05 - val_loss: 5.2310e-05\n",
      "Epoch 770/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7407e-05 - val_loss: 5.1393e-05\n",
      "Epoch 771/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7651e-05 - val_loss: 5.0980e-05\n",
      "Epoch 772/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7532e-05 - val_loss: 5.1738e-05\n",
      "Epoch 773/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7654e-05 - val_loss: 5.1547e-05\n",
      "Epoch 774/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7679e-05 - val_loss: 5.0966e-05\n",
      "Epoch 775/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7510e-05 - val_loss: 5.1359e-05\n",
      "Epoch 776/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7613e-05 - val_loss: 5.1503e-05\n",
      "Epoch 777/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7617e-05 - val_loss: 5.1783e-05\n",
      "Epoch 778/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7524e-05 - val_loss: 5.1188e-05\n",
      "Epoch 779/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7574e-05 - val_loss: 5.2176e-05\n",
      "Epoch 780/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7364e-05 - val_loss: 5.0709e-05\n",
      "Epoch 781/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7364e-05 - val_loss: 5.1083e-05\n",
      "Epoch 782/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7469e-05 - val_loss: 5.1079e-05\n",
      "Epoch 783/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7766e-05 - val_loss: 5.2183e-05\n",
      "Epoch 784/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7370e-05 - val_loss: 5.0407e-05\n",
      "Epoch 785/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7286e-05 - val_loss: 5.0584e-05\n",
      "Epoch 786/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7450e-05 - val_loss: 5.0766e-05\n",
      "Epoch 787/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7311e-05 - val_loss: 5.0670e-05\n",
      "Epoch 788/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7337e-05 - val_loss: 5.1141e-05\n",
      "Epoch 789/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7111e-05 - val_loss: 5.0901e-05\n",
      "Epoch 790/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7265e-05 - val_loss: 5.1241e-05\n",
      "Epoch 791/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7509e-05 - val_loss: 5.0536e-05\n",
      "Epoch 792/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7178e-05 - val_loss: 5.1381e-05\n",
      "Epoch 793/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7262e-05 - val_loss: 5.1444e-05\n",
      "Epoch 794/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7265e-05 - val_loss: 5.1134e-05\n",
      "Epoch 795/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7125e-05 - val_loss: 5.0728e-05\n",
      "Epoch 796/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7172e-05 - val_loss: 5.0744e-05\n",
      "Epoch 797/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7300e-05 - val_loss: 5.0194e-05\n",
      "Epoch 798/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7215e-05 - val_loss: 5.0879e-05\n",
      "Epoch 799/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7175e-05 - val_loss: 5.1280e-05\n",
      "Epoch 800/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7151e-05 - val_loss: 5.0608e-05\n",
      "Epoch 801/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7324e-05 - val_loss: 5.0749e-05\n",
      "Epoch 802/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6824e-05 - val_loss: 5.1063e-05\n",
      "Epoch 803/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7278e-05 - val_loss: 5.0443e-05\n",
      "Epoch 804/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6824e-05 - val_loss: 5.0559e-05\n",
      "Epoch 805/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7023e-05 - val_loss: 5.0800e-05\n",
      "Epoch 806/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6972e-05 - val_loss: 5.0547e-05\n",
      "Epoch 807/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6960e-05 - val_loss: 5.0228e-05\n",
      "Epoch 808/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6935e-05 - val_loss: 5.1499e-05\n",
      "Epoch 809/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7087e-05 - val_loss: 5.1403e-05\n",
      "Epoch 810/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7171e-05 - val_loss: 5.1970e-05\n",
      "Epoch 811/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6983e-05 - val_loss: 5.0284e-05\n",
      "Epoch 812/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6886e-05 - val_loss: 5.0976e-05\n",
      "Epoch 813/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6929e-05 - val_loss: 5.1088e-05\n",
      "Epoch 814/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6991e-05 - val_loss: 5.1135e-05\n",
      "Epoch 815/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7038e-05 - val_loss: 5.1629e-05\n",
      "Epoch 816/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6952e-05 - val_loss: 5.0627e-05\n",
      "Epoch 817/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 4ms/step - loss: 4.7098e-05 - val_loss: 5.0803e-05\n",
      "Epoch 818/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6996e-05 - val_loss: 5.0488e-05\n",
      "Epoch 819/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6770e-05 - val_loss: 5.0968e-05\n",
      "Epoch 820/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6461e-05 - val_loss: 5.0374e-05\n",
      "Epoch 821/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6748e-05 - val_loss: 5.0723e-05\n",
      "Epoch 822/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6998e-05 - val_loss: 5.0386e-05\n",
      "Epoch 823/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6586e-05 - val_loss: 5.0548e-05\n",
      "Epoch 824/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6681e-05 - val_loss: 5.0052e-05\n",
      "Epoch 825/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6834e-05 - val_loss: 5.0513e-05\n",
      "Epoch 826/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6694e-05 - val_loss: 5.0362e-05\n",
      "Epoch 827/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6601e-05 - val_loss: 5.0475e-05\n",
      "Epoch 828/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6665e-05 - val_loss: 5.0704e-05\n",
      "Epoch 829/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6695e-05 - val_loss: 5.0714e-05\n",
      "Epoch 830/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6764e-05 - val_loss: 5.0603e-05\n",
      "Epoch 831/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6551e-05 - val_loss: 5.0398e-05\n",
      "Epoch 832/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6699e-05 - val_loss: 5.0683e-05\n",
      "Epoch 833/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6469e-05 - val_loss: 5.0193e-05\n",
      "Epoch 834/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6631e-05 - val_loss: 5.0721e-05\n",
      "Epoch 835/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6672e-05 - val_loss: 5.0284e-05\n",
      "Epoch 836/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6375e-05 - val_loss: 5.0433e-05\n",
      "Epoch 837/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6826e-05 - val_loss: 5.0119e-05\n",
      "Epoch 838/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6604e-05 - val_loss: 5.0384e-05\n",
      "Epoch 839/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6725e-05 - val_loss: 5.1035e-05\n",
      "Epoch 840/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6529e-05 - val_loss: 4.9912e-05\n",
      "Epoch 841/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6459e-05 - val_loss: 5.0126e-05\n",
      "Epoch 842/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6558e-05 - val_loss: 5.1093e-05\n",
      "Epoch 843/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6583e-05 - val_loss: 5.1225e-05\n",
      "Epoch 844/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6427e-05 - val_loss: 5.0580e-05\n",
      "Epoch 845/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6386e-05 - val_loss: 5.0267e-05\n",
      "Epoch 846/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6311e-05 - val_loss: 5.0310e-05\n",
      "Epoch 847/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6639e-05 - val_loss: 5.0324e-05\n",
      "Epoch 848/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6401e-05 - val_loss: 5.0011e-05\n",
      "Epoch 849/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6455e-05 - val_loss: 5.0202e-05\n",
      "Epoch 850/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6262e-05 - val_loss: 5.0840e-05\n",
      "Epoch 851/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6219e-05 - val_loss: 5.0327e-05\n",
      "Epoch 852/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6351e-05 - val_loss: 5.1456e-05\n",
      "Epoch 853/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6398e-05 - val_loss: 5.0105e-05\n",
      "Epoch 854/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6548e-05 - val_loss: 5.0418e-05\n",
      "Epoch 855/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6269e-05 - val_loss: 5.0399e-05\n",
      "Epoch 856/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6170e-05 - val_loss: 5.1131e-05\n",
      "Epoch 857/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6392e-05 - val_loss: 5.0474e-05\n",
      "Epoch 858/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6220e-05 - val_loss: 5.0348e-05\n",
      "Epoch 859/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6162e-05 - val_loss: 5.0339e-05\n",
      "Epoch 860/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6433e-05 - val_loss: 5.0353e-05\n",
      "Epoch 861/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6340e-05 - val_loss: 5.1190e-05\n",
      "Epoch 862/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6355e-05 - val_loss: 5.0722e-05\n",
      "Epoch 863/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6345e-05 - val_loss: 5.0722e-05\n",
      "Epoch 864/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6243e-05 - val_loss: 5.0320e-05\n",
      "Epoch 865/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6153e-05 - val_loss: 4.9801e-05\n",
      "Epoch 866/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6059e-05 - val_loss: 5.0262e-05\n",
      "Epoch 867/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5963e-05 - val_loss: 5.0466e-05\n",
      "Epoch 868/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6112e-05 - val_loss: 4.9922e-05\n",
      "Epoch 869/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6032e-05 - val_loss: 4.9795e-05\n",
      "Epoch 870/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6205e-05 - val_loss: 5.0502e-05\n",
      "Epoch 871/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6212e-05 - val_loss: 5.0937e-05\n",
      "Epoch 872/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6012e-05 - val_loss: 5.0014e-05\n",
      "Epoch 873/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6078e-05 - val_loss: 5.0642e-05\n",
      "Epoch 874/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6082e-05 - val_loss: 5.0437e-05\n",
      "Epoch 875/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6311e-05 - val_loss: 5.0806e-05\n",
      "Epoch 876/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6130e-05 - val_loss: 4.9862e-05\n",
      "Epoch 877/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6116e-05 - val_loss: 5.0610e-05\n",
      "Epoch 878/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5949e-05 - val_loss: 5.0035e-05\n",
      "Epoch 879/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5699e-05 - val_loss: 4.9780e-05\n",
      "Epoch 880/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6077e-05 - val_loss: 5.0081e-05\n",
      "Epoch 881/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6038e-05 - val_loss: 5.1075e-05\n",
      "Epoch 882/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5999e-05 - val_loss: 5.0297e-05\n",
      "Epoch 883/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5752e-05 - val_loss: 4.9914e-05\n",
      "Epoch 884/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5647e-05 - val_loss: 4.9535e-05\n",
      "Epoch 885/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5867e-05 - val_loss: 5.0122e-05\n",
      "Epoch 886/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5906e-05 - val_loss: 5.0536e-05\n",
      "Epoch 887/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.6088e-05 - val_loss: 4.9659e-05\n",
      "Epoch 888/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5766e-05 - val_loss: 4.9758e-05\n",
      "Epoch 889/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.5907e-05 - val_loss: 5.0984e-05\n",
      "Epoch 890/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.5778e-05 - val_loss: 4.9880e-05\n",
      "Epoch 891/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 5ms/step - loss: 4.5768e-05 - val_loss: 4.9826e-05\n",
      "Epoch 892/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.5716e-05 - val_loss: 4.9812e-05\n",
      "Epoch 893/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.5846e-05 - val_loss: 4.9831e-05\n",
      "Epoch 894/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.5885e-05 - val_loss: 4.9801e-05\n",
      "Epoch 895/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.5801e-05 - val_loss: 4.9721e-05\n",
      "Epoch 896/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5555e-05 - val_loss: 5.0503e-05\n",
      "Epoch 897/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5773e-05 - val_loss: 5.0127e-05\n",
      "Epoch 898/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5546e-05 - val_loss: 5.0388e-05\n",
      "Epoch 899/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5789e-05 - val_loss: 4.9868e-05\n",
      "Epoch 900/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5777e-05 - val_loss: 5.0024e-05\n",
      "Epoch 901/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5469e-05 - val_loss: 4.9927e-05\n",
      "Epoch 902/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5520e-05 - val_loss: 4.9820e-05\n",
      "Epoch 903/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5589e-05 - val_loss: 4.9747e-05\n",
      "Epoch 904/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5633e-05 - val_loss: 5.0367e-05\n",
      "Epoch 905/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5583e-05 - val_loss: 5.0269e-05\n",
      "Epoch 906/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5736e-05 - val_loss: 5.0401e-05\n",
      "Epoch 907/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5957e-05 - val_loss: 4.9452e-05\n",
      "Epoch 908/1000\n",
      "95/95 [==============================] - 0s 5ms/step - loss: 4.5568e-05 - val_loss: 4.9884e-05\n",
      "Epoch 909/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5568e-05 - val_loss: 4.9962e-05\n",
      "Epoch 910/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5647e-05 - val_loss: 4.9602e-05\n",
      "Epoch 911/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5759e-05 - val_loss: 4.9860e-05\n",
      "Epoch 912/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5384e-05 - val_loss: 4.9620e-05\n",
      "Epoch 913/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5382e-05 - val_loss: 5.0679e-05\n",
      "Epoch 914/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5580e-05 - val_loss: 4.9531e-05\n",
      "Epoch 915/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5578e-05 - val_loss: 5.0603e-05\n",
      "Epoch 916/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5632e-05 - val_loss: 4.9323e-05\n",
      "Epoch 917/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5541e-05 - val_loss: 5.0248e-05\n",
      "Epoch 918/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5631e-05 - val_loss: 4.9293e-05\n",
      "Epoch 919/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5321e-05 - val_loss: 5.0241e-05\n",
      "Epoch 920/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5296e-05 - val_loss: 5.0605e-05\n",
      "Epoch 921/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5507e-05 - val_loss: 5.0194e-05\n",
      "Epoch 922/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5394e-05 - val_loss: 5.0209e-05\n",
      "Epoch 923/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5337e-05 - val_loss: 4.9573e-05\n",
      "Epoch 924/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5412e-05 - val_loss: 5.0103e-05\n",
      "Epoch 925/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5391e-05 - val_loss: 4.9636e-05\n",
      "Epoch 926/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5339e-05 - val_loss: 5.0458e-05\n",
      "Epoch 927/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5348e-05 - val_loss: 4.9918e-05\n",
      "Epoch 928/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5588e-05 - val_loss: 5.0044e-05\n",
      "Epoch 929/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5296e-05 - val_loss: 4.9196e-05\n",
      "Epoch 930/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5381e-05 - val_loss: 4.9411e-05\n",
      "Epoch 931/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5368e-05 - val_loss: 4.9461e-05\n",
      "Epoch 932/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5364e-05 - val_loss: 5.0303e-05\n",
      "Epoch 933/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5254e-05 - val_loss: 4.9401e-05\n",
      "Epoch 934/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5118e-05 - val_loss: 4.9348e-05\n",
      "Epoch 935/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5044e-05 - val_loss: 4.9399e-05\n",
      "Epoch 936/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5386e-05 - val_loss: 4.9460e-05\n",
      "Epoch 937/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5222e-05 - val_loss: 5.0161e-05\n",
      "Epoch 938/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5200e-05 - val_loss: 4.9471e-05\n",
      "Epoch 939/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5260e-05 - val_loss: 4.9316e-05\n",
      "Epoch 940/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5089e-05 - val_loss: 4.9549e-05\n",
      "Epoch 941/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5263e-05 - val_loss: 4.9562e-05\n",
      "Epoch 942/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5066e-05 - val_loss: 5.0736e-05\n",
      "Epoch 943/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5410e-05 - val_loss: 4.9288e-05\n",
      "Epoch 944/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5092e-05 - val_loss: 4.9733e-05\n",
      "Epoch 945/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5093e-05 - val_loss: 4.9626e-05\n",
      "Epoch 946/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4984e-05 - val_loss: 4.9818e-05\n",
      "Epoch 947/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5240e-05 - val_loss: 4.9598e-05\n",
      "Epoch 948/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5201e-05 - val_loss: 4.9280e-05\n",
      "Epoch 949/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4864e-05 - val_loss: 4.9287e-05\n",
      "Epoch 950/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4971e-05 - val_loss: 4.9260e-05\n",
      "Epoch 951/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5146e-05 - val_loss: 4.9838e-05\n",
      "Epoch 952/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5139e-05 - val_loss: 4.9798e-05\n",
      "Epoch 953/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4993e-05 - val_loss: 4.9661e-05\n",
      "Epoch 954/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5261e-05 - val_loss: 4.9507e-05\n",
      "Epoch 955/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4926e-05 - val_loss: 4.9208e-05\n",
      "Epoch 956/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4854e-05 - val_loss: 4.9616e-05\n",
      "Epoch 957/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4848e-05 - val_loss: 4.9111e-05\n",
      "Epoch 958/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4822e-05 - val_loss: 4.9723e-05\n",
      "Epoch 959/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4952e-05 - val_loss: 4.9565e-05\n",
      "Epoch 960/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4996e-05 - val_loss: 4.9899e-05\n",
      "Epoch 961/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4961e-05 - val_loss: 4.9117e-05\n",
      "Epoch 962/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4982e-05 - val_loss: 4.9649e-05\n",
      "Epoch 963/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4824e-05 - val_loss: 4.9192e-05\n",
      "Epoch 964/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.5226e-05 - val_loss: 5.0364e-05\n",
      "Epoch 965/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4854e-05 - val_loss: 5.1484e-05\n",
      "Epoch 966/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4862e-05 - val_loss: 4.9480e-05\n",
      "Epoch 967/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4705e-05 - val_loss: 4.9010e-05\n",
      "Epoch 968/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4693e-05 - val_loss: 4.9053e-05\n",
      "Epoch 969/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4745e-05 - val_loss: 4.8940e-05\n",
      "Epoch 970/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4675e-05 - val_loss: 4.9557e-05\n",
      "Epoch 971/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4775e-05 - val_loss: 4.8775e-05\n",
      "Epoch 972/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4698e-05 - val_loss: 4.9916e-05\n",
      "Epoch 973/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4849e-05 - val_loss: 4.9431e-05\n",
      "Epoch 974/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4795e-05 - val_loss: 4.9435e-05\n",
      "Epoch 975/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4826e-05 - val_loss: 4.9625e-05\n",
      "Epoch 976/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4684e-05 - val_loss: 4.9319e-05\n",
      "Epoch 977/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4601e-05 - val_loss: 4.9184e-05\n",
      "Epoch 978/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4752e-05 - val_loss: 4.8868e-05\n",
      "Epoch 979/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4669e-05 - val_loss: 4.8946e-05\n",
      "Epoch 980/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4780e-05 - val_loss: 4.9273e-05\n",
      "Epoch 981/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4810e-05 - val_loss: 4.9200e-05\n",
      "Epoch 982/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4728e-05 - val_loss: 4.9512e-05\n",
      "Epoch 983/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4616e-05 - val_loss: 4.9206e-05\n",
      "Epoch 984/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4964e-05 - val_loss: 4.9960e-05\n",
      "Epoch 985/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4539e-05 - val_loss: 4.9625e-05\n",
      "Epoch 986/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4709e-05 - val_loss: 4.9726e-05\n",
      "Epoch 987/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4470e-05 - val_loss: 4.9224e-05\n",
      "Epoch 988/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4515e-05 - val_loss: 4.9702e-05\n",
      "Epoch 989/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4657e-05 - val_loss: 4.9501e-05\n",
      "Epoch 990/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4408e-05 - val_loss: 4.9579e-05\n",
      "Epoch 991/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4494e-05 - val_loss: 4.9686e-05\n",
      "Epoch 992/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4547e-05 - val_loss: 4.9405e-05\n",
      "Epoch 993/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4675e-05 - val_loss: 4.9216e-05\n",
      "Epoch 994/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4377e-05 - val_loss: 4.8672e-05\n",
      "Epoch 995/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4618e-05 - val_loss: 4.9320e-05\n",
      "Epoch 996/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4412e-05 - val_loss: 4.9511e-05\n",
      "Epoch 997/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4640e-05 - val_loss: 4.9174e-05\n",
      "Epoch 998/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4700e-05 - val_loss: 4.9991e-05\n",
      "Epoch 999/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4545e-05 - val_loss: 4.9912e-05\n",
      "Epoch 1000/1000\n",
      "95/95 [==============================] - 0s 4ms/step - loss: 4.4667e-05 - val_loss: 4.9360e-05\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.losses import Huber\n",
    "\n",
    "#Train Learning Model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001), loss='mse') #0.0001\n",
    "#model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001), loss=Huber(delta=3.0))\n",
    "\n",
    "\n",
    "#history = model.fit(x_train, y_train, epochs = 50000, validation_split=0.0, batch_size = x_train.shape[0])\n",
    "#history = model.fit(x_train, y_train, epochs = 3000, validation_split=0.0, batch_size = 1280) #1280\n",
    "history = model.fit(x = x_train, y = y_train, epochs = 1000, batch_size = 1280, validation_data = (x_valid, y_valid)) #1280, 1000 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot Training Progree\n",
    "plt.plot(history.history['loss'], 'r', label='loss')\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(history.history['val_loss'], 'b', label='val_loss') if 'val_loss' in history.history else None\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jiayu/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /home/jiayu/Desktop/MLP_DataSet/Rubbles//ML_Models/NN_Model_Valid_OriginalForm/assets\n"
     ]
    }
   ],
   "source": [
    "#Save Trained Model\n",
    "MLmodel_name = \"NN_Model_Valid_\" + trainingset[\"PreProcessMode\"]\n",
    "model.save(ML_Model_Path + MLmodel_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save DataSet Setttings\n",
    "datasetSettings = {\"Shift_World_Frame_Type\":trainingset[\"Shift_World_Frame_Type\"],\n",
    "                   \"VectorScaleFactor\":trainingset[\"VectorScaleFactor\"],\n",
    "                   \"NumPreviewSteps\":trainingset[\"NumPreviewSteps\"],\n",
    "                   \"Contact_Representation_Type\":trainingset[\"Contact_Representation_Type\"],\n",
    "                   \"TrainingLoss\":history.history['loss']}\n",
    "#Validation loss\n",
    "datasetSettings[\"ValidationLoss\"] = history.history['val_loss'] if 'val_loss' in history.history else None\n",
    "\n",
    "#ProProcess\n",
    "datasetSettings[\"PreProcessMode\"] = trainingset[\"PreProcessMode\"]\n",
    "datasetSettings[\"Scaler_X\"] = trainingset[\"Scaler_X\"]\n",
    "datasetSettings[\"Scaler_Y\"] = trainingset[\"Scaler_Y\"]\n",
    "\n",
    "#Dump File\n",
    "pickle.dump(datasetSettings, open(ML_Model_Path + MLmodel_name+ '/datasetSettings' +'.p', \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.46418906e-01 -8.49456480e-02  7.99586336e-01  1.48521400e-01\n",
      "  1.07545024e-01 -1.11004699e-04  1.54833590e-08 -1.93962072e-09\n",
      " -2.29540166e-09 -2.79980848e-01 -1.94277001e-01  4.15072207e-02\n",
      "  0.00000000e+00  4.24969733e-01  8.65458148e-01  0.00000000e+00\n",
      " -1.50030267e-01  8.65458148e-01  0.00000000e+00 -1.50030267e-01\n",
      " -1.34541852e-01  0.00000000e+00  4.24969733e-01 -1.34541852e-01\n",
      "  0.00000000e+00 -1.50030267e-01 -1.34541852e-01  4.71389217e-02\n",
      " -7.25030267e-01 -1.34541852e-01  4.71389217e-02 -7.25030267e-01\n",
      " -1.13454185e+00 -4.71389217e-02 -1.50030267e-01 -1.13454185e+00\n",
      " -4.71389217e-02  4.24969733e-01 -1.34541852e-01 -5.17224150e-02\n",
      " -1.50030267e-01 -1.34541852e-01  5.17224150e-02 -1.50030267e-01\n",
      " -1.13454185e+00  5.17224150e-02  4.24969733e-01 -1.13454185e+00\n",
      " -5.17224150e-02  9.99969733e-01  8.65458148e-01 -8.32569316e-02\n",
      "  4.24969733e-01  8.65458148e-01 -8.32569316e-02  4.24969733e-01\n",
      " -1.34541852e-01  8.32569316e-02  9.99969733e-01 -1.34541852e-01\n",
      "  8.32569316e-02  9.99969733e-01 -1.34541852e-01  8.84043086e-02\n",
      "  4.24969733e-01 -1.34541852e-01  8.84043086e-02  4.24969733e-01\n",
      " -1.13454185e+00 -8.84043086e-02  9.99969733e-01 -1.13454185e+00\n",
      " -8.84043086e-02  1.57496973e+00  8.65458148e-01 -3.52500611e-02\n",
      "  9.99969733e-01  8.65458148e-01  3.52500611e-02  9.99969733e-01\n",
      " -1.34541852e-01  3.52500611e-02  1.57496973e+00 -1.34541852e-01\n",
      " -3.52500611e-02]\n",
      "Data Kept Original Form, But need to scale back to meters\n",
      "predicted result: \n",
      " [[ 1.4578664e-01 -1.2820500e-01  7.7656484e-01  1.5381481e-01\n",
      "  -1.3302626e-01 -1.8507801e-02 -7.6271174e-04 -1.8798013e-04\n",
      "   1.7076451e-04  7.1761590e-01  8.8591546e-01]]\n",
      "true value: \n",
      " [ 1.34344301e-01 -1.24537780e-01  7.79258666e-01  1.33611663e-01\n",
      " -1.32174515e-01 -1.82662181e-02 -1.56202368e-08  1.64473400e-09\n",
      "  1.51954990e-09  7.00715334e-01  9.01704617e-01]\n",
      "diff: \n",
      " [[0.01144234 0.00366722 0.00269383 0.02020314 0.00085174 0.00024158\n",
      "  0.0007627  0.00018798 0.00017076 0.01690057 0.01578916]]\n"
     ]
    }
   ],
   "source": [
    "#Show Prediction Result for Training\n",
    "from sklearn import preprocessing\n",
    "\n",
    "datapoint_num = 3\n",
    "y_pred_temp = model.predict(np.array([x_train[datapoint_num]]))\n",
    "\n",
    "print(x_train[datapoint_num])\n",
    "\n",
    "#Recover to original format\n",
    "if trainingset[\"PreProcessMode\"] == \"OriginalForm\":\n",
    "    print(\"Data Kept Original Form, But need to scale back to meters\")\n",
    "    y_pred_originalform = y_pred_temp/trainingset[\"VectorScaleFactor\"]\n",
    "    y_true_originalform = y_train[datapoint_num]/trainingset[\"VectorScaleFactor\"]\n",
    "elif trainingset[\"PreProcessMode\"] == \"Standarization\" or trainingset[\"PreProcessMode\"] == \"MaxAbs\":\n",
    "    y_pred_originalform = dataset[\"Scaler_Y\"].inverse_transform(y_pred_temp)\n",
    "    y_true_originalform = dataset[\"Scaler_Y\"].inverse_transform(np.array([y_train[datapoint_num]]))\n",
    "else:\n",
    "    raise Exception(\"Unknow Pre Process Mode\")\n",
    "\n",
    "\n",
    "print(\"predicted result: \\n\",y_pred_originalform)\n",
    "print(\"true value: \\n\",y_true_originalform)\n",
    "print(\"diff: \\n\", np.absolute(y_pred_originalform - y_true_originalform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Kept Original Form, But need to scale back to meters\n",
      "[0.23600886 0.23614269 0.23642108 0.23642461 0.23643673 0.23646535\n",
      " 0.23654178 0.23663527 0.23671324 0.23682972 0.23697776 0.23714085\n",
      " 0.23728726 0.23738933 0.23798134 0.23800822 0.23801365 0.23813657\n",
      " 0.23830015 0.23832691 0.23835243 0.23869546 0.23900303 0.23951152\n",
      " 0.23978041 0.23985697 0.23997326 0.24003007 0.24011755 0.24013782\n",
      " 0.24030981 0.24056982 0.24076874 0.24090193 0.24096934 0.24111293\n",
      " 0.2411354  0.24123707 0.241253   0.24138815 0.24182713 0.24184276\n",
      " 0.2419344  0.24194565 0.24203428 0.24204318 0.24227741 0.24240201\n",
      " 0.24245299 0.24255158 0.24319565 0.24326344 0.24370576 0.2440157\n",
      " 0.24415845 0.24436414 0.24449356 0.24458738 0.24463679 0.24468766\n",
      " 0.24482775 0.24492956 0.24499547 0.24499579 0.24518743 0.24519539\n",
      " 0.24528161 0.2453702  0.24538149 0.24605803 0.2461513  0.24619454\n",
      " 0.24626882 0.24650771 0.24687656 0.24735649 0.24739374 0.24816161\n",
      " 0.24826022 0.24897721 0.24899463 0.24903516 0.24906088 0.24920249\n",
      " 0.24939206 0.24987004 0.24997321 0.24998693 0.25031175 0.25032398\n",
      " 0.25057714 0.25059962 0.25077912 0.25084982 0.25093459 0.25102968\n",
      " 0.25110212 0.25112535 0.25135238 0.2514105  0.25146388 0.25149215\n",
      " 0.25150996 0.25165791 0.25167226 0.25204754 0.25217197 0.25217743\n",
      " 0.25231924 0.25235364 0.25259848 0.25303203 0.2530456  0.25305763\n",
      " 0.25315874 0.25363464 0.2536996  0.25396196 0.25397757 0.25412274\n",
      " 0.25414429 0.25419243 0.25434388 0.25434655 0.25436425 0.25442465\n",
      " 0.25492874 0.25517665 0.25551027 0.25560937 0.25579523 0.25629579\n",
      " 0.25643697 0.25656162 0.25663055 0.25666477 0.25684799 0.25701644\n",
      " 0.25711623 0.25723235 0.25724295 0.25736897 0.25743053 0.25746544\n",
      " 0.25781401 0.25781794 0.25782408 0.25785021 0.25823626 0.25834495\n",
      " 0.25852634 0.2587363  0.25876039 0.25924278 0.25941327 0.25962877\n",
      " 0.25979375 0.25980771 0.25987356 0.26013412 0.2601965  0.26036505\n",
      " 0.26049452 0.26053303 0.26062548 0.26087495 0.2610927  0.26109511\n",
      " 0.26155754 0.26171041 0.26200885 0.26239397 0.26249427 0.26249981\n",
      " 0.26267496 0.26341219 0.26357103 0.26364426 0.26369143 0.26376134\n",
      " 0.26499228 0.26543164 0.26576757 0.2658278  0.26610999 0.26673148\n",
      " 0.26700264 0.26705967 0.26744042 0.2675217  0.26761939 0.26771601\n",
      " 0.267941   0.26815734 0.26822479 0.26842981 0.26869901 0.26891218\n",
      " 0.26933167 0.26936311 0.26949852 0.26987491 0.26995171 0.27010219\n",
      " 0.27039999 0.27084217 0.27086952 0.27094936 0.27109851 0.27156021\n",
      " 0.27162922 0.272225   0.27225585 0.27229338 0.2723131  0.2727172\n",
      " 0.27286243 0.27289883 0.27343551 0.2741955  0.27442698 0.27453575\n",
      " 0.27474716 0.27508296 0.27539784 0.27574834 0.27584054 0.27595306\n",
      " 0.27638958 0.2764995  0.27721936 0.27735952 0.27740094 0.27780067\n",
      " 0.27809018 0.27811706 0.27841926 0.27857977 0.27858142 0.27883637\n",
      " 0.27900268 0.27938014 0.27942831 0.27953398 0.27962636 0.27989794\n",
      " 0.27995723 0.28007195 0.2806679  0.28096486 0.28151882 0.28157583\n",
      " 0.28203628 0.28212787 0.28289282 0.28398303 0.28413801 0.28477637\n",
      " 0.28569848 0.2866715  0.28687529 0.28692396 0.28749562 0.2877924\n",
      " 0.28806996 0.28812739 0.28831612 0.2883805  0.28862203 0.28881968\n",
      " 0.29061376 0.29070561 0.29087206 0.29130593 0.29255135 0.29257595\n",
      " 0.29286318 0.29327369 0.29444985 0.29453847 0.29456917 0.2952714\n",
      " 0.2959139  0.29757806 0.29930842 0.30183406 0.30321941 0.30420424\n",
      " 0.30540709 0.30916979 0.30990896 0.31000658 0.31132342 0.3119005\n",
      " 0.31240046 0.31377768 0.31422173 0.314994   0.31933359 0.32216327]\n",
      "Error Mean:  0.023869487982499105\n",
      "Error Std 0.020059579680026432\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Error Stat with Training Set\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred_train = model.predict(x_train)\n",
    "\n",
    "\n",
    "if trainingset[\"PreProcessMode\"] == \"OriginalForm\":\n",
    "    print(\"Data Kept Original Form, But need to scale back to meters\")\n",
    "    y_pred_train_originalform = y_pred_train/trainingset[\"VectorScaleFactor\"]\n",
    "    y_true_train_originalform = y_train/trainingset[\"VectorScaleFactor\"]\n",
    "elif trainingset[\"PreProcessMode\"] == \"Standarization\" or trainingset[\"PreProcessMode\"] == \"MaxAbs\":\n",
    "    print(\"PreProcessing of: \", trainingset[\"PreProcessMode\"])\n",
    "    y_pred_train_originalform = trainingset[\"Scaler_Y\"].inverse_transform(y_pred_train)\n",
    "    y_true_train_originalform = trainingset[\"Scaler_Y\"].inverse_transform(y_train)\n",
    "else:\n",
    "    raise Exception(\"Unknow Pre Process Mode\")\n",
    "\n",
    "#Compute Error\n",
    "err = np.linalg.norm(y_true_train_originalform-y_pred_train_originalform, axis=1)\n",
    "\n",
    "#Plot Histogram\n",
    "fig=plt.figure();   ax = fig.gca()\n",
    "plt.hist(err, bins=50, density = True, range = (0.0, 0.375))\n",
    "ax.set_xlabel(\"Normalised Error\")\n",
    "ax.set_xlim([-0.025,0.375])\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "ax.set_ylim([-1,50])\n",
    "\n",
    "#### Sort the error\n",
    "\n",
    "err_sorted = np.sort(err)\n",
    "print(err_sorted[-300:])  # print the 100 biggest error\n",
    "\n",
    "print(\"Error Mean: \", err_sorted.mean())\n",
    "print(\"Error Std\", err_sorted.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Kept Original Form, But need to scale back to meters\n",
      "[0.0033313  0.00346541 0.00353714 ... 0.31839441 0.31935815 0.35135725]\n",
      "Error Mean:  0.025052085534083193\n",
      "Error Std 0.02140831077007152\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Error Stat with Validation Set\n",
    "\n",
    "y_pred_valid = model.predict(x_valid)\n",
    "\n",
    "\n",
    "if validationset[\"PreProcessMode\"] == \"OriginalForm\":\n",
    "    print(\"Data Kept Original Form, But need to scale back to meters\")\n",
    "    y_pred_valid_originalform = y_pred_valid/validationset[\"VectorScaleFactor\"]\n",
    "    y_true_valid_originalform = y_valid/validationset[\"VectorScaleFactor\"]\n",
    "elif validationset[\"PreProcessMode\"] == \"Standarization\" or validationset[\"PreProcessMode\"] == \"MaxAbs\":\n",
    "    print(\"PreProcessing of: \", validationset[\"PreProcessMode\"])\n",
    "    y_pred_valid_originalform = validationset[\"Scaler_Y\"].inverse_transform(y_pred_valid)\n",
    "    y_true_valid_originalform = validationset[\"Scaler_Y\"].inverse_transform(y_valid)\n",
    "else:\n",
    "    raise Exception(\"Unknow Pre Process Mode\")\n",
    "\n",
    "#Compute Error\n",
    "err = np.linalg.norm(y_true_valid_originalform-y_pred_valid_originalform, axis=1)\n",
    "\n",
    "#Plot Histogram\n",
    "fig=plt.figure();   ax = fig.gca()\n",
    "plt.hist(err, bins=50, density = True, range = (0.0, 0.375))\n",
    "ax.set_xlabel(\"Normalised Error\")\n",
    "ax.set_xlim([-0.025,0.375])\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "ax.set_ylim([-1,50])\n",
    "\n",
    "#### Sort the error\n",
    "\n",
    "err_sorted = np.sort(err)\n",
    "print(err_sorted)  # print the 100 biggest error\n",
    "\n",
    "print(\"Error Mean: \", err_sorted.mean())\n",
    "print(\"Error Std\", err_sorted.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Kept Original Form, But need to scale back to meters\n",
      "[0.00184869 0.00228481 0.00279936 ... 0.32147956 0.32973017 0.32990142]\n",
      "Error Mean:  0.023198824589737117\n",
      "Error Std 0.021627270312226707\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Error Stat with Test Set\n",
    "\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "if testset[\"PreProcessMode\"] == \"OriginalForm\":\n",
    "    print(\"Data Kept Original Form, But need to scale back to meters\")\n",
    "    y_pred_test_originalform = y_pred_test/testset[\"VectorScaleFactor\"]\n",
    "    y_true_test_originalform = y_test/testset[\"VectorScaleFactor\"]\n",
    "elif testset[\"PreProcessMode\"] == \"Standarization\" or testset[\"PreProcessMode\"] == \"MaxAbs\":\n",
    "    print(\"PreProcessing of: \", validationset[\"PreProcessMode\"])\n",
    "    y_pred_test_originalform = validationset[\"Scaler_Y\"].inverse_transform(y_pred_test)\n",
    "    y_true_test_originalform = validationset[\"Scaler_Y\"].inverse_transform(y_test)\n",
    "else:\n",
    "    raise Exception(\"Unknow Pre Process Mode\")\n",
    "\n",
    "#Compute Error\n",
    "err = np.linalg.norm(y_pred_test_originalform-y_true_test_originalform, axis=1)\n",
    "\n",
    "#Plot Histogram\n",
    "fig=plt.figure();   ax = fig.gca()\n",
    "plt.hist(err, bins=50, density = True, range = (0.0, 0.375))\n",
    "ax.set_xlabel(\"Normalised Error\")\n",
    "ax.set_xlim([-0.025,0.375])\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "ax.set_ylim([-1,50])\n",
    "\n",
    "#### Sort the error\n",
    "\n",
    "err_sorted = np.sort(err)\n",
    "print(err_sorted)  # print the 100 biggest error\n",
    "\n",
    "print(\"Error Mean: \", err_sorted.mean())\n",
    "print(\"Error Std\", err_sorted.std())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a501000252d127e7c27d83f75df0a57bca228f59033b739034a7cde4260d0152"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
