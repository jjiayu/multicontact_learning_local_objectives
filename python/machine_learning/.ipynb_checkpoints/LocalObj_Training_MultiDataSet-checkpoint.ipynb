{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double check the Path for storing trajectories is correct\n"
     ]
    }
   ],
   "source": [
    "#Import Packages\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from multicontact_learning_local_objectives.python.machine_learning.ml_utils import *\n",
    "import matplotlib.pyplot as plt #Matplotlib\n",
    "import shutil\n",
    "\n",
    "print(\"Double check the Path for storing trajectories is correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Check we provide the Correct Traj Path: \n",
      " /media/jiayu/Seagate/Rubbles_AddVarSteps_1to2StepbeforeFail_RemovebyClip/\n"
     ]
    }
   ],
   "source": [
    "#Define Path for Storing Trajectories\n",
    "#Collect Data Points Path\n",
    "#workingDirectory = \"/home/jiayu/Desktop/multicontact_learning_local_objectives/data/large_slope_flat_patches/\"\n",
    "#workingDirectory = \"/home/jiayu/Desktop/MLP_DataSet/Rubbles_DaggerExact/\"\n",
    "#workingDirectory = \"/home/jiayu/Desktop/MLP_DataSet/Rubbles_Add2Steps\"\n",
    "#workingDirectory = \"/media/jiayu/Seagate/Rubbles_Add2Step_KeepOutlier\"\n",
    "#workingDirectory = \"/media/jiayu/Seagate/Rubbles_AddVarSteps_1to2StepbeforeFail_RemovebyClip/\"\n",
    "#workingDirectory = \"/media/jiayu/Seagate/Rubbles_Add2Steps_1StepbeforeFail_RemovebyClip/\"\n",
    "workingDirectory = \"/media/jiayu/Seagate/LargeSlope_Angle_23_X_negative/\"\n",
    "\n",
    "#NOTE: need to have \"/\" at the end\n",
    "print(\"Double Check we provide the Correct Traj Path: \\n\", workingDirectory)\n",
    "\n",
    "#Define dataset folder\n",
    "TrainingSetPath = [workingDirectory + \"/DataSet/\"+\"TrainingSet_Initial\",\n",
    "                   workingDirectory + \"/DataSet/\"+\"TrainingAugVarSteps_1StepbeforeFail_1Time_RemovebyClip_SmallThre\",\n",
    "                   workingDirectory + \"/DataSet/\"+\"TrainingAugVarSteps_2StepbeforeFail_1Time_RemovebyClip_SmallThre\",\n",
    "                   workingDirectory + \"/DataSet/\"+\"TrainingAugVarSteps_1StepbeforeFail_2Time_RemovebyClip_SmallThre\",\n",
    "                   workingDirectory + \"/DataSet/\"+\"TrainingAugVarSteps_2StepbeforeFail_2Time_RemovebyClip_SmallThre\",\n",
    "                   workingDirectory + \"/DataSet/\"+\"TrainingAugVarSteps_1StepbeforeFail_3Time_RemovebyClip_SmallThre\",\n",
    "                   workingDirectory + \"/DataSet/\"+\"TrainingAugVarSteps_2StepbeforeFail_3Time_RemovebyClip_SmallThre\"]\n",
    "\n",
    "# TrainingSetPath = [workingDirectory + \"/DataSet/\"+\"TrainingSet_Initial\",\n",
    "#                    workingDirectory + \"/DataSet/\"+\"TrainingAug2Steps_1StepbeforeFail_1Time_RemovebyClip\",]\n",
    "\n",
    "# TrainingSetPath = [workingDirectory + \"/DataSet/\"+\"TrainingSet\",\n",
    "#                    workingDirectory + \"/DataSet/\"+\"Training_Aug_1StepBeforeFail_1Time\",\n",
    "#                    workingDirectory + \"/DataSet/\"+\"Training_Aug_1StepBeforeFail_2Time\",\n",
    "#                    workingDirectory + \"/DataSet/\"+\"Training_Aug_1StepBeforeFail_3Time\"]\n",
    "\n",
    "ValidationSetPath = workingDirectory + \"/DataSet/\"+\"ValidationSet\"\n",
    "TestSetPath = workingDirectory + \"/DataSet/\"+\"TestSet\"\n",
    "\n",
    "#Path to store ML Model, create one if we dont have\n",
    "ML_Model_Path = workingDirectory + \"/ML_Models/\"\n",
    "if not (os.path.isdir(ML_Model_Path)):\n",
    "    os.mkdir(ML_Model_Path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning Code\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For dataset:  0\n",
      "DataSet Sizes: \n",
      "(12000, 85)\n",
      "(12000, 11)\n",
      "World Frame Shift:  StanceFoot\n",
      "Contact Location Representation Type:  FollowRectangelBorder\n",
      "Scaling Factor of Variables:  1.0\n",
      "Number of Preview Steps:  4\n",
      "Pre Process Mode:  OriginalForm\n",
      " \n",
      "For dataset:  1\n",
      "DataSet Sizes: \n",
      "(14954, 85)\n",
      "(14954, 11)\n",
      "World Frame Shift:  StanceFoot\n",
      "Contact Location Representation Type:  FollowRectangelBorder\n",
      "Scaling Factor of Variables:  1.0\n",
      "Number of Preview Steps:  4\n",
      "Pre Process Mode:  OriginalForm\n",
      " \n",
      "For dataset:  2\n",
      "DataSet Sizes: \n",
      "(17936, 85)\n",
      "(17936, 11)\n",
      "World Frame Shift:  StanceFoot\n",
      "Contact Location Representation Type:  FollowRectangelBorder\n",
      "Scaling Factor of Variables:  1.0\n",
      "Number of Preview Steps:  4\n",
      "Pre Process Mode:  OriginalForm\n",
      " \n",
      "For dataset:  3\n",
      "DataSet Sizes: \n",
      "(20093, 85)\n",
      "(20093, 11)\n",
      "World Frame Shift:  StanceFoot\n",
      "Contact Location Representation Type:  FollowRectangelBorder\n",
      "Scaling Factor of Variables:  1.0\n",
      "Number of Preview Steps:  4\n",
      "Pre Process Mode:  OriginalForm\n",
      " \n",
      "For dataset:  4\n",
      "DataSet Sizes: \n",
      "(22145, 85)\n",
      "(22145, 11)\n",
      "World Frame Shift:  StanceFoot\n",
      "Contact Location Representation Type:  FollowRectangelBorder\n",
      "Scaling Factor of Variables:  1.0\n",
      "Number of Preview Steps:  4\n",
      "Pre Process Mode:  OriginalForm\n",
      " \n",
      "For dataset:  5\n",
      "DataSet Sizes: \n",
      "(23505, 85)\n",
      "(23505, 11)\n",
      "World Frame Shift:  StanceFoot\n",
      "Contact Location Representation Type:  FollowRectangelBorder\n",
      "Scaling Factor of Variables:  1.0\n",
      "Number of Preview Steps:  4\n",
      "Pre Process Mode:  OriginalForm\n",
      " \n",
      "For dataset:  6\n",
      "DataSet Sizes: \n",
      "(24895, 85)\n",
      "(24895, 11)\n",
      "World Frame Shift:  StanceFoot\n",
      "Contact Location Representation Type:  FollowRectangelBorder\n",
      "Scaling Factor of Variables:  1.0\n",
      "Number of Preview Steps:  4\n",
      "Pre Process Mode:  OriginalForm\n",
      " \n",
      "Final Data Set Size\n",
      "(24895, 85)\n",
      "(24895, 11)\n",
      " \n",
      "Set Up for Validation Set\n",
      "World Frame Shift:  StanceFoot\n",
      "Contact Location Representation Type:  FollowRectangelBorder\n",
      "Scaling Factor of Variables:  1.0\n",
      "Number of Preview Steps:  4\n",
      "Pre Process Mode:  OriginalForm\n",
      "Validation Set Size\n",
      "(23250, 85)\n",
      "(23250, 11)\n",
      " \n",
      " \n",
      "Set Up for Test Set\n",
      "World Frame Shift:  StanceFoot\n",
      "Contact Location Representation Type:  FollowRectangelBorder\n",
      "Scaling Factor of Variables:  1.0\n",
      "Number of Preview Steps:  4\n",
      "Pre Process Mode:  OriginalForm\n",
      "Test Set Size\n",
      "(23250, 85)\n",
      "(23250, 11)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Load DataSet File\n",
    "\n",
    "#For training set\n",
    "for trainingset_idx in range(len(TrainingSetPath)):\n",
    "    trainingset_file = TrainingSetPath[trainingset_idx] + \"/data\"+'.p'\n",
    "    trainingset = pickle.load(open(trainingset_file,\"rb\"))\n",
    "    \n",
    "    print(\"For dataset: \", trainingset_idx)\n",
    "    print(\"DataSet Sizes: \")\n",
    "    \n",
    "    if trainingset_idx == 0:\n",
    "        x_train = trainingset[\"input\"]\n",
    "        y_train = trainingset[\"output\"]\n",
    "    else:\n",
    "        x_train = np.concatenate((x_train,trainingset[\"input\"]),axis=0)\n",
    "        y_train = np.concatenate((y_train,trainingset[\"output\"]),axis=0)\n",
    "    \n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "\n",
    "    print(\"World Frame Shift: \", trainingset[\"Shift_World_Frame_Type\"])\n",
    "    print(\"Contact Location Representation Type: \",trainingset[\"Contact_Representation_Type\"])\n",
    "    print(\"Scaling Factor of Variables: \",trainingset[\"VectorScaleFactor\"])\n",
    "    print(\"Number of Preview Steps: \", trainingset[\"NumPreviewSteps\"])\n",
    "    print(\"Pre Process Mode: \",trainingset[\"PreProcessMode\"])\n",
    "    print(\" \")\n",
    "\n",
    "print(\"Final Data Set Size\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\" \")\n",
    "\n",
    "#For validation and Test\n",
    "\n",
    "#Load Validation Set and Test Set\n",
    "validationset_file = ValidationSetPath + \"/data\"+'.p'\n",
    "validationset = pickle.load(open(validationset_file,\"rb\"))\n",
    "\n",
    "testset_file = TestSetPath + \"/data\"+'.p'\n",
    "testset = pickle.load(open(testset_file,\"rb\"))\n",
    "\n",
    "x_valid = validationset[\"input\"]\n",
    "y_valid = validationset[\"output\"]\n",
    "\n",
    "x_test = testset[\"input\"]\n",
    "y_test = testset[\"output\"]\n",
    "\n",
    "print(\"Set Up for Validation Set\")\n",
    "print(\"World Frame Shift: \", validationset[\"Shift_World_Frame_Type\"])\n",
    "print(\"Contact Location Representation Type: \",validationset[\"Contact_Representation_Type\"])\n",
    "print(\"Scaling Factor of Variables: \",validationset[\"VectorScaleFactor\"])\n",
    "print(\"Number of Preview Steps: \", validationset[\"NumPreviewSteps\"])\n",
    "print(\"Pre Process Mode: \",validationset[\"PreProcessMode\"])\n",
    "print(\"Validation Set Size\")\n",
    "print(x_valid.shape)\n",
    "print(y_valid.shape)\n",
    "print(\" \")\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print(\"Set Up for Test Set\")\n",
    "print(\"World Frame Shift: \", testset[\"Shift_World_Frame_Type\"])\n",
    "print(\"Contact Location Representation Type: \",testset[\"Contact_Representation_Type\"])\n",
    "print(\"Scaling Factor of Variables: \",testset[\"VectorScaleFactor\"])\n",
    "print(\"Number of Preview Steps: \", testset[\"NumPreviewSteps\"])\n",
    "print(\"Pre Process Mode: \",testset[\"PreProcessMode\"])\n",
    "print(\"Test Set Size\")\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim:  85\n",
      "output dim: 11\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Decide input and outpu dimensionality\n",
    "d_in = x_train[0].shape[0]\n",
    "print(\"input dim: \", d_in)\n",
    "d_out = y_train[0].shape[0]\n",
    "print(\"output dim:\", d_out)\n",
    "print(\" \")\n",
    "\n",
    "# #Double check with mean and std\n",
    "# print(\"Inputs: \")\n",
    "# print(\"Input Mean: \", x_train.mean(axis=0))\n",
    "# print(\"Input Std: \", x_train.std(axis=0))\n",
    "# print(\"Input Max: \", x_train.max(axis=0))\n",
    "# print(\"Input Min: \", x_train.min(axis=0))\n",
    "# print(\" \")\n",
    "\n",
    "\n",
    "# print(\"Output Mean: \", y_train.mean(axis=0))\n",
    "# print(\"Output Std: \", y_train.std(axis=0))\n",
    "# print(\"Output Max: \", y_train.max(axis=0))\n",
    "# print(\"Output Min: \", y_train.min(axis=0))\n",
    "\n",
    "# print(\"Final Data Set Size\")\n",
    "# print(x_train.shape)\n",
    "# print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define learning model\n",
    "# model = Sequential([\n",
    "#     Dense(256, activation='relu', input_shape=(d_in,)),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dense(d_out)\n",
    "# ])\n",
    "# loss: 4.6886e-04 - val_loss: 5.4786e-04\n",
    "\n",
    "# #True code\n",
    "# model = Sequential([\n",
    "#     Dense(256, activation='relu', input_shape=(d_in,)), #tanh\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dense(d_out, activation='linear')\n",
    "# ])\n",
    "\n",
    "# #True code\n",
    "# model = Sequential([\n",
    "#     Dense(256, activation='relu', input_shape=(d_in,), kernel_regularizer='l1'), #tanh\n",
    "#     Dense(256, activation='relu', kernel_regularizer='l1'),\n",
    "#     Dense(256, activation='relu', kernel_regularizer='l1'),\n",
    "#     Dense(256, activation='relu', kernel_regularizer='l1'),\n",
    "#     Dense(d_out, activation='linear')\n",
    "# ])\n",
    "\n",
    "#True code\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(d_in,), ), #tanh\n",
    "    Dense(256, activation='relu', ),\n",
    "    Dense(256, activation='relu', ),\n",
    "    Dense(256, activation='relu', ),\n",
    "    Dense(d_out, activation='linear')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 1.3228e-04 - val_loss: 1.7838e-04\n",
      "Epoch 2/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0508e-04 - val_loss: 1.7532e-04\n",
      "Epoch 3/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0239e-04 - val_loss: 1.7422e-04\n",
      "Epoch 4/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0265e-04 - val_loss: 1.7571e-04\n",
      "Epoch 5/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0334e-04 - val_loss: 1.7518e-04\n",
      "Epoch 6/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0289e-04 - val_loss: 1.7418e-04\n",
      "Epoch 7/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0334e-04 - val_loss: 1.7510e-04\n",
      "Epoch 8/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0300e-04 - val_loss: 1.7512e-04\n",
      "Epoch 9/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0311e-04 - val_loss: 1.7528e-04\n",
      "Epoch 10/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0306e-04 - val_loss: 1.7465e-04\n",
      "Epoch 11/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0327e-04 - val_loss: 1.7486e-04\n",
      "Epoch 12/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0375e-04 - val_loss: 1.7522e-04\n",
      "Epoch 13/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0332e-04 - val_loss: 1.7585e-04\n",
      "Epoch 14/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0329e-04 - val_loss: 1.7517e-04\n",
      "Epoch 15/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0367e-04 - val_loss: 1.7473e-04\n",
      "Epoch 16/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0385e-04 - val_loss: 1.7445e-04\n",
      "Epoch 17/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0302e-04 - val_loss: 1.7528e-04\n",
      "Epoch 18/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0337e-04 - val_loss: 1.7576e-04\n",
      "Epoch 19/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0378e-04 - val_loss: 1.7580e-04\n",
      "Epoch 20/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0414e-04 - val_loss: 1.7604e-04\n",
      "Epoch 21/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0405e-04 - val_loss: 1.7606e-04\n",
      "Epoch 22/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0426e-04 - val_loss: 1.7650e-04\n",
      "Epoch 23/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0349e-04 - val_loss: 1.7498e-04\n",
      "Epoch 24/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0345e-04 - val_loss: 1.7649e-04\n",
      "Epoch 25/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0410e-04 - val_loss: 1.7447e-04\n",
      "Epoch 26/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0360e-04 - val_loss: 1.7573e-04\n",
      "Epoch 27/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0456e-04 - val_loss: 1.7540e-04\n",
      "Epoch 28/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0430e-04 - val_loss: 1.7613e-04\n",
      "Epoch 29/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0414e-04 - val_loss: 1.7469e-04\n",
      "Epoch 30/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0367e-04 - val_loss: 1.7558e-04\n",
      "Epoch 31/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0400e-04 - val_loss: 1.7465e-04\n",
      "Epoch 32/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0376e-04 - val_loss: 1.7707e-04\n",
      "Epoch 33/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0500e-04 - val_loss: 1.7542e-04\n",
      "Epoch 34/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0396e-04 - val_loss: 1.7751e-04\n",
      "Epoch 35/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0407e-04 - val_loss: 1.7596e-04\n",
      "Epoch 36/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0405e-04 - val_loss: 1.7626e-04\n",
      "Epoch 37/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0467e-04 - val_loss: 1.8232e-04\n",
      "Epoch 38/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0788e-04 - val_loss: 1.7699e-04\n",
      "Epoch 39/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0381e-04 - val_loss: 1.7507e-04\n",
      "Epoch 40/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0382e-04 - val_loss: 1.7638e-04\n",
      "Epoch 41/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0398e-04 - val_loss: 1.7765e-04\n",
      "Epoch 42/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0561e-04 - val_loss: 1.7916e-04\n",
      "Epoch 43/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0424e-04 - val_loss: 1.7616e-04\n",
      "Epoch 44/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0348e-04 - val_loss: 1.7595e-04\n",
      "Epoch 45/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0349e-04 - val_loss: 1.7497e-04\n",
      "Epoch 46/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0371e-04 - val_loss: 1.7568e-04\n",
      "Epoch 47/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0390e-04 - val_loss: 1.7699e-04\n",
      "Epoch 48/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0373e-04 - val_loss: 1.7546e-04\n",
      "Epoch 49/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0387e-04 - val_loss: 1.7708e-04\n",
      "Epoch 50/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0373e-04 - val_loss: 1.7650e-04\n",
      "Epoch 51/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0383e-04 - val_loss: 1.7612e-04\n",
      "Epoch 52/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0445e-04 - val_loss: 1.7566e-04\n",
      "Epoch 53/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0471e-04 - val_loss: 1.7691e-04\n",
      "Epoch 54/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0315e-04 - val_loss: 1.7460e-04\n",
      "Epoch 55/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0416e-04 - val_loss: 1.7471e-04\n",
      "Epoch 56/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0378e-04 - val_loss: 1.7660e-04\n",
      "Epoch 57/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0459e-04 - val_loss: 1.7668e-04\n",
      "Epoch 58/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0413e-04 - val_loss: 1.7602e-04\n",
      "Epoch 59/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0447e-04 - val_loss: 1.7718e-04\n",
      "Epoch 60/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0437e-04 - val_loss: 1.7584e-04\n",
      "Epoch 61/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0367e-04 - val_loss: 1.7416e-04\n",
      "Epoch 62/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0330e-04 - val_loss: 1.7557e-04\n",
      "Epoch 63/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0414e-04 - val_loss: 1.7530e-04\n",
      "Epoch 64/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0374e-04 - val_loss: 1.8009e-04\n",
      "Epoch 65/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0436e-04 - val_loss: 1.7537e-04\n",
      "Epoch 66/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0363e-04 - val_loss: 1.7698e-04\n",
      "Epoch 67/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0318e-04 - val_loss: 1.7579e-04\n",
      "Epoch 68/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0350e-04 - val_loss: 1.7697e-04\n",
      "Epoch 69/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0385e-04 - val_loss: 1.7615e-04\n",
      "Epoch 70/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0314e-04 - val_loss: 1.7505e-04\n",
      "Epoch 71/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0335e-04 - val_loss: 1.7708e-04\n",
      "Epoch 72/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0357e-04 - val_loss: 1.7586e-04\n",
      "Epoch 73/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0427e-04 - val_loss: 1.7597e-04\n",
      "Epoch 74/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0366e-04 - val_loss: 1.7579e-04\n",
      "Epoch 75/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0389e-04 - val_loss: 1.7794e-04\n",
      "Epoch 76/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0349e-04 - val_loss: 1.7573e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0396e-04 - val_loss: 1.7515e-04\n",
      "Epoch 78/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0350e-04 - val_loss: 1.7779e-04\n",
      "Epoch 79/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0388e-04 - val_loss: 1.7747e-04\n",
      "Epoch 80/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0310e-04 - val_loss: 1.7645e-04\n",
      "Epoch 81/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0334e-04 - val_loss: 1.7621e-04\n",
      "Epoch 82/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0403e-04 - val_loss: 1.7517e-04\n",
      "Epoch 83/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0352e-04 - val_loss: 1.7611e-04\n",
      "Epoch 84/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0319e-04 - val_loss: 1.7633e-04\n",
      "Epoch 85/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0327e-04 - val_loss: 1.7632e-04\n",
      "Epoch 86/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0336e-04 - val_loss: 1.7578e-04\n",
      "Epoch 87/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0371e-04 - val_loss: 1.7731e-04\n",
      "Epoch 88/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0363e-04 - val_loss: 1.7611e-04\n",
      "Epoch 89/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0355e-04 - val_loss: 1.7540e-04\n",
      "Epoch 90/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0379e-04 - val_loss: 1.7577e-04\n",
      "Epoch 91/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0393e-04 - val_loss: 1.7536e-04\n",
      "Epoch 92/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0282e-04 - val_loss: 1.7606e-04\n",
      "Epoch 93/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0301e-04 - val_loss: 1.7595e-04\n",
      "Epoch 94/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0378e-04 - val_loss: 1.7657e-04\n",
      "Epoch 95/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0410e-04 - val_loss: 1.7742e-04\n",
      "Epoch 96/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0334e-04 - val_loss: 1.7598e-04\n",
      "Epoch 97/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0334e-04 - val_loss: 1.7579e-04\n",
      "Epoch 98/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0372e-04 - val_loss: 1.7668e-04\n",
      "Epoch 99/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0318e-04 - val_loss: 1.7643e-04\n",
      "Epoch 100/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0419e-04 - val_loss: 1.7766e-04\n",
      "Epoch 101/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0392e-04 - val_loss: 1.7731e-04\n",
      "Epoch 102/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0386e-04 - val_loss: 1.7700e-04\n",
      "Epoch 103/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0441e-04 - val_loss: 1.7646e-04\n",
      "Epoch 104/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0353e-04 - val_loss: 1.7775e-04\n",
      "Epoch 105/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0405e-04 - val_loss: 1.8093e-04\n",
      "Epoch 106/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0457e-04 - val_loss: 1.7809e-04\n",
      "Epoch 107/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0431e-04 - val_loss: 1.7670e-04\n",
      "Epoch 108/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0434e-04 - val_loss: 1.7797e-04\n",
      "Epoch 109/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0386e-04 - val_loss: 1.7634e-04\n",
      "Epoch 110/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0273e-04 - val_loss: 1.7610e-04\n",
      "Epoch 111/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0336e-04 - val_loss: 1.7555e-04\n",
      "Epoch 112/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0322e-04 - val_loss: 1.7577e-04\n",
      "Epoch 113/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0381e-04 - val_loss: 1.7725e-04\n",
      "Epoch 114/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0345e-04 - val_loss: 1.7632e-04\n",
      "Epoch 115/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0338e-04 - val_loss: 1.7740e-04\n",
      "Epoch 116/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0303e-04 - val_loss: 1.7645e-04\n",
      "Epoch 117/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0276e-04 - val_loss: 1.7739e-04\n",
      "Epoch 118/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0340e-04 - val_loss: 1.7597e-04\n",
      "Epoch 119/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0309e-04 - val_loss: 1.7879e-04\n",
      "Epoch 120/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0382e-04 - val_loss: 1.7579e-04\n",
      "Epoch 121/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0272e-04 - val_loss: 1.7618e-04\n",
      "Epoch 122/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0270e-04 - val_loss: 1.7459e-04\n",
      "Epoch 123/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0289e-04 - val_loss: 1.7607e-04\n",
      "Epoch 124/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0331e-04 - val_loss: 1.7606e-04\n",
      "Epoch 125/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0299e-04 - val_loss: 1.7743e-04\n",
      "Epoch 126/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0369e-04 - val_loss: 1.7736e-04\n",
      "Epoch 127/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0368e-04 - val_loss: 1.7587e-04\n",
      "Epoch 128/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0289e-04 - val_loss: 1.7641e-04\n",
      "Epoch 129/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0290e-04 - val_loss: 1.7650e-04\n",
      "Epoch 130/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0310e-04 - val_loss: 1.7557e-04\n",
      "Epoch 131/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0285e-04 - val_loss: 1.7632e-04\n",
      "Epoch 132/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0289e-04 - val_loss: 1.7462e-04\n",
      "Epoch 133/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0240e-04 - val_loss: 1.7573e-04\n",
      "Epoch 134/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0312e-04 - val_loss: 1.7734e-04\n",
      "Epoch 135/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0366e-04 - val_loss: 1.7891e-04\n",
      "Epoch 136/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0388e-04 - val_loss: 1.7711e-04\n",
      "Epoch 137/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0366e-04 - val_loss: 1.7589e-04\n",
      "Epoch 138/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0314e-04 - val_loss: 1.7633e-04\n",
      "Epoch 139/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0321e-04 - val_loss: 1.7642e-04\n",
      "Epoch 140/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0372e-04 - val_loss: 1.7998e-04\n",
      "Epoch 141/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0428e-04 - val_loss: 1.7727e-04\n",
      "Epoch 142/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0376e-04 - val_loss: 1.7638e-04\n",
      "Epoch 143/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0286e-04 - val_loss: 1.7551e-04\n",
      "Epoch 144/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0321e-04 - val_loss: 1.7565e-04\n",
      "Epoch 145/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0393e-04 - val_loss: 1.7749e-04\n",
      "Epoch 146/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0352e-04 - val_loss: 1.7755e-04\n",
      "Epoch 147/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0312e-04 - val_loss: 1.7590e-04\n",
      "Epoch 148/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0275e-04 - val_loss: 1.7635e-04\n",
      "Epoch 149/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0293e-04 - val_loss: 1.7658e-04\n",
      "Epoch 150/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0302e-04 - val_loss: 1.7582e-04\n",
      "Epoch 151/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0295e-04 - val_loss: 1.7644e-04\n",
      "Epoch 152/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0273e-04 - val_loss: 1.7722e-04\n",
      "Epoch 153/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0238e-04 - val_loss: 1.7527e-04\n",
      "Epoch 154/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0318e-04 - val_loss: 1.7600e-04\n",
      "Epoch 155/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0430e-04 - val_loss: 1.7608e-04\n",
      "Epoch 156/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0321e-04 - val_loss: 1.7580e-04\n",
      "Epoch 157/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0206e-04 - val_loss: 1.7610e-04\n",
      "Epoch 158/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0259e-04 - val_loss: 1.7665e-04\n",
      "Epoch 159/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0328e-04 - val_loss: 1.7657e-04\n",
      "Epoch 160/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0323e-04 - val_loss: 1.7572e-04\n",
      "Epoch 161/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0284e-04 - val_loss: 1.7697e-04\n",
      "Epoch 162/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0309e-04 - val_loss: 1.7702e-04\n",
      "Epoch 163/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0289e-04 - val_loss: 1.7479e-04\n",
      "Epoch 164/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0474e-04 - val_loss: 1.7704e-04\n",
      "Epoch 165/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0281e-04 - val_loss: 1.7821e-04\n",
      "Epoch 166/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0286e-04 - val_loss: 1.7549e-04\n",
      "Epoch 167/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0309e-04 - val_loss: 1.7639e-04\n",
      "Epoch 168/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0282e-04 - val_loss: 1.7604e-04\n",
      "Epoch 169/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0215e-04 - val_loss: 1.7550e-04\n",
      "Epoch 170/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0213e-04 - val_loss: 1.7781e-04\n",
      "Epoch 171/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0342e-04 - val_loss: 1.7622e-04\n",
      "Epoch 172/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0301e-04 - val_loss: 1.7514e-04\n",
      "Epoch 173/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0250e-04 - val_loss: 1.7622e-04\n",
      "Epoch 174/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0197e-04 - val_loss: 1.7646e-04\n",
      "Epoch 175/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0247e-04 - val_loss: 1.7508e-04\n",
      "Epoch 176/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0278e-04 - val_loss: 1.7834e-04\n",
      "Epoch 177/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0369e-04 - val_loss: 1.7766e-04\n",
      "Epoch 178/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0459e-04 - val_loss: 1.7745e-04\n",
      "Epoch 179/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0368e-04 - val_loss: 1.7720e-04\n",
      "Epoch 180/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0302e-04 - val_loss: 1.7705e-04\n",
      "Epoch 181/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0326e-04 - val_loss: 1.7674e-04\n",
      "Epoch 182/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0326e-04 - val_loss: 1.7653e-04\n",
      "Epoch 183/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0325e-04 - val_loss: 1.7620e-04\n",
      "Epoch 184/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0215e-04 - val_loss: 1.7453e-04\n",
      "Epoch 185/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0241e-04 - val_loss: 1.7643e-04\n",
      "Epoch 186/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0260e-04 - val_loss: 1.7564e-04\n",
      "Epoch 187/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0183e-04 - val_loss: 1.7486e-04\n",
      "Epoch 188/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0247e-04 - val_loss: 1.7581e-04\n",
      "Epoch 189/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0280e-04 - val_loss: 1.7636e-04\n",
      "Epoch 190/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0297e-04 - val_loss: 1.7584e-04\n",
      "Epoch 191/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0270e-04 - val_loss: 1.7496e-04\n",
      "Epoch 192/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0188e-04 - val_loss: 1.7765e-04\n",
      "Epoch 193/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0261e-04 - val_loss: 1.7679e-04\n",
      "Epoch 194/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0286e-04 - val_loss: 1.7978e-04\n",
      "Epoch 195/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0385e-04 - val_loss: 1.7708e-04\n",
      "Epoch 196/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0334e-04 - val_loss: 1.7678e-04\n",
      "Epoch 197/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0313e-04 - val_loss: 1.7615e-04\n",
      "Epoch 198/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0286e-04 - val_loss: 1.7524e-04\n",
      "Epoch 199/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0204e-04 - val_loss: 1.7550e-04\n",
      "Epoch 200/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0223e-04 - val_loss: 1.7775e-04\n",
      "Epoch 201/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0303e-04 - val_loss: 1.7757e-04\n",
      "Epoch 202/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0275e-04 - val_loss: 1.7769e-04\n",
      "Epoch 203/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0329e-04 - val_loss: 1.7575e-04\n",
      "Epoch 204/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0254e-04 - val_loss: 1.7568e-04\n",
      "Epoch 205/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0216e-04 - val_loss: 1.7753e-04\n",
      "Epoch 206/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0322e-04 - val_loss: 1.7673e-04\n",
      "Epoch 207/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0229e-04 - val_loss: 1.7518e-04\n",
      "Epoch 208/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0201e-04 - val_loss: 1.7529e-04\n",
      "Epoch 209/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0258e-04 - val_loss: 1.7570e-04\n",
      "Epoch 210/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0178e-04 - val_loss: 1.7641e-04\n",
      "Epoch 211/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0261e-04 - val_loss: 1.7730e-04\n",
      "Epoch 212/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0212e-04 - val_loss: 1.7582e-04\n",
      "Epoch 213/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0266e-04 - val_loss: 1.7766e-04\n",
      "Epoch 214/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0311e-04 - val_loss: 1.7781e-04\n",
      "Epoch 215/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0457e-04 - val_loss: 1.7958e-04\n",
      "Epoch 216/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1.0326e-04 - val_loss: 1.7609e-04\n",
      "Epoch 217/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0234e-04 - val_loss: 1.7573e-04\n",
      "Epoch 218/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0340e-04 - val_loss: 1.7693e-04\n",
      "Epoch 219/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0326e-04 - val_loss: 1.7574e-04\n",
      "Epoch 220/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0165e-04 - val_loss: 1.7552e-04\n",
      "Epoch 221/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0291e-04 - val_loss: 1.7692e-04\n",
      "Epoch 222/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1.0298e-04 - val_loss: 1.7909e-04\n",
      "Epoch 223/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0413e-04 - val_loss: 1.7661e-04\n",
      "Epoch 224/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0257e-04 - val_loss: 1.7633e-04\n",
      "Epoch 225/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0253e-04 - val_loss: 1.7529e-04\n",
      "Epoch 226/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0238e-04 - val_loss: 1.7712e-04\n",
      "Epoch 227/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0302e-04 - val_loss: 1.7929e-04\n",
      "Epoch 228/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0248e-04 - val_loss: 1.7582e-04\n",
      "Epoch 229/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0190e-04 - val_loss: 1.7597e-04\n",
      "Epoch 230/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0180e-04 - val_loss: 1.7526e-04\n",
      "Epoch 231/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0248e-04 - val_loss: 1.7763e-04\n",
      "Epoch 232/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0350e-04 - val_loss: 1.7715e-04\n",
      "Epoch 233/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0282e-04 - val_loss: 1.7680e-04\n",
      "Epoch 234/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0220e-04 - val_loss: 1.7617e-04\n",
      "Epoch 235/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0293e-04 - val_loss: 1.7847e-04\n",
      "Epoch 236/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0307e-04 - val_loss: 1.7695e-04\n",
      "Epoch 237/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0373e-04 - val_loss: 1.7787e-04\n",
      "Epoch 238/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0278e-04 - val_loss: 1.7708e-04\n",
      "Epoch 239/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0252e-04 - val_loss: 1.7800e-04\n",
      "Epoch 240/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0286e-04 - val_loss: 1.7733e-04\n",
      "Epoch 241/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0340e-04 - val_loss: 1.7517e-04\n",
      "Epoch 242/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0207e-04 - val_loss: 1.7583e-04\n",
      "Epoch 243/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0157e-04 - val_loss: 1.7544e-04\n",
      "Epoch 244/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0230e-04 - val_loss: 1.7549e-04\n",
      "Epoch 245/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0198e-04 - val_loss: 1.7639e-04\n",
      "Epoch 246/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0274e-04 - val_loss: 1.7671e-04\n",
      "Epoch 247/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0259e-04 - val_loss: 1.7658e-04\n",
      "Epoch 248/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0257e-04 - val_loss: 1.7820e-04\n",
      "Epoch 249/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0274e-04 - val_loss: 1.7696e-04\n",
      "Epoch 250/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0212e-04 - val_loss: 1.7572e-04\n",
      "Epoch 251/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0176e-04 - val_loss: 1.7783e-04\n",
      "Epoch 252/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0237e-04 - val_loss: 1.7598e-04\n",
      "Epoch 253/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0237e-04 - val_loss: 1.7754e-04\n",
      "Epoch 254/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0242e-04 - val_loss: 1.7523e-04\n",
      "Epoch 255/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0164e-04 - val_loss: 1.7640e-04\n",
      "Epoch 256/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0158e-04 - val_loss: 1.7629e-04\n",
      "Epoch 257/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0182e-04 - val_loss: 1.7648e-04\n",
      "Epoch 258/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0207e-04 - val_loss: 1.7562e-04\n",
      "Epoch 259/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0185e-04 - val_loss: 1.7771e-04\n",
      "Epoch 260/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0220e-04 - val_loss: 1.7894e-04\n",
      "Epoch 261/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0201e-04 - val_loss: 1.7696e-04\n",
      "Epoch 262/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0178e-04 - val_loss: 1.7660e-04\n",
      "Epoch 263/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0267e-04 - val_loss: 1.7678e-04\n",
      "Epoch 264/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0282e-04 - val_loss: 1.7772e-04\n",
      "Epoch 265/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0179e-04 - val_loss: 1.7701e-04\n",
      "Epoch 266/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0310e-04 - val_loss: 1.7705e-04\n",
      "Epoch 267/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0257e-04 - val_loss: 1.7691e-04\n",
      "Epoch 268/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0266e-04 - val_loss: 1.7660e-04\n",
      "Epoch 269/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0217e-04 - val_loss: 1.7619e-04\n",
      "Epoch 270/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0217e-04 - val_loss: 1.7890e-04\n",
      "Epoch 271/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0376e-04 - val_loss: 1.7998e-04\n",
      "Epoch 272/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0286e-04 - val_loss: 1.7585e-04\n",
      "Epoch 273/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0246e-04 - val_loss: 1.7742e-04\n",
      "Epoch 274/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0277e-04 - val_loss: 1.7787e-04\n",
      "Epoch 275/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0302e-04 - val_loss: 1.7698e-04\n",
      "Epoch 276/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0218e-04 - val_loss: 1.7581e-04\n",
      "Epoch 277/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0185e-04 - val_loss: 1.7725e-04\n",
      "Epoch 278/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0193e-04 - val_loss: 1.7623e-04\n",
      "Epoch 279/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0182e-04 - val_loss: 1.7557e-04\n",
      "Epoch 280/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0232e-04 - val_loss: 1.7623e-04\n",
      "Epoch 281/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0161e-04 - val_loss: 1.7594e-04\n",
      "Epoch 282/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0135e-04 - val_loss: 1.7559e-04\n",
      "Epoch 283/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0265e-04 - val_loss: 1.7691e-04\n",
      "Epoch 284/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0148e-04 - val_loss: 1.7676e-04\n",
      "Epoch 285/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0169e-04 - val_loss: 1.7627e-04\n",
      "Epoch 286/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0143e-04 - val_loss: 1.7852e-04\n",
      "Epoch 287/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0228e-04 - val_loss: 1.7735e-04\n",
      "Epoch 288/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0313e-04 - val_loss: 1.7677e-04\n",
      "Epoch 289/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0185e-04 - val_loss: 1.7695e-04\n",
      "Epoch 290/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0232e-04 - val_loss: 1.7655e-04\n",
      "Epoch 291/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0149e-04 - val_loss: 1.7703e-04\n",
      "Epoch 292/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0264e-04 - val_loss: 1.7581e-04\n",
      "Epoch 293/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0162e-04 - val_loss: 1.7683e-04\n",
      "Epoch 294/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0227e-04 - val_loss: 1.7557e-04\n",
      "Epoch 295/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0326e-04 - val_loss: 1.8047e-04\n",
      "Epoch 296/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0260e-04 - val_loss: 1.7627e-04\n",
      "Epoch 297/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0165e-04 - val_loss: 1.7665e-04\n",
      "Epoch 298/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0129e-04 - val_loss: 1.7654e-04\n",
      "Epoch 299/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0075e-04 - val_loss: 1.7665e-04\n",
      "Epoch 300/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0233e-04 - val_loss: 1.7802e-04\n",
      "Epoch 301/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0126e-04 - val_loss: 1.7652e-04\n",
      "Epoch 302/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0214e-04 - val_loss: 1.7652e-04\n",
      "Epoch 303/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0202e-04 - val_loss: 1.7609e-04\n",
      "Epoch 304/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0170e-04 - val_loss: 1.7481e-04\n",
      "Epoch 305/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0243e-04 - val_loss: 1.7781e-04\n",
      "Epoch 306/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0177e-04 - val_loss: 1.7637e-04\n",
      "Epoch 307/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 1.0220e-04 - val_loss: 1.8005e-04\n",
      "Epoch 308/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1.0362e-04 - val_loss: 1.7657e-04\n",
      "Epoch 309/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1.0126e-04 - val_loss: 1.7553e-04\n",
      "Epoch 310/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1.0200e-04 - val_loss: 1.7898e-04\n",
      "Epoch 311/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1.0210e-04 - val_loss: 1.7576e-04\n",
      "Epoch 312/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1.0130e-04 - val_loss: 1.7465e-04\n",
      "Epoch 313/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1.0191e-04 - val_loss: 1.7583e-04\n",
      "Epoch 314/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1.0123e-04 - val_loss: 1.7619e-04\n",
      "Epoch 315/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1.0205e-04 - val_loss: 1.7609e-04\n",
      "Epoch 316/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 1.0192e-04 - val_loss: 1.7818e-04\n",
      "Epoch 317/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1.0157e-04 - val_loss: 1.7632e-04\n",
      "Epoch 318/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1.0242e-04 - val_loss: 1.7784e-04\n",
      "Epoch 319/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1.0229e-04 - val_loss: 1.7631e-04\n",
      "Epoch 320/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1.0165e-04 - val_loss: 1.7645e-04\n",
      "Epoch 321/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1.0306e-04 - val_loss: 1.7778e-04\n",
      "Epoch 322/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1.0234e-04 - val_loss: 1.7677e-04\n",
      "Epoch 323/500\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 1.0219e-04 - val_loss: 1.7718e-04\n",
      "Epoch 324/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0148e-04 - val_loss: 1.7825e-04\n",
      "Epoch 325/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1.0223e-04 - val_loss: 1.7633e-04\n",
      "Epoch 326/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0177e-04 - val_loss: 1.7964e-04\n",
      "Epoch 327/500\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 1.0199e-04 - val_loss: 1.7633e-04\n",
      "Epoch 328/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0203e-04 - val_loss: 1.7714e-04\n",
      "Epoch 329/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0148e-04 - val_loss: 1.7811e-04\n",
      "Epoch 330/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0226e-04 - val_loss: 1.7671e-04\n",
      "Epoch 331/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0230e-04 - val_loss: 1.7614e-04\n",
      "Epoch 332/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0158e-04 - val_loss: 1.7748e-04\n",
      "Epoch 333/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0071e-04 - val_loss: 1.7483e-04\n",
      "Epoch 334/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0079e-04 - val_loss: 1.7478e-04\n",
      "Epoch 335/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0081e-04 - val_loss: 1.7819e-04\n",
      "Epoch 336/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0162e-04 - val_loss: 1.7803e-04\n",
      "Epoch 337/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0176e-04 - val_loss: 1.7751e-04\n",
      "Epoch 338/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0284e-04 - val_loss: 1.7758e-04\n",
      "Epoch 339/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0153e-04 - val_loss: 1.7867e-04\n",
      "Epoch 340/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0295e-04 - val_loss: 1.7775e-04\n",
      "Epoch 341/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0202e-04 - val_loss: 1.7771e-04\n",
      "Epoch 342/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0139e-04 - val_loss: 1.7661e-04\n",
      "Epoch 343/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0165e-04 - val_loss: 1.7789e-04\n",
      "Epoch 344/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0225e-04 - val_loss: 1.7817e-04\n",
      "Epoch 345/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0226e-04 - val_loss: 1.7631e-04\n",
      "Epoch 346/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0157e-04 - val_loss: 1.7706e-04\n",
      "Epoch 347/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0210e-04 - val_loss: 1.7561e-04\n",
      "Epoch 348/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0080e-04 - val_loss: 1.7602e-04\n",
      "Epoch 349/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0085e-04 - val_loss: 1.7707e-04\n",
      "Epoch 350/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0120e-04 - val_loss: 1.7616e-04\n",
      "Epoch 351/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0173e-04 - val_loss: 1.7630e-04\n",
      "Epoch 352/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0167e-04 - val_loss: 1.7546e-04\n",
      "Epoch 353/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0105e-04 - val_loss: 1.7647e-04\n",
      "Epoch 354/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0111e-04 - val_loss: 1.7755e-04\n",
      "Epoch 355/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0149e-04 - val_loss: 1.7974e-04\n",
      "Epoch 356/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0342e-04 - val_loss: 1.7606e-04\n",
      "Epoch 357/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0187e-04 - val_loss: 1.7591e-04\n",
      "Epoch 358/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0193e-04 - val_loss: 1.7731e-04\n",
      "Epoch 359/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0075e-04 - val_loss: 1.7769e-04\n",
      "Epoch 360/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0100e-04 - val_loss: 1.7576e-04\n",
      "Epoch 361/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0088e-04 - val_loss: 1.7621e-04\n",
      "Epoch 362/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0146e-04 - val_loss: 1.7866e-04\n",
      "Epoch 363/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0153e-04 - val_loss: 1.7773e-04\n",
      "Epoch 364/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0211e-04 - val_loss: 1.7599e-04\n",
      "Epoch 365/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0079e-04 - val_loss: 1.7712e-04\n",
      "Epoch 366/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0138e-04 - val_loss: 1.7775e-04\n",
      "Epoch 367/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0204e-04 - val_loss: 1.7635e-04\n",
      "Epoch 368/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0161e-04 - val_loss: 1.7579e-04\n",
      "Epoch 369/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0225e-04 - val_loss: 1.7751e-04\n",
      "Epoch 370/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0144e-04 - val_loss: 1.7730e-04\n",
      "Epoch 371/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0095e-04 - val_loss: 1.7623e-04\n",
      "Epoch 372/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0230e-04 - val_loss: 1.7727e-04\n",
      "Epoch 373/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0200e-04 - val_loss: 1.8038e-04\n",
      "Epoch 374/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0256e-04 - val_loss: 1.8019e-04\n",
      "Epoch 375/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0226e-04 - val_loss: 1.7632e-04\n",
      "Epoch 376/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0151e-04 - val_loss: 1.7691e-04\n",
      "Epoch 377/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0114e-04 - val_loss: 1.7924e-04\n",
      "Epoch 378/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0153e-04 - val_loss: 1.7783e-04\n",
      "Epoch 379/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0130e-04 - val_loss: 1.7760e-04\n",
      "Epoch 380/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0096e-04 - val_loss: 1.7566e-04\n",
      "Epoch 381/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0060e-04 - val_loss: 1.7746e-04\n",
      "Epoch 382/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0147e-04 - val_loss: 1.7969e-04\n",
      "Epoch 383/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0131e-04 - val_loss: 1.7732e-04\n",
      "Epoch 384/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0100e-04 - val_loss: 1.7752e-04\n",
      "Epoch 385/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0082e-04 - val_loss: 1.7568e-04\n",
      "Epoch 386/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0136e-04 - val_loss: 1.7867e-04\n",
      "Epoch 387/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0229e-04 - val_loss: 1.7736e-04\n",
      "Epoch 388/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0062e-04 - val_loss: 1.7724e-04\n",
      "Epoch 389/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0127e-04 - val_loss: 1.7727e-04\n",
      "Epoch 390/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0103e-04 - val_loss: 1.7692e-04\n",
      "Epoch 391/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0178e-04 - val_loss: 1.7683e-04\n",
      "Epoch 392/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0058e-04 - val_loss: 1.7733e-04\n",
      "Epoch 393/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0091e-04 - val_loss: 1.7599e-04\n",
      "Epoch 394/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0082e-04 - val_loss: 1.7552e-04\n",
      "Epoch 395/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0133e-04 - val_loss: 1.7694e-04\n",
      "Epoch 396/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0164e-04 - val_loss: 1.7733e-04\n",
      "Epoch 397/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0125e-04 - val_loss: 1.7651e-04\n",
      "Epoch 398/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0194e-04 - val_loss: 1.7922e-04\n",
      "Epoch 399/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0137e-04 - val_loss: 1.7641e-04\n",
      "Epoch 400/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0147e-04 - val_loss: 1.7661e-04\n",
      "Epoch 401/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0087e-04 - val_loss: 1.7711e-04\n",
      "Epoch 402/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0225e-04 - val_loss: 1.7666e-04\n",
      "Epoch 403/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0176e-04 - val_loss: 1.7634e-04\n",
      "Epoch 404/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0114e-04 - val_loss: 1.7586e-04\n",
      "Epoch 405/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0086e-04 - val_loss: 1.7683e-04\n",
      "Epoch 406/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0037e-04 - val_loss: 1.7602e-04\n",
      "Epoch 407/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0080e-04 - val_loss: 1.7612e-04\n",
      "Epoch 408/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0169e-04 - val_loss: 1.7719e-04\n",
      "Epoch 409/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0080e-04 - val_loss: 1.7544e-04\n",
      "Epoch 410/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0039e-04 - val_loss: 1.7928e-04\n",
      "Epoch 411/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0121e-04 - val_loss: 1.7688e-04\n",
      "Epoch 412/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0094e-04 - val_loss: 1.7724e-04\n",
      "Epoch 413/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0170e-04 - val_loss: 1.7618e-04\n",
      "Epoch 414/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0136e-04 - val_loss: 1.7785e-04\n",
      "Epoch 415/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0163e-04 - val_loss: 1.8110e-04\n",
      "Epoch 416/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0197e-04 - val_loss: 1.7801e-04\n",
      "Epoch 417/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0136e-04 - val_loss: 1.7685e-04\n",
      "Epoch 418/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0153e-04 - val_loss: 1.7791e-04\n",
      "Epoch 419/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0157e-04 - val_loss: 1.7927e-04\n",
      "Epoch 420/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0143e-04 - val_loss: 1.7629e-04\n",
      "Epoch 421/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0179e-04 - val_loss: 1.7689e-04\n",
      "Epoch 422/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0043e-04 - val_loss: 1.7688e-04\n",
      "Epoch 423/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0020e-04 - val_loss: 1.7622e-04\n",
      "Epoch 424/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0074e-04 - val_loss: 1.7730e-04\n",
      "Epoch 425/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0103e-04 - val_loss: 1.7648e-04\n",
      "Epoch 426/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0129e-04 - val_loss: 1.7859e-04\n",
      "Epoch 427/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0196e-04 - val_loss: 1.8058e-04\n",
      "Epoch 428/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0172e-04 - val_loss: 1.7716e-04\n",
      "Epoch 429/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0156e-04 - val_loss: 1.7744e-04\n",
      "Epoch 430/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0087e-04 - val_loss: 1.7599e-04\n",
      "Epoch 431/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0059e-04 - val_loss: 1.7669e-04\n",
      "Epoch 432/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0051e-04 - val_loss: 1.7790e-04\n",
      "Epoch 433/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0119e-04 - val_loss: 1.7773e-04\n",
      "Epoch 434/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0105e-04 - val_loss: 1.7828e-04\n",
      "Epoch 435/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0084e-04 - val_loss: 1.7586e-04\n",
      "Epoch 436/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 9.9633e-05 - val_loss: 1.7703e-04\n",
      "Epoch 437/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0078e-04 - val_loss: 1.7711e-04\n",
      "Epoch 438/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0041e-04 - val_loss: 1.7699e-04\n",
      "Epoch 439/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0056e-04 - val_loss: 1.7616e-04\n",
      "Epoch 440/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0062e-04 - val_loss: 1.7749e-04\n",
      "Epoch 441/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0033e-04 - val_loss: 1.7696e-04\n",
      "Epoch 442/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0013e-04 - val_loss: 1.7639e-04\n",
      "Epoch 443/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0121e-04 - val_loss: 1.7568e-04\n",
      "Epoch 444/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0064e-04 - val_loss: 1.7693e-04\n",
      "Epoch 445/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0046e-04 - val_loss: 1.7727e-04\n",
      "Epoch 446/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0177e-04 - val_loss: 1.7819e-04\n",
      "Epoch 447/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0086e-04 - val_loss: 1.7781e-04\n",
      "Epoch 448/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0102e-04 - val_loss: 1.7699e-04\n",
      "Epoch 449/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0184e-04 - val_loss: 1.7737e-04\n",
      "Epoch 450/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0223e-04 - val_loss: 1.7684e-04\n",
      "Epoch 451/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0108e-04 - val_loss: 1.7658e-04\n",
      "Epoch 452/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0016e-04 - val_loss: 1.7685e-04\n",
      "Epoch 453/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0017e-04 - val_loss: 1.7599e-04\n",
      "Epoch 454/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0011e-04 - val_loss: 1.7971e-04\n",
      "Epoch 455/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0162e-04 - val_loss: 1.7728e-04\n",
      "Epoch 456/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0144e-04 - val_loss: 1.8025e-04\n",
      "Epoch 457/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0135e-04 - val_loss: 1.7658e-04\n",
      "Epoch 458/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0017e-04 - val_loss: 1.7723e-04\n",
      "Epoch 459/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0051e-04 - val_loss: 1.7826e-04\n",
      "Epoch 460/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0022e-04 - val_loss: 1.7845e-04\n",
      "Epoch 461/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0032e-04 - val_loss: 1.7655e-04\n",
      "Epoch 462/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0006e-04 - val_loss: 1.7640e-04\n",
      "Epoch 463/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0066e-04 - val_loss: 1.7798e-04\n",
      "Epoch 464/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0077e-04 - val_loss: 1.7885e-04\n",
      "Epoch 465/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0132e-04 - val_loss: 1.7758e-04\n",
      "Epoch 466/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0041e-04 - val_loss: 1.7836e-04\n",
      "Epoch 467/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0057e-04 - val_loss: 1.7760e-04\n",
      "Epoch 468/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0036e-04 - val_loss: 1.7866e-04\n",
      "Epoch 469/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0115e-04 - val_loss: 1.7629e-04\n",
      "Epoch 470/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0058e-04 - val_loss: 1.7648e-04\n",
      "Epoch 471/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0047e-04 - val_loss: 1.7735e-04\n",
      "Epoch 472/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0044e-04 - val_loss: 1.7584e-04\n",
      "Epoch 473/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0096e-04 - val_loss: 1.7679e-04\n",
      "Epoch 474/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0052e-04 - val_loss: 1.7660e-04\n",
      "Epoch 475/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0004e-04 - val_loss: 1.8072e-04\n",
      "Epoch 476/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0124e-04 - val_loss: 1.7795e-04\n",
      "Epoch 477/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0020e-04 - val_loss: 1.7813e-04\n",
      "Epoch 478/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0019e-04 - val_loss: 1.7639e-04\n",
      "Epoch 479/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0067e-04 - val_loss: 1.7711e-04\n",
      "Epoch 480/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0039e-04 - val_loss: 1.7910e-04\n",
      "Epoch 481/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0100e-04 - val_loss: 1.7802e-04\n",
      "Epoch 482/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0081e-04 - val_loss: 1.7861e-04\n",
      "Epoch 483/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0013e-04 - val_loss: 1.7619e-04\n",
      "Epoch 484/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0011e-04 - val_loss: 1.7847e-04\n",
      "Epoch 485/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0035e-04 - val_loss: 1.7692e-04\n",
      "Epoch 486/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0066e-04 - val_loss: 1.7742e-04\n",
      "Epoch 487/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0072e-04 - val_loss: 1.7730e-04\n",
      "Epoch 488/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0074e-04 - val_loss: 1.7992e-04\n",
      "Epoch 489/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0150e-04 - val_loss: 1.7797e-04\n",
      "Epoch 490/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0066e-04 - val_loss: 1.7620e-04\n",
      "Epoch 491/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0006e-04 - val_loss: 1.7865e-04\n",
      "Epoch 492/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0042e-04 - val_loss: 1.7728e-04\n",
      "Epoch 493/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0024e-04 - val_loss: 1.7983e-04\n",
      "Epoch 494/500\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 1.0075e-04 - val_loss: 1.7662e-04\n",
      "Epoch 495/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0097e-04 - val_loss: 1.7740e-04\n",
      "Epoch 496/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0065e-04 - val_loss: 1.7745e-04\n",
      "Epoch 497/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0018e-04 - val_loss: 1.7731e-04\n",
      "Epoch 498/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0042e-04 - val_loss: 1.7774e-04\n",
      "Epoch 499/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0034e-04 - val_loss: 1.7768e-04\n",
      "Epoch 500/500\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 1.0035e-04 - val_loss: 1.7723e-04\n"
     ]
    }
   ],
   "source": [
    "#Train Learning Model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.000075), loss='mse') #0.0001\n",
    "\n",
    "#history = model.fit(x_train, y_train, epochs = 50000, validation_split=0.0, batch_size = x_train.shape[0])\n",
    "#history = model.fit(x_train, y_train, epochs = 3000, validation_split=0.0, batch_size = 1280) #1280\n",
    "#Batch size = 1280 for remove outlier, 2560 for keep outlier\n",
    "history = model.fit(x = x_train, y = y_train, epochs = 500, batch_size = 1280, validation_data = (x_valid, y_valid),shuffle=True) #1280, 1000 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot Training Progree\n",
    "plt.plot(history.history['loss'], 'r', label='loss')\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(history.history['val_loss'], 'b', label='val_loss') if 'val_loss' in history.history else None\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /media/jiayu/Seagate/Rubbles_AddVarSteps_1to2StepbeforeFail_RemovebyClip//ML_Models/NN_Model_AugVarStep_1to2StepbeforeFail_3Time_RemovebyClip_SmallThre/assets\n"
     ]
    }
   ],
   "source": [
    "#Save Trained Model\n",
    "#MLmodel_name = \"NN_Model_Valid_\" + trainingset[\"PreProcessMode\"] + \"_Dagger_InitSet_2Iter\"\n",
    "MLmodel_name = \"NN_Model\" + \"_\" + \"AugVarStep_1to2StepbeforeFail_3Time_RemovebyClip_SmallThre\"\n",
    "model.save(ML_Model_Path + MLmodel_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save DataSet Setttings\n",
    "datasetSettings = {\"Shift_World_Frame_Type\":trainingset[\"Shift_World_Frame_Type\"],\n",
    "                   \"VectorScaleFactor\":trainingset[\"VectorScaleFactor\"],\n",
    "                   \"NumPreviewSteps\":trainingset[\"NumPreviewSteps\"],\n",
    "                   \"Contact_Representation_Type\":trainingset[\"Contact_Representation_Type\"],\n",
    "                   \"TrainingLoss\":history.history['loss']}\n",
    "#Validation loss\n",
    "datasetSettings[\"ValidationLoss\"] = history.history['val_loss'] if 'val_loss' in history.history else None\n",
    "\n",
    "#ProProcess\n",
    "datasetSettings[\"PreProcessMode\"] = trainingset[\"PreProcessMode\"]\n",
    "datasetSettings[\"Scaler_X\"] = trainingset[\"Scaler_X\"]\n",
    "datasetSettings[\"Scaler_Y\"] = trainingset[\"Scaler_Y\"]\n",
    "\n",
    "#Dump File\n",
    "pickle.dump(datasetSettings, open(ML_Model_Path + MLmodel_name+ '/datasetSettings' +'.p', \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.52858895e-01 -2.05587167e-01  6.39173090e-01  1.77166956e-01\n",
      "  1.13520033e-01  3.14785003e-02  2.42701544e-08 -9.27010472e-09\n",
      "  9.18989045e-09 -3.03339699e-01 -1.82052221e-01 -1.47323984e-01\n",
      "  0.00000000e+00  4.07600237e-01  8.79879765e-01 -1.08538178e-13\n",
      " -1.67399763e-01  8.79879765e-01 -1.08538178e-13 -1.67399763e-01\n",
      " -1.36174106e-01 -1.08538178e-13  4.07600237e-01 -1.36174106e-01\n",
      " -1.08538178e-13 -1.67399763e-01 -1.10558810e-01 -1.42383095e-01\n",
      " -7.42399763e-01 -1.10558810e-01 -1.42383095e-01 -7.42399763e-01\n",
      " -1.11413510e+00 -2.11739963e-01 -1.67399763e-01 -1.11413510e+00\n",
      " -2.11739963e-01  4.07600237e-01 -1.28462115e-01 -4.28672459e-02\n",
      " -1.67399763e-01 -1.12032011e-01 -1.34194283e-01 -1.67399763e-01\n",
      " -1.09623179e+00 -3.11255813e-01  4.07600237e-01 -1.11266190e+00\n",
      " -2.19928775e-01  9.82600237e-01  8.59512762e-01  1.13210360e-01\n",
      "  4.07600237e-01  8.68392681e-01  6.38511695e-02  4.07600237e-01\n",
      " -1.15807103e-01 -1.13210360e-01  9.82600237e-01 -1.24687022e-01\n",
      " -6.38511695e-02  9.82600237e-01 -1.15139507e-01 -1.16921206e-01\n",
      "  4.07600237e-01 -1.25354618e-01 -6.01403229e-02  4.07600237e-01\n",
      " -1.10955440e+00 -2.37201852e-01  9.82600237e-01 -1.09933929e+00\n",
      " -2.93982736e-01  1.55760024e+00  8.70815140e-01  5.03858844e-02\n",
      "  9.82600237e-01  8.57090303e-01  1.26675645e-01  9.82600237e-01\n",
      " -1.27109481e-01 -5.03858844e-02  1.55760024e+00 -1.13384644e-01\n",
      " -1.26675645e-01]\n",
      "Data Kept Original Form, But need to scale back to meters\n",
      "predicted result: \n",
      " [[ 1.5606351e-01 -2.2336808e-01  6.5634823e-01  1.4439844e-01\n",
      "  -1.0890162e-01 -1.0541869e-02 -4.4472408e-03  3.3742748e-05\n",
      "   7.6674274e-04  7.6080716e-01  9.2629910e-01]]\n",
      "true value: \n",
      " [ 1.42196008e-01 -2.19000933e-01  6.47028457e-01  1.58672442e-01\n",
      " -9.93163582e-02 -2.48645780e-02 -1.18271556e-05 -2.25050684e-05\n",
      "  1.47771749e-05  7.51100722e-01  9.33309934e-01]\n",
      "diff: \n",
      " [[1.38675042e-02 4.36714591e-03 9.31977107e-03 1.42740062e-02\n",
      "  9.58526172e-03 1.43227086e-02 4.43541369e-03 5.62478166e-05\n",
      "  7.51965567e-04 9.70643430e-03 7.01083858e-03]]\n"
     ]
    }
   ],
   "source": [
    "#Show Prediction Result for Training\n",
    "from sklearn import preprocessing\n",
    "\n",
    "datapoint_num = 33\n",
    "y_pred_temp = model.predict(np.array([x_train[datapoint_num]]))\n",
    "\n",
    "print(x_train[datapoint_num])\n",
    "\n",
    "#Recover to original format\n",
    "if trainingset[\"PreProcessMode\"] == \"OriginalForm\":\n",
    "    print(\"Data Kept Original Form, But need to scale back to meters\")\n",
    "    y_pred_originalform = y_pred_temp/trainingset[\"VectorScaleFactor\"]\n",
    "    y_true_originalform = y_train[datapoint_num]/trainingset[\"VectorScaleFactor\"]\n",
    "elif trainingset[\"PreProcessMode\"] == \"Standarization\" or trainingset[\"PreProcessMode\"] == \"MaxAbs\":\n",
    "    y_pred_originalform = dataset[\"Scaler_Y\"].inverse_transform(y_pred_temp)\n",
    "    y_true_originalform = dataset[\"Scaler_Y\"].inverse_transform(np.array([y_train[datapoint_num]]))\n",
    "else:\n",
    "    raise Exception(\"Unknow Pre Process Mode\")\n",
    "\n",
    "\n",
    "print(\"predicted result: \\n\",y_pred_originalform)\n",
    "print(\"true value: \\n\",y_true_originalform)\n",
    "print(\"diff: \\n\", np.absolute(y_pred_originalform - y_true_originalform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Kept Original Form, But need to scale back to meters\n",
      "[0.05176143 0.05176433 0.05176769 0.05178429 0.05179206 0.05180442\n",
      " 0.05183186 0.05184901 0.0518885  0.05190271 0.0519148  0.05191839\n",
      " 0.05192649 0.05192816 0.05195357 0.05198649 0.0519959  0.05200022\n",
      " 0.05201007 0.05201726 0.05204081 0.05204215 0.05206529 0.05207508\n",
      " 0.05207912 0.05208096 0.05209241 0.05209341 0.05210935 0.05212826\n",
      " 0.05212978 0.05214006 0.052147   0.05215252 0.05216684 0.05216773\n",
      " 0.05218408 0.05219966 0.05220966 0.05221236 0.05223203 0.0522594\n",
      " 0.05229076 0.05229192 0.05231493 0.05233378 0.05235997 0.05236049\n",
      " 0.05236474 0.05237135 0.05239588 0.05239645 0.05241621 0.05243831\n",
      " 0.05247708 0.05249452 0.05250863 0.05253078 0.05253874 0.05255391\n",
      " 0.05255556 0.05256882 0.0525906  0.05259869 0.05260735 0.05261517\n",
      " 0.05262586 0.05264194 0.05267664 0.05268309 0.05273415 0.05275279\n",
      " 0.0528246  0.05285464 0.05286221 0.05286979 0.05289346 0.05292038\n",
      " 0.05294583 0.05295396 0.05296477 0.05297169 0.05298827 0.05301315\n",
      " 0.05301982 0.05307024 0.05307068 0.0530828  0.05309254 0.05311376\n",
      " 0.05312316 0.05313199 0.05314047 0.0531474  0.05314995 0.05316738\n",
      " 0.05317003 0.05318356 0.05318416 0.05319825 0.05324732 0.05324788\n",
      " 0.05329459 0.05338248 0.05338844 0.05341436 0.05342043 0.05342733\n",
      " 0.05344443 0.05347026 0.05348344 0.05349705 0.05350233 0.05351314\n",
      " 0.05356601 0.05358776 0.05361644 0.05363459 0.05364118 0.05364787\n",
      " 0.05369634 0.05372383 0.05376856 0.05380584 0.05381181 0.05383067\n",
      " 0.05383756 0.05387155 0.05391924 0.05392291 0.05394641 0.05394859\n",
      " 0.05397752 0.05399765 0.05402712 0.05405341 0.05410044 0.0541052\n",
      " 0.05413137 0.05414362 0.0541769  0.05419688 0.05421138 0.05429458\n",
      " 0.05431507 0.05436398 0.05437889 0.05444203 0.05448083 0.05452735\n",
      " 0.05453495 0.05453538 0.05455111 0.05459146 0.05463604 0.05465584\n",
      " 0.05468261 0.05469004 0.05470831 0.05471376 0.05474306 0.05475337\n",
      " 0.05475739 0.05477377 0.05479795 0.05481894 0.05483123 0.05484278\n",
      " 0.05487419 0.05490322 0.05492093 0.05494016 0.05494647 0.0549539\n",
      " 0.05495528 0.05496592 0.05499223 0.05499352 0.05499602 0.05502905\n",
      " 0.0550666  0.05509713 0.05510011 0.05510213 0.05511693 0.05514735\n",
      " 0.05517097 0.05517557 0.05518596 0.05520312 0.05522178 0.05524003\n",
      " 0.05525972 0.05526502 0.05529985 0.05530613 0.05533209 0.05535516\n",
      " 0.05540754 0.05541478 0.05547568 0.05547918 0.05548716 0.05550889\n",
      " 0.05552704 0.05556065 0.05556243 0.0555637  0.05557623 0.05559144\n",
      " 0.05563143 0.0556384  0.05566028 0.05566858 0.05569929 0.05572022\n",
      " 0.05575336 0.05579062 0.0558205  0.05582549 0.05583904 0.05587915\n",
      " 0.05588404 0.05594387 0.05596416 0.05597707 0.05598157 0.05599714\n",
      " 0.05599974 0.05605929 0.05606977 0.05608292 0.05616519 0.05621947\n",
      " 0.05627514 0.05627619 0.05634715 0.05636712 0.05645291 0.05645469\n",
      " 0.05646051 0.05646947 0.05648591 0.05649677 0.05650293 0.05652115\n",
      " 0.05652811 0.05654122 0.05655299 0.05655389 0.05657823 0.05658811\n",
      " 0.05665406 0.05667135 0.05668074 0.05669341 0.05671879 0.05672635\n",
      " 0.05674539 0.05675488 0.05679295 0.05682033 0.05684956 0.05690572\n",
      " 0.05691931 0.05695432 0.05698053 0.05699065 0.05702171 0.05711788\n",
      " 0.05716302 0.05719275 0.0572095  0.0572688  0.05729457 0.05739506\n",
      " 0.05739974 0.05743655 0.05746608 0.05748163 0.05750704 0.05751038\n",
      " 0.05753225 0.05757384 0.05760326 0.05764533 0.05765944 0.05778075\n",
      " 0.05779577 0.05786123 0.05790381 0.05790876 0.0579262  0.05793894\n",
      " 0.05802466 0.05806402 0.05807752 0.05807885 0.05811066 0.05811878\n",
      " 0.05819172 0.05822058 0.05823072 0.05828033 0.05829165 0.05831285\n",
      " 0.05836473 0.05843117 0.05844993 0.05845273 0.05845952 0.05846388\n",
      " 0.05851993 0.05852186 0.05853099 0.05855933 0.05856788 0.05860221\n",
      " 0.05869578 0.05869774 0.05870038 0.05870619 0.05871727 0.05875194\n",
      " 0.05877913 0.0587877  0.05881202 0.05883009 0.05885202 0.05891794\n",
      " 0.05898496 0.05902029 0.05903316 0.05904826 0.05911046 0.05912124\n",
      " 0.05913662 0.05916886 0.05917088 0.05918621 0.05921496 0.0592191\n",
      " 0.05923317 0.05931895 0.05942956 0.05952802 0.05954618 0.05957542\n",
      " 0.05962202 0.0596338  0.05965195 0.05965626 0.05974486 0.05974988\n",
      " 0.05976048 0.05979134 0.05979145 0.05982228 0.05982592 0.0598301\n",
      " 0.05984119 0.05986385 0.0599091  0.05996489 0.05998501 0.05999214\n",
      " 0.05999896 0.06002638 0.06021927 0.06028244 0.06028633 0.06032293\n",
      " 0.06033366 0.06041558 0.06043721 0.06049103 0.06049622 0.06054203\n",
      " 0.06054821 0.06055148 0.06056994 0.06057539 0.06063094 0.06065644\n",
      " 0.06070489 0.06072962 0.06073134 0.06081482 0.06087317 0.06087545\n",
      " 0.06097147 0.06098317 0.06099163 0.06107269 0.06108903 0.06113236\n",
      " 0.06121049 0.06124349 0.06134883 0.06137584 0.06138905 0.06144601\n",
      " 0.06148818 0.06151858 0.06160373 0.06166111 0.06167692 0.06182953\n",
      " 0.06183165 0.061837   0.06184558 0.06196275 0.06201764 0.06207734\n",
      " 0.06211902 0.06212901 0.06216571 0.06217606 0.06217651 0.06220534\n",
      " 0.06223078 0.06237748 0.06242563 0.06251597 0.06253087 0.06255095\n",
      " 0.06257525 0.06258129 0.06258351 0.06259305 0.06259987 0.06260836\n",
      " 0.06261502 0.06263435 0.06264387 0.06265022 0.0626593  0.06274678\n",
      " 0.06274864 0.06276609 0.06279734 0.06280367 0.06281854 0.06283058\n",
      " 0.06285821 0.06286905 0.06290501 0.06290585 0.06296754 0.06300003\n",
      " 0.06301289 0.06301519 0.0630956  0.06315762 0.06317162 0.06321954\n",
      " 0.06327796 0.06331939 0.06332111 0.06339796 0.06342188 0.0635585\n",
      " 0.06358943 0.06360683 0.06363495 0.06366123 0.06366244 0.06368523\n",
      " 0.06372418 0.06378695 0.06379564 0.0638016  0.06383522 0.0640042\n",
      " 0.06400632 0.06403762 0.06406473 0.0640745  0.06408643 0.06409445\n",
      " 0.06414151 0.06424292 0.06426558 0.06429757 0.0643438  0.06439744\n",
      " 0.06452011 0.06457714 0.06458625 0.06459943 0.0646079  0.06468528\n",
      " 0.06469031 0.06481078 0.06483864 0.06490419 0.06502248 0.06503983\n",
      " 0.0652036  0.06527453 0.06527519 0.065301   0.06557502 0.06606509\n",
      " 0.0661061  0.0661333  0.06614768 0.06631351 0.0663191  0.06647845\n",
      " 0.0665657  0.06657785 0.066622   0.06663405 0.06667177 0.06670283\n",
      " 0.066734   0.0667355  0.06674473 0.06693847 0.06697485 0.06714157\n",
      " 0.06719496 0.06719754 0.06721988 0.06726255 0.06732436 0.06736328\n",
      " 0.06744788 0.06746759 0.06747233 0.06748938 0.06751834 0.06751843\n",
      " 0.06753128 0.0675534  0.06773563 0.06774713 0.06790005 0.06796526\n",
      " 0.06798274 0.06814111 0.06815742 0.06831341 0.06834218 0.06835702\n",
      " 0.06845124 0.06851399 0.06853154 0.06860334 0.06884554 0.06892469\n",
      " 0.06904508 0.069305   0.06936578 0.06947743 0.06961672 0.06966391\n",
      " 0.06971954 0.06992017 0.07009293 0.07013201 0.0701797  0.07028154\n",
      " 0.07031889 0.07033548 0.07033757 0.07045185 0.0704525  0.07058095\n",
      " 0.07059078 0.07065734 0.07076572 0.0707679  0.07080627 0.07083454\n",
      " 0.07086436 0.07089298 0.07089443 0.0710114  0.07116963 0.07121823\n",
      " 0.07129259 0.07137261 0.0713997  0.07142582 0.07143135 0.07145131\n",
      " 0.07152052 0.07156471 0.07170529 0.07198379 0.07205996 0.07207274\n",
      " 0.07219048 0.07238603 0.07238903 0.07275881 0.0728409  0.072985\n",
      " 0.07315287 0.0732724  0.07332524 0.07350008 0.07365475 0.07412321\n",
      " 0.07420608 0.07421655 0.07426938 0.07438074 0.07446809 0.07467126\n",
      " 0.07478194 0.07490573 0.0749964  0.07518286 0.07533597 0.07536608\n",
      " 0.07554134 0.0756095  0.07565766 0.07570007 0.07577762 0.07579639\n",
      " 0.07580929 0.07598714 0.07626392 0.07626727 0.07645184 0.07654687\n",
      " 0.07676796 0.07681187 0.07715732 0.07717071 0.07718539 0.07750124\n",
      " 0.07769992 0.07798398 0.07806792 0.07807345 0.07840667 0.07843493\n",
      " 0.07847832 0.07850627 0.07855661 0.07878985 0.07885542 0.07890458\n",
      " 0.07908385 0.0791771  0.07925651 0.07926484 0.07934957 0.07940346\n",
      " 0.07951798 0.0796593  0.07994478 0.080713   0.08079932 0.0808793\n",
      " 0.08090809 0.08093891 0.0810831  0.08124617 0.08132328 0.08144178\n",
      " 0.08172963 0.0818024  0.08224288 0.08235616 0.08293584 0.08301618\n",
      " 0.08306444 0.08313785 0.08329778 0.08362252 0.08373057 0.08478869\n",
      " 0.0848861  0.0849053  0.08513964 0.08523201 0.08537202 0.08549554\n",
      " 0.08568853 0.08575539 0.08582002 0.08584702 0.08605988 0.08675619\n",
      " 0.08691161 0.08695502 0.0873844  0.08772905 0.08806567 0.08824311\n",
      " 0.08853069 0.08872884 0.08903866 0.08910327 0.08937918 0.08945523\n",
      " 0.0895841  0.08976603 0.09064062 0.0906844  0.09072741 0.09082709\n",
      " 0.09111897 0.09169634 0.09195749 0.09225603 0.09232995 0.09234031\n",
      " 0.09294721 0.09326447 0.09373919 0.09374109 0.09380167 0.09387431\n",
      " 0.09402386 0.09405809 0.09411901 0.09424627 0.09449696 0.09489955\n",
      " 0.09502103 0.09551251 0.09554213 0.09559387 0.09562987 0.09742405\n",
      " 0.09753883 0.09754768 0.09757499 0.09877951 0.09883274 0.09952526\n",
      " 0.09964062 0.10000464 0.10091802 0.10097019 0.10098742 0.10159446\n",
      " 0.10161043 0.10163387 0.10164279 0.10278761 0.10359504 0.10375445\n",
      " 0.10389875 0.10459087 0.10463497 0.1046575  0.10490322 0.10504465\n",
      " 0.10513371 0.10580099 0.10683474 0.10708167 0.10835032 0.1086561\n",
      " 0.10881112 0.10883615 0.10893867 0.10903608 0.10914261 0.10924411\n",
      " 0.10944648 0.1096038  0.10971383 0.10988277 0.10995942 0.10996546\n",
      " 0.11024035 0.11030203 0.1105038  0.11069463 0.11122108 0.11141583\n",
      " 0.11243564 0.11243874 0.1128614  0.11417232 0.11417707 0.11478352\n",
      " 0.11499189 0.11506054 0.11512151 0.11684062 0.11701643 0.11731127\n",
      " 0.11765365 0.11870567 0.11921634 0.11949074 0.11963234 0.11970231\n",
      " 0.11987614 0.11996643 0.12056575 0.12064776 0.12105257 0.12165426\n",
      " 0.12179798 0.12239345 0.12301685 0.12340449 0.12387639 0.12397737\n",
      " 0.12520445 0.12575836 0.12577056 0.12751034 0.12759215 0.12768692\n",
      " 0.12772949 0.12814013 0.12843518 0.13003003 0.13006767 0.13050731\n",
      " 0.13272015 0.13311522 0.13341938 0.13358652 0.13365448 0.13442371\n",
      " 0.13473961 0.13499613 0.13598132 0.13605973 0.13700904 0.13702968\n",
      " 0.13727021 0.13779026 0.13802995 0.13836452 0.13838642 0.13930961\n",
      " 0.13941293 0.13990543 0.14060338 0.14235392 0.14298458 0.14585495\n",
      " 0.14590634 0.14607878 0.14646691 0.14687425 0.14751277 0.14810939\n",
      " 0.14923786 0.14924368 0.14974496 0.15082134 0.15141081 0.15214312\n",
      " 0.15252467 0.15413772 0.15525926 0.15584268 0.15685278 0.15746226\n",
      " 0.15808659 0.15861989 0.15867145 0.15885922 0.16165555 0.16272001\n",
      " 0.16354234 0.16370263 0.16433236 0.16436273 0.16505342 0.16517778\n",
      " 0.16715073 0.16734706 0.16794918 0.16818467 0.16841135 0.16948225\n",
      " 0.17100976 0.17155912 0.1727284  0.17277834 0.17288057 0.17376603\n",
      " 0.17423383 0.17455389 0.17463355 0.17554671 0.177635   0.17786958\n",
      " 0.17795624 0.17904104 0.18031178 0.18391365 0.1843048  0.18550357\n",
      " 0.18602108 0.18718752 0.18719008 0.18768849 0.18783067 0.18786908\n",
      " 0.18986684 0.19134054 0.19499517 0.19668574 0.1980403  0.19929191\n",
      " 0.19937347 0.1997578  0.20011491 0.20080929 0.20117547 0.20147517\n",
      " 0.20329866 0.20345995 0.20352401 0.20565759 0.20624472 0.2066793\n",
      " 0.20852346 0.20911537 0.20916496 0.20927413 0.21090634 0.21092694\n",
      " 0.21119374 0.21276147 0.21433922 0.21481541 0.21719888 0.21941418\n",
      " 0.22499696 0.22742921 0.22764229 0.22857108 0.22938742 0.22967671\n",
      " 0.2300461  0.23139943 0.23191204 0.23287193 0.23433312 0.23464226\n",
      " 0.23480895 0.23541687 0.23543808 0.23545137 0.23621803 0.23746547\n",
      " 0.23869877 0.24130341 0.24240569 0.24540644 0.24598536 0.24788675\n",
      " 0.24880729 0.25039248 0.2505097  0.25109007 0.25172707 0.25409336\n",
      " 0.25410807 0.25571919 0.25609291 0.25652094 0.25763887 0.25807691\n",
      " 0.25840505 0.25957505 0.25971439 0.26047622 0.26134925 0.26403103\n",
      " 0.26660856 0.2740531  0.28023258 0.28062621 0.28093772 0.28306675\n",
      " 0.28404259 0.28856423 0.28923043 0.29224758 0.29397456 0.29417687\n",
      " 0.29621584 0.29819159 0.30284003 0.30451843 0.30935857 0.31084141\n",
      " 0.31322166 0.43169768 0.52275854 0.68430259]\n",
      "Error Mean:  0.02576634206864569\n",
      "Error Std 0.020683973289253806\n",
      "[0.08675619 0.08691161 0.08903866 0.08910327 0.08937918 0.08945523\n",
      " 0.0895841  0.09064062 0.0906844  0.09072741 0.09111897 0.09169634\n",
      " 0.09234031 0.09374109 0.09380167 0.09402386 0.09489955 0.09753883\n",
      " 0.09877951 0.09964062 0.10159446 0.10278761 0.10359504 0.10463497\n",
      " 0.10683474 0.10883615 0.10924411 0.11024035 0.11141583 0.11243564\n",
      " 0.11243874 0.1128614  0.11478352 0.11499189 0.11506054 0.11949074\n",
      " 0.12056575 0.12239345 0.12843518 0.13050731 0.13365448 0.13727021\n",
      " 0.13836452 0.13990543 0.14590634 0.14646691 0.14687425 0.14924368\n",
      " 0.15082134 0.15525926 0.15685278 0.15808659 0.16165555 0.16272001\n",
      " 0.16354234 0.16433236 0.16715073 0.16734706 0.16794918 0.17100976\n",
      " 0.17288057 0.17423383 0.17554671 0.18602108 0.18786908 0.19668574\n",
      " 0.19929191 0.19937347 0.20147517 0.21090634 0.21433922 0.21481541\n",
      " 0.22764229 0.22857108 0.22967671 0.2300461  0.23139943 0.23433312\n",
      " 0.23545137 0.23621803 0.23746547 0.23869877 0.24240569 0.24540644\n",
      " 0.24788675 0.24880729 0.25039248 0.25409336 0.25410807 0.25571919\n",
      " 0.25609291 0.25807691 0.25971439 0.26047622 0.29224758 0.29397456\n",
      " 0.29819159 0.30284003 0.31084141 0.31322166]\n",
      "[ 3 29  4 15 18  8 18 20 19  2  4  8 26 17 19  3  0  6  5 24 22  8  0  5\n",
      "  7 20  9  8  4  4 23 25 21  0 10 14  2 17 19  0  0 13 12 10 25 17  4 26\n",
      " 24  9 20 22  3 17  1 20  2 26  8  9  2 18 29 10 12 24  4  0 21  0 27 21\n",
      "  5 26 21 13 21 27 27 13 29 27  3 17 27 25 13  5 16 17 19  3 19 28 22  3\n",
      "  4  0 16  0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([9., 1., 4., 6., 7., 4., 1., 1., 5., 3., 3., 0., 2., 4., 1., 1., 2.,\n",
       "        6., 3., 5., 4., 5., 3., 1., 3., 3., 4., 5., 1., 3.]),\n",
       " array([ 0.        ,  0.96666667,  1.93333333,  2.9       ,  3.86666667,\n",
       "         4.83333333,  5.8       ,  6.76666667,  7.73333333,  8.7       ,\n",
       "         9.66666667, 10.63333333, 11.6       , 12.56666667, 13.53333333,\n",
       "        14.5       , 15.46666667, 16.43333333, 17.4       , 18.36666667,\n",
       "        19.33333333, 20.3       , 21.26666667, 22.23333333, 23.2       ,\n",
       "        24.16666667, 25.13333333, 26.1       , 27.06666667, 28.03333333,\n",
       "        29.        ]),\n",
       " <a list of 30 Patch objects>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Error Stat with Training Set\n",
    "import matplotlib.pyplot as plt\n",
    "y_pred_train = model.predict(x_train)\n",
    "\n",
    "if trainingset[\"PreProcessMode\"] == \"OriginalForm\":\n",
    "    print(\"Data Kept Original Form, But need to scale back to meters\")\n",
    "    y_pred_train_originalform = y_pred_train/trainingset[\"VectorScaleFactor\"]\n",
    "    y_true_train_originalform = y_train/trainingset[\"VectorScaleFactor\"]\n",
    "elif trainingset[\"PreProcessMode\"] == \"Standarization\" or trainingset[\"PreProcessMode\"] == \"MaxAbs\":\n",
    "    print(\"PreProcessing of: \", trainingset[\"PreProcessMode\"])\n",
    "    y_pred_train_originalform = trainingset[\"Scaler_Y\"].inverse_transform(y_pred_train)\n",
    "    y_true_train_originalform = trainingset[\"Scaler_Y\"].inverse_transform(y_train)\n",
    "else:\n",
    "    raise Exception(\"Unknow Pre Process Mode\")\n",
    "\n",
    "#Compute Error\n",
    "err = np.linalg.norm(y_true_train_originalform-y_pred_train_originalform, axis=1)\n",
    "\n",
    "#Plot Histogram\n",
    "fig=plt.figure();   ax = fig.gca()\n",
    "plt.hist(err, bins=50, density = True, range = (0.0, 0.375))\n",
    "ax.set_xlabel(\"Normalised Error\")\n",
    "ax.set_xlim([-0.025,0.375])\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "ax.set_ylim([-1,50])\n",
    "\n",
    "#### Sort the error\n",
    "\n",
    "err_sorted = np.sort(err)\n",
    "print(err_sorted[-1000:])  # print the 100 biggest error\n",
    "\n",
    "print(\"Error Mean: \", err_sorted.mean())\n",
    "print(\"Error Std\", err_sorted.std())\n",
    "\n",
    "##Plot prediction on the initial dataset\n",
    "err_initdata=err[0:12000+1]\n",
    "\n",
    "err_initdata_sorted = np.sort(err_initdata)\n",
    "print(err_initdata_sorted[-100:])  # print the 100 biggest error\n",
    "\n",
    "err_initdata_idx_sorted = np.argsort(err_initdata)\n",
    "print(err_initdata_idx_sorted[-100:]%30)\n",
    "selected_err=err_initdata_idx_sorted[-100:]%30\n",
    "fig=plt.figure();   ax = fig.gca()\n",
    "plt.hist(selected_err, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Kept Original Form, But need to scale back to meters\n",
      "[0.00524116 0.00546573 0.00548191 ... 0.3210508  0.32771714 0.3683    ]\n",
      "Error Mean:  0.03564561444670766\n",
      "Error Std 0.02622515852379317\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Error Stat with Validation Set\n",
    "\n",
    "y_pred_valid = model.predict(x_valid)\n",
    "\n",
    "\n",
    "if validationset[\"PreProcessMode\"] == \"OriginalForm\":\n",
    "    print(\"Data Kept Original Form, But need to scale back to meters\")\n",
    "    y_pred_valid_originalform = y_pred_valid/validationset[\"VectorScaleFactor\"]\n",
    "    y_true_valid_originalform = y_valid/validationset[\"VectorScaleFactor\"]\n",
    "elif validationset[\"PreProcessMode\"] == \"Standarization\" or validationset[\"PreProcessMode\"] == \"MaxAbs\":\n",
    "    print(\"PreProcessing of: \", validationset[\"PreProcessMode\"])\n",
    "    y_pred_valid_originalform = validationset[\"Scaler_Y\"].inverse_transform(y_pred_valid)\n",
    "    y_true_valid_originalform = validationset[\"Scaler_Y\"].inverse_transform(y_valid)\n",
    "else:\n",
    "    raise Exception(\"Unknow Pre Process Mode\")\n",
    "\n",
    "#Compute Error\n",
    "err = np.linalg.norm(y_true_valid_originalform-y_pred_valid_originalform, axis=1)\n",
    "\n",
    "#Plot Histogram\n",
    "fig=plt.figure();   ax = fig.gca()\n",
    "plt.hist(err, bins=50, density = True, range = (0.0, 0.375))\n",
    "ax.set_xlabel(\"Normalised Error\")\n",
    "ax.set_xlim([-0.025,0.375])\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "ax.set_ylim([-1,50])\n",
    "\n",
    "#### Sort the error\n",
    "\n",
    "err_sorted = np.sort(err)\n",
    "print(err_sorted)  # print the 100 biggest error\n",
    "\n",
    "print(\"Error Mean: \", err_sorted.mean())\n",
    "print(\"Error Std\", err_sorted.std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Kept Original Form, But need to scale back to meters\n",
      "[0.00524116 0.00546573 0.00548191 ... 0.3210508  0.32771714 0.3683    ]\n",
      "Error Mean:  0.03564561444670766\n",
      "Error Std 0.02622515852379317\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEKCAYAAAAVaT4rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATqUlEQVR4nO3df7RlZX3f8fcnAwYzikAY6FScDBIal7/AeIMi5ocCXShpB7vUmJh20rAyy8aINpo4ra5G22RlbBOTYozpLEQnDSYhK6GgtOKsqWAsqMzgIFAwKB0sZRYDOvhbZODbP86+4TLcO3ffmbvPPXOf92uts87Z++zn7O99GD5nn+fs/ZxUFZKkdvzAUhcgSRovg1+SGmPwS1JjDH5JaozBL0mNMfglqTFHDPniSXYB3wQeAfZV1VSS44C/BNYCu4DXVtXeIeuQJD1mHEf8L6uq06tqqlveCGyrqlOBbd2yJGlMlmKoZx2wpXu8BbhgCWqQpGZlyCt3k/wfYC9QwH+pqs1JHqyqY2Zss7eqjp2l7QZgA8DKlStf+KxnPWuwOiVpOdqxY8cDVbVq//WDjvEDZ1XVvUlOALYmuaNvw6raDGwGmJqaqu3btw9VoyQtS0nunm39oEM9VXVvd78HuAI4A7gvyequqNXAniFrkCQ93mDBn2RlkqdOPwb+MXArcBWwvttsPXDlUDVIkp5oyKGeE4Erkkzv5yNV9fEkNwKXJ7kQ+ArwmgFrkCTtZ7Dgr6q7gNNmWf9V4Oyh9itJOjCv3JWkxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUmMGDP8mKJJ9P8rFu+bgkW5Pc2d0fO3QNkqTHjOOI/83A7TOWNwLbqupUYFu3LEkak0GDP8lJwPnAJTNWrwO2dI+3ABcMWYMk6fGGPuL/Q+A3gUdnrDuxqnYDdPcnzNYwyYYk25Nsv//++wcuU5LaMVjwJ/lZYE9V7TiY9lW1uaqmqmpq1apVi1ydJLXriAFf+yzgnyZ5JXAUcHSSPwPuS7K6qnYnWQ3sGbAGSdJ+Bjvir6p/U1UnVdVa4HXA/6yqXwSuAtZ3m60HrhyqBknSEy3FefybgHOT3Amc2y1LksZkyKGev1dV1wLXdo+/Cpw9jv1Kkp7IK3clqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxgwV/kqOSfC7JzUluS/Lubv1xSbYmubO7P3aoGiRJTzTkEf9DwMur6jTgdOC8JC8GNgLbqupUYFu3LEkak17Bn5FfTPLvuuU1Sc44UJsa+Va3eGR3K2AdsKVbvwW44KAqlyQdlL5H/H8MnAn8fLf8TeD98zVKsiLJTmAPsLWqPgucWFW7Abr7ExZctSTpoPUN/hdV1RuB7wFU1V7gSfM1qqpHqup04CTgjCTP7VtYkg1JtifZfv/99/dtJkmaR9/gfzjJCkZDNSRZBTzadydV9SBwLXAecF+S1d3rrGb0aWC2NpuraqqqplatWtV3V5KkeRzRc7uLgSuAE5L8DvBq4J0HatC9OTxcVQ8meTJwDvAe4CpgPbCpu7/yIGufGGs3Xj3r+l2bzh9zJZI0v17BX1WXJdkBnA0EuKCqbp+n2WpgS/dJ4QeAy6vqY0luAC5PciHwFeA1B1++JGmhegV/kuMYDcn8+Yx1R1bVw3O1qaovAC+YZf1XGb2BSJKWQN+hnpuAZwB7GR3xHwPsTrIH+JWq2jFQfRNjruEcSTrc9P1y9+PAK6vq+Kr6YeAVwOXArzI61VOSdJjoG/xTVXXN9EJVfQL4qar6DPCDg1QmSRpE36GeryV5O/AX3fLPAXu7L257n9YpSVp6fY/4f4HRRVj/jdHpl2u6dSuA1w5TmiRpCH1P53wAeNMcT39p8cqRJA2t7+mcq4DfBJ4DHDW9vqpePlBdkqSB9B3quQy4AzgZeDewC7hxoJokSQPqG/w/XFUfZDQFw3VV9cvAiwesS5I0kL5n9Uxfobs7yfnAvYy+7JUkHWb6Bv9vJ3ka8FbgfcDRwFsGq0qSNJi+wb+3qr4OfB14GUCSswarSpI0mL5j/O/ruU6SNOEOeMSf5EzgJcCqJL8+46mjGV28JUk6zMw31PMk4Cnddk+dsf4bjH6MRZJ0mDlg8FfVdcB1ST5cVXePqSZJ0oD6frn7g0k2A2tntvHKXUk6/PQN/r8C/gS4BHhkuHIkSUPrG/z7quoDg1YiSRqLvqdzfjTJryZZneS46duglUmSBtH3iH99d/8bM9YV8MzFLUeSNLS+8/GfPHQhkqTx6DXUk+SHkryzO7OHJKcm+dlhS5MkDaHvGP+HgO8zuooX4B7gtwepSJI0qL7Bf0pV/Ue66Zmr6rtABqtKkjSYvsH//SRPZvSFLklOAR4arCpJ0mD6ntXzW8DHgWckuQw4C/iloYqSJA2n71k9W5PcxOjnFgO8uaoeGLSyZWDtxqtnXb9r0/ljrkSSHtP3rJ5XMbp69+qq+hiwL8kFw5YmSRpC3zH+3+p+gQuAqnqQ0fCPJOkw0zf4Z9uu7/cDkqQJ0jf4tyd5b5JTkjwzyR8AO4YsTJI0jL7B/yZGF3D9JXA58F3gjUMVJUkazrzDNUlWAFdW1TljqEeSNLB5j/ir6hHgO0metpAXTvKMJJ9McnuS25K8uVt/XJKtSe7s7o89yNolSQeh7xe03wNuSbIV+Pb0yqq66ABt9gFvraqbkjwV2NG1/yVgW1VtSrIR2Ai8/aCqlyQtWN/gv7q79VZVu4Hd3eNvJrkdeDqwDviZbrMtwLUY/JI0Nn2v3N3SzdWzpqq+uNCdJFkLvAD4LHBi96ZAVe1OcsIcbTYAGwDWrFmz0F1KkubQ98rdfwLsZDRfD0lOT3JVz7ZPAf4aeEtVfaNvYVW1uaqmqmpq1apVfZtJkubR93TOdwFnAA8CVNVOYN5f5UpyJKPQv6yq/qZbfV+S1d3zq4E9C6xZknQI+gb/vplTNnTqQA2SBPggcHtVvXfGU1fx2G/4rgeu7FmDJGkR9P1y99YkvwCsSHIqcBFw/TxtzgL+OaOzgXZ26/4tsAm4PMmFwFeA1yy8bEnSweob/G8C3sHox1c+AlzDPD+9WFWfZu5f6Tq7b4GSpMV1wOBPchTwBuBHgVuAM6tq3zgKkyQNY74x/i3AFKPQfwXwe4NXJEka1HxDPc+uqucBJPkg8LnhS5IkDWm+I/6Hpx84xCNJy8N8R/ynJZm+6CrAk7vlAFVVRw9anSRp0R0w+KtqxbgKkSSNR98LuCRJy4TBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWpM3/n4tYjWbrx6zud2bTp/jJVIapFH/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGjNY8Ce5NMmeJLfOWHdckq1J7uzujx1q/5Kk2Q15xP9h4Lz91m0EtlXVqcC2blmSNEaDBX9VfQr42n6r1wFbusdbgAuG2r8kaXZHjHl/J1bVboCq2p3khLk2TLIB2ACwZs2aMZUHazdePbZ9SdJSGHfw91ZVm4HNAFNTU7XE5YzNXG88uzadP+ZKJC1X4z6r574kqwG6+z1j3r8kNW/cwX8VsL57vB64csz7l6TmDXk6558DNwA/luSeJBcCm4Bzk9wJnNstS5LGaLAx/qr6+TmeOnuofUqS5ueVu5LUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqzMT+EIsezx9okbRYPOKXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcYLuA5zXtglaaE84pekxhj8ktQYg1+SGmPwS1JjDH5Jaoxn9SxTc53tA57xI7XOI35JaozBL0mNcainQV70JbXNI35JaozBL0mNWZKhniTnAf8ZWAFcUlWblqIOPZ5DQFIbxh78SVYA7wfOBe4BbkxyVVX973HXon4OdGroXHyzkCbXUhzxnwF8qaruAkjyF8A6wOBfRg7mzWIuvolIi2spgv/pwP+dsXwP8KJxF7GYwaRh+d9K47bcDzaWIvgzy7p6wkbJBmADwJo1axa9iOX+H1aS5rIUZ/XcAzxjxvJJwL37b1RVm6tqqqqmVq1aNbbiJGm5W4rgvxE4NcnJSZ4EvA64agnqkKQmjX2op6r2Jfk14BpGp3NeWlW3jbsOSWpVqp4wvD5xktwP3L3IL3s88MAiv+YQrHPxHA41gnUutpbr/JGqesJY+WER/ENIsr2qppa6jvlY5+I5HGoE61xs1vlETtkgSY0x+CWpMS0H/+alLqAn61w8h0ONYJ2LzTr30+wYvyS1quUjfklqksEvSY1ZdsGf5LwkX0zypSQbZ3k+SS7unv9Ckh/v23aC6tyV5JYkO5NsX+I6n5XkhiQPJXnbQtpOUJ2T1J+v7/57fyHJ9UlO69t2guocS3/2qHFdV9/OJNuTvLRv2wmqc5i+rKplc2N0JfCXgWcCTwJuBp693zavBP4Ho8niXgx8tm/bSaize24XcPyE9OcJwE8AvwO8bSFtJ6HOCezPlwDHdo9fMcH/Pmetc1z92bPGp/DY95jPB+6Y0L6ctc4h+3K5HfH//Vz/VfV9YHqu/5nWAX9aI58BjkmyumfbSahznOats6r2VNWNwMMLbTshdY5Tnzqvr6q93eJnGE1i2KvthNQ5Ln1q/FZ16Qms5LFZgCetL+eqczDLLfhnm+v/6T236dN2sRxKnTD6h/GJJDu66auHcih9Mmn9eSCT2p8XMvrUdzBtD8Wh1Anj6c9eNSZ5VZI7gKuBX15I2wmoEwbqyyX5zd0B9Znrf65tev1OwCI5lDoBzqqqe5OcAGxNckdVfWpRK5y/hiHbLtSh7mvi+jPJyxgF6vR470T25yx1wnj6s1eNVXUFcEWSnwL+A3BO37aL5FDqhIH6crkd8feZ63+ubXr9TsAiOZQ6qarp+z3AFYw+Ti5VnUO0XahD2tek9WeS5wOXAOuq6qsLaTsBdY6rPxfUH11YnpLk+IW2PUSHUudwfTnEFxpLdWP0CeYu4GQe+yLlOfttcz6P/9L0c33bTkidK4Gnznh8PXDeUtU5Y9t38fgvdyeqPw9Q50T1J7AG+BLwkoP9G5e4zrH0Z88af5THvjT9ceD/df8/TVpfzlXnYH256H/oUt8YnQ3zd4y+SX9Ht+4NwBu6xwHe3z1/CzB1oLaTViejswNu7m63TUCd/4DRUc03gAe7x0dPYH/OWucE9uclwF5gZ3fbPqH/Pmetc5z92aPGt3c17ARuAF46oX05a51D9qVTNkhSY5bbGL8kaR4GvyQ1xuCXpMYY/JLUGINfkhpj8GtiJakkvz9j+W1J3jXmGq5NMtU9/u9JjjnE11ub5NY51n+3m4Vx+vYvDmVf0lyW25QNWl4eAv5Zkt+tqgcW2jjJEVW1b7GKqapXLtZrzeHLVXX6gTZIsqKqHplreY42YXSB0KOLVKcOcx7xa5LtY/Q7pP96/yeS/EiSbd085tuSrOnWfzjJe5N8EnhPt/yBJJ9McleSn05yaZLbk3x4xut9oJsL/bYk756tmG5u9OOTrExydZKbk9ya5Oe651+Y5LpuQq1rpmdT7dbfnOQG4I0L7YQk30ry75N8FjhzluVf7+q4NclbujZru7/xj4GbePy0AWqcwa9J937g9Umett/6P2I0bfXzgcuAi2c894+Ac6rqrd3yscDLGb2BfBT4A+A5wPOSTB9hv6OqphjNh/7T3Tw0czkPuLeqTquq5wIfT3Ik8D7g1VX1QuBSRnP/A3wIuKiqzpznbz1lv6Gen+zWrwRuraoXVdWnZy4D3wX+JfAiRlN7/EqSF3TtfqzroxdU1d3z7FsNMfg10arqG8CfAhft99SZwEe6x/+Vx88O+Vf7DX98tEaXqN8C3FdVt3TDHrcBa7ttXpvkJuDzjN4Unn2Asm4BzknyniQ/WVVfZxSyz2U0g+JO4J3ASd0b1jFVdd2MWufy5ao6fcbtb7v1jwB/PWO7mcsvBa6oqm9X1beAvwGm3zDurtFvOUiP4xi/Dgd/yGi44kMH2Gbm3CPf3u+5h7r7R2c8nl4+IsnJwNuAn6iqvd0Q0FFz7qjq75K8kNEcLL+b5BOMZk68bf+j+u7L4EOdF+V7+72RzVyebdrfafv3gwR4xK/DQFV9Dbic0bzv064HXtc9fj3w6UPYxdGMQvLrSU5k9FOCc0ryD4HvVNWfAb/HaEbFLwKrkpzZbXNkkudU1YPd605/Inn9IdQ5m08BFyT5oSQrgVcBfztPGzXOI34dLn4f+LUZyxcBlyb5DeB+RuPcB6Wqbk7yeUZDP3cB/2ueJs8D/lOSRxn9lOO/qqrvJ3k1cHE3vHMEo08qt3W1XZrkO8A1B3jdU7phommXVtXFc249qv2m7hPK57pVl1TV55OsnedvUMOcnVOSGuNQjyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9Jjfn/uDjjR+UwiQoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Error Stat with Test Set\n",
    "\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "if testset[\"PreProcessMode\"] == \"OriginalForm\":\n",
    "    print(\"Data Kept Original Form, But need to scale back to meters\")\n",
    "    y_pred_test_originalform = y_pred_test/testset[\"VectorScaleFactor\"]\n",
    "    y_true_test_originalform = y_test/testset[\"VectorScaleFactor\"]\n",
    "elif testset[\"PreProcessMode\"] == \"Standarization\" or testset[\"PreProcessMode\"] == \"MaxAbs\":\n",
    "    print(\"PreProcessing of: \", validationset[\"PreProcessMode\"])\n",
    "    y_pred_test_originalform = validationset[\"Scaler_Y\"].inverse_transform(y_pred_test)\n",
    "    y_true_test_originalform = validationset[\"Scaler_Y\"].inverse_transform(y_test)\n",
    "else:\n",
    "    raise Exception(\"Unknow Pre Process Mode\")\n",
    "\n",
    "#Compute Error\n",
    "err = np.linalg.norm(y_pred_test_originalform-y_true_test_originalform, axis=1)\n",
    "\n",
    "#Plot Histogram\n",
    "fig=plt.figure();   ax = fig.gca()\n",
    "plt.hist(err, bins=50, density = True, range = (0.0, 0.375))\n",
    "ax.set_xlabel(\"Normalised Error\")\n",
    "ax.set_xlim([-0.025,0.375])\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "ax.set_ylim([-1,50])\n",
    "\n",
    "#### Sort the error\n",
    "\n",
    "err_sorted = np.sort(err)\n",
    "print(err_sorted)  # print the 100 biggest error\n",
    "\n",
    "print(\"Error Mean: \", err_sorted.mean())\n",
    "print(\"Error Std\", err_sorted.std())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a501000252d127e7c27d83f75df0a57bca228f59033b739034a7cde4260d0152"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
