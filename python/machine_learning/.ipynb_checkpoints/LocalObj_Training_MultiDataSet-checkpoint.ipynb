{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double check the Path for storing trajectories is correct\n"
     ]
    }
   ],
   "source": [
    "#Import Packages\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from multicontact_learning_local_objectives.python.machine_learning.ml_utils import *\n",
    "import matplotlib.pyplot as plt #Matplotlib\n",
    "import shutil\n",
    "\n",
    "print(\"Double check the Path for storing trajectories is correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double Check we provide the Correct Traj Path: \n",
      " /home/jiayu/Desktop/MLP_DataSet/TimeTrack_LargeSlope_Angle_17_26/\n"
     ]
    }
   ],
   "source": [
    "#Define Path for Storing Trajectories\n",
    "#Collect Data Points Path\n",
    "#workingDirectory = \"/home/jiayu/Desktop/multicontact_learning_local_objectives/data/large_slope_flat_patches/\"\n",
    "#workingDirectory = \"/home/jiayu/Desktop/MLP_DataSet/Rubbles_DaggerExact/\"\n",
    "#workingDirectory = \"/home/jiayu/Desktop/MLP_DataSet/Rubbles_Add2Steps\"\n",
    "#workingDirectory = \"/media/jiayu/Seagate/Rubbles_Add2Step_KeepOutlier\"\n",
    "#workingDirectory = \"/media/jiayu/Seagate/Rubbles_AddVarSteps_1to2StepbeforeFail_RemovebyClip/\"\n",
    "#workingDirectory = \"/media/jiayu/Seagate/Rubbles_Add2Steps_1StepbeforeFail_RemovebyClip/\"\n",
    "#workingDirectory = \"/media/jiayu/Seagate/LargeSlope_Angle_17_26/\"\n",
    "workingDirectory = \"/home/jiayu/Desktop/MLP_DataSet/TimeTrack_LargeSlope_Angle_17_26/\"\n",
    "\n",
    "#NOTE: need to have \"/\" at the end\n",
    "print(\"Double Check we provide the Correct Traj Path: \\n\", workingDirectory)\n",
    "\n",
    "#Define dataset folder\n",
    "TrainingSetPath = [workingDirectory + \"/DataSet/\"+\"Training_InitSet\"]\n",
    "\n",
    "# TrainingSetPath = [workingDirectory + \"/DataSet/\"+\"TrainingSet_Initial\",\n",
    "#                    workingDirectory + \"/DataSet/\"+\"TrainingAug2Steps_1StepbeforeFail_1Time_RemovebyClip\",]\n",
    "\n",
    "# TrainingSetPath = [workingDirectory + \"/DataSet/\"+\"TrainingSet\",\n",
    "#                    workingDirectory + \"/DataSet/\"+\"Training_Aug_1StepBeforeFail_1Time\",\n",
    "#                    workingDirectory + \"/DataSet/\"+\"Training_Aug_1StepBeforeFail_2Time\",\n",
    "#                    workingDirectory + \"/DataSet/\"+\"Training_Aug_1StepBeforeFail_3Time\"]\n",
    "\n",
    "ValidationSetPath = workingDirectory + \"/DataSet/\"+\"ValidationSet\"\n",
    "TestSetPath = workingDirectory + \"/DataSet/\"+\"TestSet\"\n",
    "\n",
    "#Path to store ML Model, create one if we dont have\n",
    "ML_Model_Path = workingDirectory + \"/ML_Models/\"\n",
    "if not (os.path.isdir(ML_Model_Path)):\n",
    "    os.mkdir(ML_Model_Path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning Code\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For dataset:  0\n",
      "DataSet Sizes: \n",
      "(12000, 85)\n",
      "(12000, 14)\n",
      "World Frame Shift:  StanceFoot\n",
      "Contact Location Representation Type:  FollowRectangelBorder\n",
      "Scaling Factor of Variables:  1.0\n",
      "Number of Preview Steps:  4\n",
      "Pre Process Mode:  OriginalForm\n",
      " \n",
      "Final Data Set Size\n",
      "(12000, 85)\n",
      "(12000, 14)\n",
      " \n",
      "Set Up for Validation Set\n",
      "World Frame Shift:  StanceFoot\n",
      "Contact Location Representation Type:  FollowRectangelBorder\n",
      "Scaling Factor of Variables:  1.0\n",
      "Number of Preview Steps:  4\n",
      "Pre Process Mode:  OriginalForm\n",
      "Validation Set Size\n",
      "(9600, 85)\n",
      "(9600, 14)\n",
      " \n",
      " \n",
      "Set Up for Test Set\n",
      "World Frame Shift:  StanceFoot\n",
      "Contact Location Representation Type:  FollowRectangelBorder\n",
      "Scaling Factor of Variables:  1.0\n",
      "Number of Preview Steps:  4\n",
      "Pre Process Mode:  OriginalForm\n",
      "Test Set Size\n",
      "(9600, 85)\n",
      "(9600, 14)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Load DataSet File\n",
    "\n",
    "#For training set\n",
    "for trainingset_idx in range(len(TrainingSetPath)):\n",
    "    trainingset_file = TrainingSetPath[trainingset_idx] + \"/data\"+'.p'\n",
    "    trainingset = pickle.load(open(trainingset_file,\"rb\"))\n",
    "    \n",
    "    print(\"For dataset: \", trainingset_idx)\n",
    "    print(\"DataSet Sizes: \")\n",
    "    \n",
    "    if trainingset_idx == 0:\n",
    "        x_train = trainingset[\"input\"]\n",
    "        y_train = trainingset[\"output\"]\n",
    "    else:\n",
    "        x_train = np.concatenate((x_train,trainingset[\"input\"]),axis=0)\n",
    "        y_train = np.concatenate((y_train,trainingset[\"output\"]),axis=0)\n",
    "    \n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "\n",
    "    print(\"World Frame Shift: \", trainingset[\"Shift_World_Frame_Type\"])\n",
    "    print(\"Contact Location Representation Type: \",trainingset[\"Contact_Representation_Type\"])\n",
    "    print(\"Scaling Factor of Variables: \",trainingset[\"VectorScaleFactor\"])\n",
    "    print(\"Number of Preview Steps: \", trainingset[\"NumPreviewSteps\"])\n",
    "    print(\"Pre Process Mode: \",trainingset[\"PreProcessMode\"])\n",
    "    print(\" \")\n",
    "\n",
    "print(\"Final Data Set Size\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\" \")\n",
    "\n",
    "#For validation and Test\n",
    "\n",
    "#Load Validation Set and Test Set\n",
    "validationset_file = ValidationSetPath + \"/data\"+'.p'\n",
    "validationset = pickle.load(open(validationset_file,\"rb\"))\n",
    "\n",
    "testset_file = TestSetPath + \"/data\"+'.p'\n",
    "testset = pickle.load(open(testset_file,\"rb\"))\n",
    "\n",
    "x_valid = validationset[\"input\"]\n",
    "y_valid = validationset[\"output\"]\n",
    "\n",
    "x_test = testset[\"input\"]\n",
    "y_test = testset[\"output\"]\n",
    "\n",
    "print(\"Set Up for Validation Set\")\n",
    "print(\"World Frame Shift: \", validationset[\"Shift_World_Frame_Type\"])\n",
    "print(\"Contact Location Representation Type: \",validationset[\"Contact_Representation_Type\"])\n",
    "print(\"Scaling Factor of Variables: \",validationset[\"VectorScaleFactor\"])\n",
    "print(\"Number of Preview Steps: \", validationset[\"NumPreviewSteps\"])\n",
    "print(\"Pre Process Mode: \",validationset[\"PreProcessMode\"])\n",
    "print(\"Validation Set Size\")\n",
    "print(x_valid.shape)\n",
    "print(y_valid.shape)\n",
    "print(\" \")\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print(\"Set Up for Test Set\")\n",
    "print(\"World Frame Shift: \", testset[\"Shift_World_Frame_Type\"])\n",
    "print(\"Contact Location Representation Type: \",testset[\"Contact_Representation_Type\"])\n",
    "print(\"Scaling Factor of Variables: \",testset[\"VectorScaleFactor\"])\n",
    "print(\"Number of Preview Steps: \", testset[\"NumPreviewSteps\"])\n",
    "print(\"Pre Process Mode: \",testset[\"PreProcessMode\"])\n",
    "print(\"Test Set Size\")\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim:  85\n",
      "output dim: 14\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Decide input and outpu dimensionality\n",
    "d_in = x_train[0].shape[0]\n",
    "print(\"input dim: \", d_in)\n",
    "d_out = y_train[0].shape[0]\n",
    "print(\"output dim:\", d_out)\n",
    "print(\" \")\n",
    "\n",
    "# #Double check with mean and std\n",
    "# print(\"Inputs: \")\n",
    "# print(\"Input Mean: \", x_train.mean(axis=0))\n",
    "# print(\"Input Std: \", x_train.std(axis=0))\n",
    "# print(\"Input Max: \", x_train.max(axis=0))\n",
    "# print(\"Input Min: \", x_train.min(axis=0))\n",
    "# print(\" \")\n",
    "\n",
    "\n",
    "# print(\"Output Mean: \", y_train.mean(axis=0))\n",
    "# print(\"Output Std: \", y_train.std(axis=0))\n",
    "# print(\"Output Max: \", y_train.max(axis=0))\n",
    "# print(\"Output Min: \", y_train.min(axis=0))\n",
    "\n",
    "# print(\"Final Data Set Size\")\n",
    "# print(x_train.shape)\n",
    "# print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define learning model\n",
    "# model = Sequential([\n",
    "#     Dense(256, activation='relu', input_shape=(d_in,)),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dense(d_out)\n",
    "# ])\n",
    "# loss: 4.6886e-04 - val_loss: 5.4786e-04\n",
    "\n",
    "# #True code\n",
    "# model = Sequential([\n",
    "#     Dense(256, activation='relu', input_shape=(d_in,)), #tanh\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dense(d_out, activation='linear')\n",
    "# ])\n",
    "\n",
    "# #True code\n",
    "# model = Sequential([\n",
    "#     Dense(256, activation='relu', input_shape=(d_in,), kernel_regularizer='l1'), #tanh\n",
    "#     Dense(256, activation='relu', kernel_regularizer='l1'),\n",
    "#     Dense(256, activation='relu', kernel_regularizer='l1'),\n",
    "#     Dense(256, activation='relu', kernel_regularizer='l1'),\n",
    "#     Dense(d_out, activation='linear')\n",
    "# ])\n",
    "\n",
    "#True code\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(d_in,), ), #tanh\n",
    "    Dense(256, activation='relu', ),\n",
    "    Dense(256, activation='relu', ),\n",
    "    Dense(256, activation='relu', ),\n",
    "    Dense(d_out, activation='linear')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 9.5209e-04 - val_loss: 0.0016\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.8384e-04 - val_loss: 0.0016\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.0986e-04 - val_loss: 0.0015\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.7662e-04 - val_loss: 0.0015\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.6035e-04 - val_loss: 0.0015\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5565e-04 - val_loss: 0.0015\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5084e-04 - val_loss: 0.0015\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5152e-04 - val_loss: 0.0015\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5224e-04 - val_loss: 0.0015\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5243e-04 - val_loss: 0.0015\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5394e-04 - val_loss: 0.0015\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5303e-04 - val_loss: 0.0015\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5315e-04 - val_loss: 0.0015\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5327e-04 - val_loss: 0.0015\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5359e-04 - val_loss: 0.0015\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5299e-04 - val_loss: 0.0015\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5673e-04 - val_loss: 0.0015\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5423e-04 - val_loss: 0.0015\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5163e-04 - val_loss: 0.0015\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5237e-04 - val_loss: 0.0015\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5490e-04 - val_loss: 0.0015\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5732e-04 - val_loss: 0.0015\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5552e-04 - val_loss: 0.0015\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5483e-04 - val_loss: 0.0015\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5789e-04 - val_loss: 0.0015\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.6157e-04 - val_loss: 0.0015\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5529e-04 - val_loss: 0.0015\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5351e-04 - val_loss: 0.0015\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5571e-04 - val_loss: 0.0015\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5524e-04 - val_loss: 0.0015\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5641e-04 - val_loss: 0.0015\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5877e-04 - val_loss: 0.0015\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5943e-04 - val_loss: 0.0015\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5837e-04 - val_loss: 0.0015\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5553e-04 - val_loss: 0.0015\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5698e-04 - val_loss: 0.0015\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5239e-04 - val_loss: 0.0015\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5287e-04 - val_loss: 0.0015\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5800e-04 - val_loss: 0.0015\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5676e-04 - val_loss: 0.0015\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.6032e-04 - val_loss: 0.0015\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5482e-04 - val_loss: 0.0015\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5399e-04 - val_loss: 0.0015\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5785e-04 - val_loss: 0.0015\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5279e-04 - val_loss: 0.0015\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5507e-04 - val_loss: 0.0015\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.6570e-04 - val_loss: 0.0015\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.7164e-04 - val_loss: 0.0015\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.6200e-04 - val_loss: 0.0015\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5646e-04 - val_loss: 0.0015\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5291e-04 - val_loss: 0.0015\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5532e-04 - val_loss: 0.0015\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5975e-04 - val_loss: 0.0016\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.6215e-04 - val_loss: 0.0015\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.6250e-04 - val_loss: 0.0015\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5859e-04 - val_loss: 0.0015\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5190e-04 - val_loss: 0.0015\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5543e-04 - val_loss: 0.0015\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5533e-04 - val_loss: 0.0015\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5459e-04 - val_loss: 0.0015\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5323e-04 - val_loss: 0.0015\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5509e-04 - val_loss: 0.0015\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5595e-04 - val_loss: 0.0015\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5363e-04 - val_loss: 0.0015\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5354e-04 - val_loss: 0.0015\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5469e-04 - val_loss: 0.0015\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.6320e-04 - val_loss: 0.0016\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.6199e-04 - val_loss: 0.0016\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.6657e-04 - val_loss: 0.0015\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5951e-04 - val_loss: 0.0015\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.6150e-04 - val_loss: 0.0015\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5935e-04 - val_loss: 0.0015\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5785e-04 - val_loss: 0.0015\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5457e-04 - val_loss: 0.0015\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5390e-04 - val_loss: 0.0015\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5245e-04 - val_loss: 0.0015\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5112e-04 - val_loss: 0.0015\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5624e-04 - val_loss: 0.0015\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.6293e-04 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.7485e-04 - val_loss: 0.0015\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5716e-04 - val_loss: 0.0015\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5208e-04 - val_loss: 0.0015\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5789e-04 - val_loss: 0.0015\n",
      "Epoch 84/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5166e-04 - val_loss: 0.0015\n",
      "Epoch 85/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.6221e-04 - val_loss: 0.0015\n",
      "Epoch 86/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.6086e-04 - val_loss: 0.0016\n",
      "Epoch 87/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5476e-04 - val_loss: 0.0015\n",
      "Epoch 88/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5538e-04 - val_loss: 0.0015\n",
      "Epoch 89/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5553e-04 - val_loss: 0.0015\n",
      "Epoch 90/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5360e-04 - val_loss: 0.0015\n",
      "Epoch 91/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5341e-04 - val_loss: 0.0015\n",
      "Epoch 92/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5133e-04 - val_loss: 0.0015\n",
      "Epoch 93/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4916e-04 - val_loss: 0.0015\n",
      "Epoch 94/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5095e-04 - val_loss: 0.0015\n",
      "Epoch 95/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5070e-04 - val_loss: 0.0015\n",
      "Epoch 96/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5028e-04 - val_loss: 0.0016\n",
      "Epoch 97/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5330e-04 - val_loss: 0.0016\n",
      "Epoch 98/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5147e-04 - val_loss: 0.0015\n",
      "Epoch 99/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5056e-04 - val_loss: 0.0015\n",
      "Epoch 100/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5590e-04 - val_loss: 0.0015\n",
      "Epoch 101/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5376e-04 - val_loss: 0.0016\n",
      "Epoch 102/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.6291e-04 - val_loss: 0.0015\n",
      "Epoch 103/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.6179e-04 - val_loss: 0.0015\n",
      "Epoch 104/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5855e-04 - val_loss: 0.0015\n",
      "Epoch 105/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5427e-04 - val_loss: 0.0015\n",
      "Epoch 106/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5137e-04 - val_loss: 0.0015\n",
      "Epoch 107/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5230e-04 - val_loss: 0.0015\n",
      "Epoch 108/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5349e-04 - val_loss: 0.0015\n",
      "Epoch 109/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5194e-04 - val_loss: 0.0015\n",
      "Epoch 110/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5424e-04 - val_loss: 0.0015\n",
      "Epoch 111/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5116e-04 - val_loss: 0.0015\n",
      "Epoch 112/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4926e-04 - val_loss: 0.0015\n",
      "Epoch 113/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4969e-04 - val_loss: 0.0015\n",
      "Epoch 114/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4936e-04 - val_loss: 0.0015\n",
      "Epoch 115/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4743e-04 - val_loss: 0.0015\n",
      "Epoch 116/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5066e-04 - val_loss: 0.0015\n",
      "Epoch 117/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4890e-04 - val_loss: 0.0015\n",
      "Epoch 118/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4885e-04 - val_loss: 0.0015\n",
      "Epoch 119/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5469e-04 - val_loss: 0.0016\n",
      "Epoch 120/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5638e-04 - val_loss: 0.0015\n",
      "Epoch 121/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5254e-04 - val_loss: 0.0015\n",
      "Epoch 122/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5473e-04 - val_loss: 0.0015\n",
      "Epoch 123/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5751e-04 - val_loss: 0.0016\n",
      "Epoch 124/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.6467e-04 - val_loss: 0.0015\n",
      "Epoch 125/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.6731e-04 - val_loss: 0.0016\n",
      "Epoch 126/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5724e-04 - val_loss: 0.0016\n",
      "Epoch 127/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5109e-04 - val_loss: 0.0015\n",
      "Epoch 128/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5040e-04 - val_loss: 0.0015\n",
      "Epoch 129/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5150e-04 - val_loss: 0.0015\n",
      "Epoch 130/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5435e-04 - val_loss: 0.0015\n",
      "Epoch 131/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5714e-04 - val_loss: 0.0016\n",
      "Epoch 132/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5425e-04 - val_loss: 0.0015\n",
      "Epoch 133/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5808e-04 - val_loss: 0.0016\n",
      "Epoch 134/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5581e-04 - val_loss: 0.0015\n",
      "Epoch 135/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5333e-04 - val_loss: 0.0016\n",
      "Epoch 136/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5990e-04 - val_loss: 0.0015\n",
      "Epoch 137/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5280e-04 - val_loss: 0.0015\n",
      "Epoch 138/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4824e-04 - val_loss: 0.0015\n",
      "Epoch 139/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5446e-04 - val_loss: 0.0015\n",
      "Epoch 140/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5287e-04 - val_loss: 0.0015\n",
      "Epoch 141/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5145e-04 - val_loss: 0.0015\n",
      "Epoch 142/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5100e-04 - val_loss: 0.0015\n",
      "Epoch 143/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5286e-04 - val_loss: 0.0015\n",
      "Epoch 144/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4607e-04 - val_loss: 0.0015\n",
      "Epoch 145/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4902e-04 - val_loss: 0.0015\n",
      "Epoch 146/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5290e-04 - val_loss: 0.0015\n",
      "Epoch 147/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5470e-04 - val_loss: 0.0015\n",
      "Epoch 148/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5582e-04 - val_loss: 0.0015\n",
      "Epoch 149/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5912e-04 - val_loss: 0.0016\n",
      "Epoch 150/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.6465e-04 - val_loss: 0.0016\n",
      "Epoch 151/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5771e-04 - val_loss: 0.0015\n",
      "Epoch 152/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5070e-04 - val_loss: 0.0016\n",
      "Epoch 153/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4881e-04 - val_loss: 0.0016\n",
      "Epoch 154/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5067e-04 - val_loss: 0.0015\n",
      "Epoch 155/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4892e-04 - val_loss: 0.0016\n",
      "Epoch 156/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5651e-04 - val_loss: 0.0016\n",
      "Epoch 157/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5493e-04 - val_loss: 0.0016\n",
      "Epoch 158/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5555e-04 - val_loss: 0.0015\n",
      "Epoch 159/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5099e-04 - val_loss: 0.0015\n",
      "Epoch 160/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4966e-04 - val_loss: 0.0015\n",
      "Epoch 161/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5058e-04 - val_loss: 0.0016\n",
      "Epoch 162/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5511e-04 - val_loss: 0.0015\n",
      "Epoch 163/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5580e-04 - val_loss: 0.0015\n",
      "Epoch 164/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5451e-04 - val_loss: 0.0015\n",
      "Epoch 165/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4834e-04 - val_loss: 0.0015\n",
      "Epoch 166/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4611e-04 - val_loss: 0.0015\n",
      "Epoch 167/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4901e-04 - val_loss: 0.0015\n",
      "Epoch 168/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5331e-04 - val_loss: 0.0015\n",
      "Epoch 169/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5154e-04 - val_loss: 0.0016\n",
      "Epoch 170/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5049e-04 - val_loss: 0.0015\n",
      "Epoch 171/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5333e-04 - val_loss: 0.0015\n",
      "Epoch 172/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5071e-04 - val_loss: 0.0016\n",
      "Epoch 173/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4927e-04 - val_loss: 0.0015\n",
      "Epoch 174/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4482e-04 - val_loss: 0.0015\n",
      "Epoch 175/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5068e-04 - val_loss: 0.0016\n",
      "Epoch 176/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5907e-04 - val_loss: 0.0015\n",
      "Epoch 177/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4814e-04 - val_loss: 0.0015\n",
      "Epoch 178/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5720e-04 - val_loss: 0.0015\n",
      "Epoch 179/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4767e-04 - val_loss: 0.0016\n",
      "Epoch 180/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4786e-04 - val_loss: 0.0015\n",
      "Epoch 181/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4948e-04 - val_loss: 0.0015\n",
      "Epoch 182/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5274e-04 - val_loss: 0.0016\n",
      "Epoch 183/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5420e-04 - val_loss: 0.0016\n",
      "Epoch 184/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5291e-04 - val_loss: 0.0016\n",
      "Epoch 185/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5048e-04 - val_loss: 0.0015\n",
      "Epoch 186/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5447e-04 - val_loss: 0.0016\n",
      "Epoch 187/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5850e-04 - val_loss: 0.0016\n",
      "Epoch 188/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5434e-04 - val_loss: 0.0015\n",
      "Epoch 189/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4590e-04 - val_loss: 0.0015\n",
      "Epoch 190/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4178e-04 - val_loss: 0.0015\n",
      "Epoch 191/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4662e-04 - val_loss: 0.0015\n",
      "Epoch 192/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4590e-04 - val_loss: 0.0016\n",
      "Epoch 193/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4454e-04 - val_loss: 0.0015\n",
      "Epoch 194/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4222e-04 - val_loss: 0.0015\n",
      "Epoch 195/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4507e-04 - val_loss: 0.0015\n",
      "Epoch 196/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4362e-04 - val_loss: 0.0015\n",
      "Epoch 197/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4744e-04 - val_loss: 0.0015\n",
      "Epoch 198/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4162e-04 - val_loss: 0.0015\n",
      "Epoch 199/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4636e-04 - val_loss: 0.0016\n",
      "Epoch 200/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5294e-04 - val_loss: 0.0015\n",
      "Epoch 201/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4587e-04 - val_loss: 0.0015\n",
      "Epoch 202/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4752e-04 - val_loss: 0.0016\n",
      "Epoch 203/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5091e-04 - val_loss: 0.0015\n",
      "Epoch 204/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4964e-04 - val_loss: 0.0015\n",
      "Epoch 205/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4782e-04 - val_loss: 0.0016\n",
      "Epoch 206/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4979e-04 - val_loss: 0.0015\n",
      "Epoch 207/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4809e-04 - val_loss: 0.0016\n",
      "Epoch 208/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5261e-04 - val_loss: 0.0016\n",
      "Epoch 209/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5518e-04 - val_loss: 0.0016\n",
      "Epoch 210/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4816e-04 - val_loss: 0.0015\n",
      "Epoch 211/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5477e-04 - val_loss: 0.0016\n",
      "Epoch 212/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.7114e-04 - val_loss: 0.0015\n",
      "Epoch 213/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.7657e-04 - val_loss: 0.0016\n",
      "Epoch 214/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4978e-04 - val_loss: 0.0016\n",
      "Epoch 215/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5128e-04 - val_loss: 0.0015\n",
      "Epoch 216/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4856e-04 - val_loss: 0.0015\n",
      "Epoch 217/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4253e-04 - val_loss: 0.0015\n",
      "Epoch 218/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4179e-04 - val_loss: 0.0015\n",
      "Epoch 219/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4701e-04 - val_loss: 0.0016\n",
      "Epoch 220/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4496e-04 - val_loss: 0.0016\n",
      "Epoch 221/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5080e-04 - val_loss: 0.0015\n",
      "Epoch 222/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4918e-04 - val_loss: 0.0015\n",
      "Epoch 223/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4353e-04 - val_loss: 0.0015\n",
      "Epoch 224/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4218e-04 - val_loss: 0.0015\n",
      "Epoch 225/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4470e-04 - val_loss: 0.0015\n",
      "Epoch 226/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5486e-04 - val_loss: 0.0016\n",
      "Epoch 227/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4343e-04 - val_loss: 0.0015\n",
      "Epoch 228/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4768e-04 - val_loss: 0.0016\n",
      "Epoch 229/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4833e-04 - val_loss: 0.0015\n",
      "Epoch 230/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4578e-04 - val_loss: 0.0015\n",
      "Epoch 231/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4466e-04 - val_loss: 0.0015\n",
      "Epoch 232/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4018e-04 - val_loss: 0.0016\n",
      "Epoch 233/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5840e-04 - val_loss: 0.0016\n",
      "Epoch 234/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5412e-04 - val_loss: 0.0016\n",
      "Epoch 235/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5334e-04 - val_loss: 0.0016\n",
      "Epoch 236/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5458e-04 - val_loss: 0.0015\n",
      "Epoch 237/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4756e-04 - val_loss: 0.0016\n",
      "Epoch 238/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4600e-04 - val_loss: 0.0015\n",
      "Epoch 239/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4229e-04 - val_loss: 0.0015\n",
      "Epoch 240/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4038e-04 - val_loss: 0.0016\n",
      "Epoch 241/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4492e-04 - val_loss: 0.0016\n",
      "Epoch 242/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4543e-04 - val_loss: 0.0016\n",
      "Epoch 243/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4817e-04 - val_loss: 0.0015\n",
      "Epoch 244/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4221e-04 - val_loss: 0.0015\n",
      "Epoch 245/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4323e-04 - val_loss: 0.0015\n",
      "Epoch 246/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4723e-04 - val_loss: 0.0015\n",
      "Epoch 247/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4647e-04 - val_loss: 0.0015\n",
      "Epoch 248/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4184e-04 - val_loss: 0.0015\n",
      "Epoch 249/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4405e-04 - val_loss: 0.0015\n",
      "Epoch 250/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4740e-04 - val_loss: 0.0015\n",
      "Epoch 251/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4841e-04 - val_loss: 0.0016\n",
      "Epoch 252/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5450e-04 - val_loss: 0.0015\n",
      "Epoch 253/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4815e-04 - val_loss: 0.0015\n",
      "Epoch 254/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4157e-04 - val_loss: 0.0015\n",
      "Epoch 255/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4028e-04 - val_loss: 0.0015\n",
      "Epoch 256/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4368e-04 - val_loss: 0.0015\n",
      "Epoch 257/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4280e-04 - val_loss: 0.0016\n",
      "Epoch 258/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4896e-04 - val_loss: 0.0015\n",
      "Epoch 259/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4265e-04 - val_loss: 0.0016\n",
      "Epoch 260/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4507e-04 - val_loss: 0.0015\n",
      "Epoch 261/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5051e-04 - val_loss: 0.0016\n",
      "Epoch 262/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4615e-04 - val_loss: 0.0015\n",
      "Epoch 263/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.3849e-04 - val_loss: 0.0015\n",
      "Epoch 264/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4172e-04 - val_loss: 0.0016\n",
      "Epoch 265/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4670e-04 - val_loss: 0.0016\n",
      "Epoch 266/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4719e-04 - val_loss: 0.0015\n",
      "Epoch 267/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4227e-04 - val_loss: 0.0015\n",
      "Epoch 268/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4513e-04 - val_loss: 0.0016\n",
      "Epoch 269/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4345e-04 - val_loss: 0.0015\n",
      "Epoch 270/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4227e-04 - val_loss: 0.0016\n",
      "Epoch 271/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4518e-04 - val_loss: 0.0016\n",
      "Epoch 272/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4743e-04 - val_loss: 0.0015\n",
      "Epoch 273/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4813e-04 - val_loss: 0.0015\n",
      "Epoch 274/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5419e-04 - val_loss: 0.0015\n",
      "Epoch 275/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4663e-04 - val_loss: 0.0016\n",
      "Epoch 276/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4320e-04 - val_loss: 0.0015\n",
      "Epoch 277/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.3805e-04 - val_loss: 0.0015\n",
      "Epoch 278/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4295e-04 - val_loss: 0.0016\n",
      "Epoch 279/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.5663e-04 - val_loss: 0.0015\n",
      "Epoch 280/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4177e-04 - val_loss: 0.0015\n",
      "Epoch 281/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4325e-04 - val_loss: 0.0015\n",
      "Epoch 282/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4250e-04 - val_loss: 0.0016\n",
      "Epoch 283/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4768e-04 - val_loss: 0.0015\n",
      "Epoch 284/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4656e-04 - val_loss: 0.0015\n",
      "Epoch 285/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4178e-04 - val_loss: 0.0015\n",
      "Epoch 286/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.3769e-04 - val_loss: 0.0015\n",
      "Epoch 287/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4048e-04 - val_loss: 0.0015\n",
      "Epoch 288/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4219e-04 - val_loss: 0.0016\n",
      "Epoch 289/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4595e-04 - val_loss: 0.0016\n",
      "Epoch 290/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4234e-04 - val_loss: 0.0016\n",
      "Epoch 291/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.3983e-04 - val_loss: 0.0015\n",
      "Epoch 292/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4198e-04 - val_loss: 0.0016\n",
      "Epoch 293/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4502e-04 - val_loss: 0.0016\n",
      "Epoch 294/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.3917e-04 - val_loss: 0.0015\n",
      "Epoch 295/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4088e-04 - val_loss: 0.0015\n",
      "Epoch 296/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4244e-04 - val_loss: 0.0015\n",
      "Epoch 297/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4756e-04 - val_loss: 0.0016\n",
      "Epoch 298/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.4524e-04 - val_loss: 0.0016\n",
      "Epoch 299/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.3986e-04 - val_loss: 0.0015\n",
      "Epoch 300/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.3580e-04 - val_loss: 0.0016\n"
     ]
    }
   ],
   "source": [
    "#Train Learning Model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.00005), loss='mse') #0.0001\n",
    "\n",
    "#history = model.fit(x_train, y_train, epochs = 50000, validation_split=0.0, batch_size = x_train.shape[0])\n",
    "#history = model.fit(x_train, y_train, epochs = 3000, validation_split=0.0, batch_size = 1280) #1280\n",
    "#Batch size = 1280 for remove outlier, 2560 for keep outlier\n",
    "history = model.fit(x = x_train, y = y_train, epochs = 300, batch_size = 1280, validation_data = (x_valid, y_valid),shuffle=True) #1280, 1000 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAgIElEQVR4nO3deXhU5d3/8fc3C2E1YtgCQZaKioVHtMGrWE2tVUEfcK+CO7VS9RGXX6VuteVn66WPrV1UquJP6opCqT4Fq9JFniKtpSwSAVFEFExACVtYI5C5f3/cE7IwCSEzmTlz5vO6rlxkzpw5870T8plz7nOf+5hzDhERyQxZqS5ARESSR6EvIpJBFPoiIhlEoS8ikkEU+iIiGSQn1QU0pUuXLq5v376pLkNEJK0sWrRoo3Oua6znAh36ffv2ZeHChakuQ0QkrZjZmsaeU/eOiEgGUeiLiGQQhb6ISAYJdJ++iGSevXv3UlZWRlVVVapLCby2bdtSVFREbm5us1+j0BeRQCkrK6NTp0707dsXM0t1OYHlnGPTpk2UlZXRr1+/Zr9O3TsiEihVVVUUFBQo8A/CzCgoKDjkIyKFvogEjgK/eVrycwpn6D/3HEyenOoqREQCJ5Chb2ajzGxyZWVlyzYwdSo8/XRiixKRjNGxY8dUl9BqAhn6zrlZzrlx+fn5LduAGejmMCIiBwhk6MdN/YEikgDOOSZMmMCgQYMYPHgw06ZNA2D9+vWUlJQwZMgQBg0axNtvv011dTXXXHPN/nV/9atfpbj62MI7ZFN7+iLp79ZbYcmSxG5zyBD49a+bteorr7zCkiVLKC0tZePGjQwdOpSSkhKmTp3K8OHDueeee6iurmbXrl0sWbKE8vJyli1bBsDWrVsTW3eChHdPX6EvInGaN28eY8aMITs7m+7du/PNb36TBQsWMHToUH73u98xceJEli5dSqdOnejfvz+rV69m/PjxvPnmmxx22GGpLj+mcO7pK/RFwqGZe+StxTWSIyUlJcydO5c//elPXHnllUyYMIGrrrqK0tJSZs+ezaRJk5g+fTpTpkxJcsUHpz19EZFGlJSUMG3aNKqrq6moqGDu3LmcdNJJrFmzhm7dunHddddx7bXXsnjxYjZu3EgkEuGiiy7ipz/9KYsXL051+TGFck9/+vpTqNq0g6tSXYiIpLULLriAd955h+OPPx4z46GHHqJHjx48++yz/PznPyc3N5eOHTvy3HPPUV5eztixY4lEIgA88MADKa4+Nmvs8CUIiouLXUtuojKi22K27Mxl/s7BrVCViLSmFStWMHDgwFSXkTZi/bzMbJFzrjjW+qHs3jFzOKdhmyIiDYUz9FNdgIhIQIUy9DEIbqeViEjqhDL0DdS9IyISQzhD35z29EVEYghn6ANOPfsiIgcIZ+ib9vNFRGIJZeiDqU9fRJKmqfn3P/30UwYNGpTEapoWytBXn76ISGxJm4bBzPoD9wD5zrmLW/W9UJ++SBikamblO+64gz59+nDjjTcCMHHiRMyMuXPnsmXLFvbu3cvPfvYzzjvvvEN676qqKm644QYWLlxITk4Ov/zlL/nWt77F8uXLGTt2LHv27CESifCHP/yBnj17cskll1BWVkZ1dTX33nsvl156acsaXUez9vTNbIqZbTCzZQ2WjzCzD81slZnd2dQ2nHOrnXPXxlNsc+mKXBGJx+jRo/ffMAVg+vTpjB07lldffZXFixczZ84cfvCDHzQ6C2djJk2aBMDSpUt56aWXuPrqq6mqquKJJ57glltuYcmSJSxcuJCioiLefPNNevbsSWlpKcuWLWPEiBEJaVtz9/SfAR4DnqtZYGbZwCTgTKAMWGBmM4FsoOFMQ991zm2Iu9pm0o2zRMIhVTMrn3DCCWzYsIF169ZRUVFB586dKSws5LbbbmPu3LlkZWVRXl7OF198QY8ePZq93Xnz5jF+/HgAjj32WPr06cPKlSsZNmwY999/P2VlZVx44YUMGDCAwYMHc/vtt3PHHXcwcuRITj311IS0rVl7+s65ucDmBotPAlZF9+D3AC8D5znnljrnRjb4anbgm9k4M1toZgsrKiqa3ZADam7xK0VE4OKLL2bGjBlMmzaN0aNH8+KLL1JRUcGiRYtYsmQJ3bt3p6qq6pC22diRwWWXXcbMmTNp164dw4cP56233uLoo49m0aJFDB48mLvuuov77rsvEc2K60RuL+CzOo/LostiMrMCM3sCOMHM7mpsPefcZOdcsXOuuGvXri0qTH36IhKv0aNH8/LLLzNjxgwuvvhiKisr6datG7m5ucyZM4c1a9Yc8jZLSkp48cUXAVi5ciVr167lmGOOYfXq1fTv35+bb76Zc889l/fee49169bRvn17rrjiCm6//faEzc8fz4ncWKna6A62c24TcH0c79ds/h4qCn0RabmvfvWrbN++nV69elFYWMjll1/OqFGjKC4uZsiQIRx77LGHvM0bb7yR66+/nsGDB5OTk8MzzzxDXl4e06ZN44UXXiA3N5cePXrw4x//mAULFjBhwgSysrLIzc3l8ccfT0i7mj2fvpn1BV5zzg2KPh4GTHTODY8+vgvAOZewOwe0dD797/SZz/L1R/D+ngGJKkVEkkTz6R+aZM6nvwAYYGb9zKwNMBqYGcf29jOzUWY2ubKysmWvR907IiKxNKt7x8xeAk4DuphZGfAT59zTZnYTMBs/YmeKc255Iopyzs0CZhUXF1/Xktdr9I6IJNvSpUu58sor6y3Ly8tj/vz5KaootmaFvnNuTCPLXwdeT2hFCaI+fZH05ZzD0mzvbfDgwSxJ9JVkB9GS290GchqGuLt3NA2DSNpq27YtmzZtalGgZRLnHJs2baJt27aH9LqkTcNwKOLu3kF9+iLpqqioiLKyMuK5TidTtG3blqKiokN6TSBDP15mCn2RdJWbm0u/fv1SXUZoBbJ7J16aT19EJLZQhr7m0xcRiS2Qoa8TuSIirSOQoe+cm+WcG5efn9+i1+tErohIbIEM/XjpRK6ISGwhDX117oiIxBLK0NeJXBGR2AIZ+vGfyFX3johILIEM/fhP5Gr0johILIEM/XhpT19EJDaFvohIBglp6KtzR0QklkCGfrwncjV6R0QktkCGftwnctW9IyISUyBDP14avSMiEls4Q197+iIiMYU29EVE5EChDH3Qnr6ISCyhDH1174iIxBbI0NfcOyIirSOQoR//kE2ncfoiIjEEMvTjpbgXEYktlKGPmcbpi4jEEMrQ9zdG1/6+iEhDIQ19ncgVEYlFoS8ikkHCGfoo9EVEYgln6CvvRURiCmToxz+fvvb0RURiCWToaz59EZHWEcjQj5dCX0QkNoW+iEgGCWno63pcEZFYQhn6/oaJ2tMXEWkolKGv7h0RkdgU+iIiGSTcoe/Uty8iUle4Q19EROoJZejvpz19EZF6Qhn66t4REYlNoS8ikkECGfrxTrim0BcRiS2QoZ+wCdcU+iIi9QQy9OOl+fRFRGILZegDOLK0py8i0kAoQ3//nr5CX0SknlCHvoso9EVE6lLoi4hkkFCHvrp3RETqC2Xo11Dmi4jUF8rQV/eOiEhsCn0RkQyi0BcRySAKfRGRDBLK0Eejd0REYgpl6Ft0V1+ZLyJSXzhDH5/26t4REakvnKGvPn0RkZjCGfrRVin0RUTqC2fo60SuiEhMSQt9MzvfzJ4ysz+a2Vmt/G6A9vRFRBpqVuib2RQz22BmyxosH2FmH5rZKjO7s6ltOOf+xzl3HXANcGmLK26G/X366BZaIiJ15TRzvWeAx4DnahaYWTYwCTgTKAMWmNlMIBt4oMHrv+uc2xD9/kfR17UancgVEYmtWaHvnJtrZn0bLD4JWOWcWw1gZi8D5znnHgBGNtyG+cHzDwJvOOcWN/ZeZjYOGAdw5JFHNqe8A7eRHe3e2buvRa8XEQmrePr0ewGf1XlcFl3WmPHAGcDFZnZ9Yys55yY754qdc8Vdu3ZtUWF57bMB2LOtqkWvFxEJq+Z278QSq8O80f4U59wjwCNxvF+zte/oQ3/Xli+T8XYiImkjnj39MqB3ncdFwLr4yvHMbJSZTa6srGzR69t3UuiLiMQST+gvAAaYWT8zawOMBmYmoijn3Czn3Lj8/PwWvb7dYbkA7Nq6JxHliIiERnOHbL4EvAMcY2ZlZnatc24fcBMwG1gBTHfOLW+9UpuvfX409Cv3prgSEZFgae7onTGNLH8deD2hFSVA+8PbALB7m0JfRKSuQE7DEHeffuc8AHZtr05kWSIiaS+QoR9vn75CX0QktkCGfrzaF7QDFPoiIg2FMvQ7dPGhv32z+vRFROoKZOjH26eff7iRzT42bUpwYSIiaS6QoR9vn35WFhTkVLJxazwXHIuIhE8gQz8RuuRtZ+OOvFSXISISKKEN/YL2u9m4q0OqyxARCZTQhn6Xw/awcU+nVJchIhIogQz9eE/kAnTvUs36SHfYuTOBlYmIpLdAhn68J3IBjuyTxWYK2PFBWQIrExFJb4EM/UToc6wfq7928cYUVyIiEhzhDf3/8EcJa5ZtT3ElIiLBEd7Q/1oXANas0pz6IiI1Qhv6hb1zyGEvaz+LdVdHEZHMFMjQT8TonexsKMqr4NMv2iewMhGR9BbI0E/E6B2A47psYNmWngmqSkQk/QUy9BPl+AG7WLH3KL7c0PIjBhGRMAl16A8Z2oZ95PL+G2tSXYqISCCEO/TP6gbAkv/dmtpCREQCItSh/5WSXnRgB+8ujqS6FBGRQAh16Ge3yebEwz7mXx93TXUpIiKBEMjQT8SQzRqnDfyCRTuPZWuFbp0oIhLI0E/UkE2Ab5+VTYRs/v7CZwmoTEQkvQUy9BPp66P70o5d/G3mjlSXIiKScqEP/byB/Tk179+8tbhzqksREUm50Ic+Znz7uM9Zvq03n693qa5GRCSlwh/6wLdH+rn133q+PMWViIikVkaE/pCr/gOAy+8oSnElIiKplRGhn31Uv/3fb9SNtEQkg2VE6ANMOWUKAN//XnWKKxERSZ1Ahn4iL86qMXZiHwBe+WM269cnbLMiImklkKGfyIuz9vvWt1jQ+0IAemqKfRHJUIEM/VaRlUXxz86nCH9l7oUXprgeEZEUyJzQB7jiClaeOAaAV1+FP/4xxfWIiCRZZoV+VhbtHvlv/skwAM4/H9bo/ioikkEyK/QBvvENhh29ef/Dvn2htDR15YiIJFPmhT7Aa6/hsP0PhwyBiO6zIiIZIDNDf8AAGDuWveTsX5SdncJ6RESSJDNDH2DKFHKoZh2F+xeZwe7dKaxJRKSVZW7oA5SVUcjnvMuQ/YvatwenyThFJKQyO/R79YJbb2UIpSygeP/irCy4+WbYsCGFtYmItILMDn2AX/0KRoygmEV8Ru0snI8+Ct27w/LlKaxNRCTBFPoAr78OQBHlRDoX1Htq0CDf1//227BtWyqKExFJnECGfmtMuHaQN4Qd/h66tmUzrms3fnLnl/VWKSmB/Hy/6kcfqd9fRNJTIEO/VSZcO5gOHWr7cioqmPhgW5yDLl0OXPXoo32//7BhUFkJmzbBvn3JK1VEpKUCGfopc9xx9S/PNaNig8M5uO22A1f/17/g8MP9B0NuLtxwA3TtCitWwLp1SataROrYswc+/jgx24pEYPv22sfO+a9Fi2DtWtiyBXbu9F2/L74ITz0F11wDTz4J06fD3/4G3/++7yHIyfH/Nvfriy8S04aGzAW4n6K4uNgtXLgw+W9cWuov063x5ZfQpg0A1dX+l3coHn7YnxTu1cv/Ii+9FDZvho4d929WRBr4/HP/9/HXv8KoUf5vr21b/+/vfw9nn+2/f+45OPVU+PRTuOee2sBv3x6+9z1Yv96vn27WrYPCwoOvF4uZLXLOFcd8TqHfiIoK6Nat9vGjj8JNN9VbxTl49lkYO7blb/P003DSSf77nBw/F1CbNr77qMbKlf58QvfuLX+fupyDrVuhc+fEbE+CYdYsOPNM2LvX750WFvo9xpo/8e3boVMn//yXX/q90z17YNcuv0c7eLD/fscOP3AhL88fxd5/vw/Y99/3ofrGG1BQ4G89+swzfnvz56e06aFwySWwapU/UujZEy66qOXbUui31O7dfnehrkjE/yU1Yt06v0ffGv79bygqgnnzYOZMeOEF+Mtf/B9eXh789rf+36oq+Pvf/X+g667zHyLbtsFbb/k/3sceg9tv9zOMdu4Mr70GY8bEfs/KSjjssAObvGaND4QOHRLbxo8/hq98JbHbrOv9932o1XzQttSGDb438PXX/c9wwIDa53bvhscf9+d5xo3zh/jnnus/1Hfvhn/+0x/ldeni63noIbjsMt9VOGsWDBwIRx3lf7YTJvjf6RFH+APQZI1tyBRHHgkXXOCPEsrKYPx4/7cycqT/mdcc1bdv3+SffeAo9OPV8Lf985/71Gym3bt9UJ91VoLrSrIePfwh96E4/HC/97l+vf8Z1Bg4EM47D6ZOhdNO82HW1P0NOnWq7Vvt3Rs+++xQq5egKSz0RxdHHw3/9V/w7rv+99y9Oxx7rP/Q7NBBXaAtodBPhHnzfMdhXf/4B5x8ctyb3rfP9/E/+KC/Vkwk0e6+2x+dDR/u92B79vT7MgUFvuswL89/STgo9BMp1jHe8uX+WD9Jan5ly5f77pD58/2ogY0bk1ZCRiks9H3gkQiccorvDjv5ZN8lU9OV17GjPwKprvaBunu3P8rJzfXdbTXdYOnURSDpS6GfaOXlvnO9od27/fACEZEUair0NU6/JXr18rvb06fXX96und+Ve+IJXbIrIoGk0I/Hd77jw/0f/6i//IYb/JjLJ5/049lERAJCoZ8IJ5/sw/8vf6m//Prr/dCDceP8hD179qSmPhGRKIV+Ip1xhg//hhPxP/WUH5eWlwcjRvh1PvjAnxsQEUkihX5r6NrVB/u+ffCb39R/bvZs3/UzcKA/Gbx1a0pKFJHMpNBvTdnZ/hZczjV+N5bOnf3J33nzdPJXRFqdQj9ZjjvOh3okAo88cuDzp57qjwDM/NW+1dXJr1FEQk+hn2xmfoIP53ywjxp14DoPP1w7D2uXLn4SnS1bkl+riIRO0kLfzAaa2RNmNsPMbkjW+wZaVpafOc05P7KnT58D19m0yc/mdcQRtZNsV1Ulv1YRCYVmhb6ZTTGzDWa2rMHyEWb2oZmtMrM7m9qGc26Fc+564BIg5pViGS0310/1V3OXhtdei71ejx61F4GZ+Wkef/hDWLo0qeWKSHpq1jQMZlYC7ACec84Nii7LBlYCZwJlwAJgDJANPNBgE991zm0ws3OBO4HHnHNTD/a+gZ2GIdkWLoShQw++Xrt2fvrJgoKDrysioRX3NAzOubnA5gaLTwJWOedWO+f2AC8D5znnljrnRjb42hDdzkzn3MnA5S1vTgYqLq49AohE4Be/iL3e7t3+HEDde6699NKB65WX+1FFurGvSMaJp0+/F1B3VvOy6LKYzOw0M3vEzJ4EXm9ivXFmttDMFlZUVMRRXkiZwQ9+UPshsHVr07fUuuyy+h8Cf/873HijvxPYX/+atLJFJBjiCf1Yk8Q22lfknPtf59zNzrnvO+cmNbHeZOdcsXOuuGvXrnGUlyHy8/2dTWqOAj76yO/tN+a00/zJY/C30Ro/3n8YrFyZlHJFJLXiCf0yoHedx0XAuvjKkbiY+fvsVVTUHgns2NH0TXwfe8z/e8wx9Y8IPvnEfxCoC0gkVOIJ/QXAADPrZ2ZtgNHAzEQUZWajzGxypW4IGr8OHWDKlNoPgZ07fX/+wfTv7z8IcnP9h8C0aX55VZU/ohCRtNTcIZsvAe8Ax5hZmZld65zbB9wEzAZWANOdc43MNXBonHOznHPj8vPzE7E5qat9ez8fUM2HQHW1vzv3wYwe7cO/XTs/vUTNuYU5c+rf/FZEAk13zpIDOQelpX5qiB07Du21jz0Gp5/uRwidcUbr1CciTdKds+TQmMGQIbB9e+0Rwd69fqhoUyOFAG66yc8zdOaZtecHunf38w198IE/0azuIZGUCeSevpmNAkYdddRR13300UepLkeasmqVnyaiJd55B44/vva+wpGIn3r67LN1B3GROOjG6JI8zsGsWXD55YfeNVTXG2/4cwdDh8LhhyesPJFMoO4dSR4zOPfc+l1DzsG2bfDgg83fztlnw1ln1d5voLDQ/3v//bX3Hfjzn/18RSLSbNrTl9RascL39z/xRHzbufdeOOccP/HcFVf4qalzcxNTo0iaSbvuHfXpZzjn/DDS3/7Wf8XjX//yHyznn++npX77bSgp8fcs3rHDn0/IyUlI2SJBkXahX0N7+nKATZtgxgy4/vr4ttO7t5+RFODVV+Hkk/3Na+67z9/AXiSNKfQl/Pbsgccfh2efhXffTcw2H30Uvv51f3Xynj3+KOE730nMtkVakU7kSvi1aQO33AKLF9c/gRyJwPr1fnbRQ73Ce/x4P3qooMCfSL7kktprD776Vf/vb34Da9f621lWV/uvu+/WkFMJLO3pS2bbt8/fpezxx/1ooES65ho/Aumpp2DyZD8ZXo1IpPYDRCTB0m5PXxOuSdLk5PiTvLNn1z9CcM5PLvfJJ35UUEs884y/n8GcOf4CtrqzmGZn+3mM5s6Ffv3g97/3H0Dr1yeydSIH0J6+SEtUV/vgXrTI34zmziZvEd1yZ50FF13kp8feuROmToVvftPfM6HhlBjl5b4bKiuQ+3KSRDqRK5IKW7b4cwnTp8e+bWUiXHpp7bTXACNH+jujvfeePyfRrp2fBfWUU9SVlEEU+iJB9OWX/lqB0lK44AJ/1XJrKiyE55+Hr33Nz3v0/PO+C6pNG/98aakfqdSpU+vWIa1OoS+Srqqr/RDURx/1F5mtXu2vVWhNbdvCQw/5E9sPP+w/HCZO9Be3FRToOoY0oNAXCbNIxF9DUFGR3OsIbr8dxozxRxCdOvkZVysq/Myp3br5axtqjiIkqdIu9DUNg0iC1YxGevpp+PxzP3Fdstxwgz/3MHOmH6F09dVw4om1o6Tqnnjets3f3U1TY8Ql7UK/hvb0RZIsEvHzHi1d6mcwvfvu5L33ddf5axoGDPA325k4EY44wk+cN3gwfOMbsV/35pv+xj1HHpm8WgNOoS8iiff++77/v7jYj1RKtlmzYPNmf+QA/oPCzF9sd+utvsvrlFOSX1cAKPRFJDW2bPFHD3/6k5/g7kc/Sk0d//mffuhqZaWfTuPuu/1UGgfrRiov99dEpNnJa4W+iATfvn1+z33BAj+ktKLCT1+RbMcf74evdujgL4gD3901aFDtOrt3+w+Rfftg+PDATamh0BeRcIlEYO9ePy12djZ897vx3Z4zXqNG+e6mK6/0dXXp4s9NnHMO9OrlT1bXHC2sWOE/3Bo7R5EACn0RyVzV1f5COICyMn+ntkmTUlsT+Hs63HuvH91UXQ2nnw4/+Yn/EDvmGP/B0UJpF/oasikiKRWJ+KksKir8BWqzZye/hjiyOe1Cv4b29EUkLZSX+zmWTjzRjx76xS/i3+YHH/g9/hZQ6IuIBEUk4k8Eb9rkjySefBI+/thPq71iRe16FRUt7uJpKvR12ZuISDJlZfmRQR06+AvKkjxCSRNvi4hkEIW+iEgGUeiLiGQQhb6ISAZR6IuIZJBAhr6ZjTKzyZWVlakuRUQkVAIZ+s65Wc65cfn5+akuRUQkVAIZ+iIi0joCfUWumVUAa1r48i7AxgSWkw7U5sygNodfvO3t45zrGuuJQId+PMxsYWOXIYeV2pwZ1Obwa832qntHRCSDKPRFRDJImEM/BfdZSzm1OTOozeHXau0NbZ++iIgcKMx7+iIi0oBCX0Qkg4Qu9M1shJl9aGarzOzOVNcTDzPrbWZzzGyFmS03s1uiy48ws7+Y2UfRfzvXec1d0bZ/aGbD6yz/mpktjT73iJlZKtrUHGaWbWbvmtlr0cehbi+AmR1uZjPM7IPo73tYmNttZrdF/08vM7OXzKxtGNtrZlPMbIOZLauzLGHtNLM8M5sWXT7fzPoetCjnXGi+gGzgY6A/0AYoBY5LdV1xtKcQODH6fSdgJXAc8BBwZ3T5ncB/R78/LtrmPKBf9GeRHX3u38AwwIA3gLNT3b4m2v1/gKnAa9HHoW5vtN5nge9Fv28DHB7WdgO9gE+AdtHH04FrwtheoAQ4EVhWZ1nC2gncCDwR/X40MO2gNaX6h5LgH/AwYHadx3cBd6W6rgS274/AmcCHQGF0WSHwYaz2ArOjP5NC4IM6y8cAT6a6PY20sQj4G3A6taEf2vZG6zssGoLWYHko2x0N/c+AI/C3bH0NOCvE7e3bIPQT1s6adaLf5+Cv4rWm6glb907Nf6YaZdFlaS962HYCMB/o7pxbDxD9t1t0tcba3yv6fcPlQfRr4IdApM6yMLcX/JFpBfC7aLfW/zOzDoS03c65cuAXwFpgPVDpnPszIW1vDIls5/7XOOf2AZVAQVNvHrbQj9Wfl/ZjUs2sI/AH4Fbn3LamVo2xzDWxPFDMbCSwwTm3qLkvibEsbdpbRw6+C+Bx59wJwE78YX9j0rrd0T7s8/BdGD2BDmZ2RVMvibEsbdp7CFrSzkP+GYQt9MuA3nUeFwHrUlRLQphZLj7wX3TOvRJd/IWZFUafLwQ2RJc31v6y6PcNlwfNN4BzzexT4GXgdDN7gfC2t0YZUOacmx99PAP/IRDWdp8BfOKcq3DO7QVeAU4mvO1tKJHt3P8aM8sB8oHNTb152EJ/ATDAzPqZWRv8iY2ZKa6pxaJn6J8GVjjnflnnqZnA1dHvr8b39dcsHx09o98PGAD8O3oIud3Mvh7d5lV1XhMYzrm7nHNFzrm++N/dW865Kwhpe2s45z4HPjOzY6KLvg28T3jbvRb4upm1j9b5bWAF4W1vQ4lsZ91tXYz/m2n6aCfVJzla4aTJOfhRLh8D96S6njjbcgr+UO09YEn06xx8n93fgI+i/x5R5zX3RNv+IXVGMgDFwLLoc49xkJM9qf4CTqP2RG4mtHcIsDD6u/4foHOY2w38X+CDaK3P40eshK69wEv48xZ78Xvl1yaynUBb4PfAKvwIn/4Hq0nTMIiIZJCwde+IiEgTFPoiIhlEoS8ikkEU+iIiGUShLyKSQRT6IiIZRKEvIpJB/j92nCu+8o2KdAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot Training Progree\n",
    "plt.plot(history.history['loss'], 'r', label='loss')\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(history.history['val_loss'], 'b', label='val_loss') if 'val_loss' in history.history else None\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/jiayu/Desktop/MLP_DataSet/TimeTrack_LargeSlope_Angle_17_26//ML_Models/NN_Model_InitialSet/assets\n"
     ]
    }
   ],
   "source": [
    "#Save Trained Model\n",
    "#MLmodel_name = \"NN_Model_Valid_\" + trainingset[\"PreProcessMode\"] + \"_Dagger_InitSet_2Iter\"\n",
    "#MLmodel_name = \"NN_Model\" + \"_\" + \"AugVarStep_1to2StepbeforeFail_3Time_RemovebyClip_SmallThre\"\n",
    "MLmodel_name = \"NN_Model\" + \"_\" + \"InitialSet\"\n",
    "model.save(ML_Model_Path + MLmodel_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save DataSet Setttings\n",
    "datasetSettings = {\"Shift_World_Frame_Type\":trainingset[\"Shift_World_Frame_Type\"],\n",
    "                   \"VectorScaleFactor\":trainingset[\"VectorScaleFactor\"],\n",
    "                   \"NumPreviewSteps\":trainingset[\"NumPreviewSteps\"],\n",
    "                   \"Contact_Representation_Type\":trainingset[\"Contact_Representation_Type\"],\n",
    "                   \"TrainingLoss\":history.history['loss']}\n",
    "#Validation loss\n",
    "datasetSettings[\"ValidationLoss\"] = history.history['val_loss'] if 'val_loss' in history.history else None\n",
    "\n",
    "#ProProcess\n",
    "datasetSettings[\"PreProcessMode\"] = trainingset[\"PreProcessMode\"]\n",
    "datasetSettings[\"Scaler_X\"] = trainingset[\"Scaler_X\"]\n",
    "datasetSettings[\"Scaler_Y\"] = trainingset[\"Scaler_Y\"]\n",
    "\n",
    "#Dump File\n",
    "pickle.dump(datasetSettings, open(ML_Model_Path + MLmodel_name+ '/datasetSettings' +'.p', \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.40423273e-01 -8.21607279e-02  7.11398565e-01  1.42372109e-01\n",
      "  1.18733061e-01  9.26208473e-03  2.22871997e-08  2.11933759e-09\n",
      "  4.97221639e-10 -3.16813388e-01 -1.86392841e-01 -7.48853929e-02\n",
      "  0.00000000e+00  4.22016385e-01  9.25549843e-01  1.05915277e-13\n",
      " -1.56806867e-01  9.25549843e-01  1.05859765e-13 -1.56806867e-01\n",
      " -7.44501568e-02  1.05859765e-13  4.22016385e-01 -7.44501568e-02\n",
      "  1.05915277e-13 -1.46720066e-01 -7.44501568e-02 -8.73243089e-02\n",
      " -7.30474417e-01 -7.44501568e-02 -4.46343828e-02 -7.30474417e-01\n",
      " -1.07445016e+00 -4.46343828e-02 -1.46720066e-01 -1.07445016e+00\n",
      " -8.73243089e-02  4.13354750e-01 -7.44501568e-02  7.49862435e-02\n",
      " -1.48145232e-01 -7.44501568e-02 -7.49862435e-02 -1.48145232e-01\n",
      " -1.07445016e+00 -7.49862435e-02  4.13354750e-01 -1.07445016e+00\n",
      "  7.49862435e-02  9.98490122e-01  9.25549843e-01  2.03404253e-02\n",
      "  4.27288121e-01  9.25549843e-01 -4.56389205e-02  4.09123398e-01\n",
      " -7.44501568e-02  1.11618266e-01  9.80325399e-01 -7.44501568e-02\n",
      "  1.77597612e-01  9.83506836e-01 -7.44501568e-02  1.50055004e-01\n",
      "  4.24106684e-01 -7.44501568e-02 -1.80963127e-02  4.24106684e-01\n",
      " -1.07445016e+00 -1.80963127e-02  9.83506836e-01 -1.07445016e+00\n",
      "  1.50055004e-01  1.57146541e+00  9.25549843e-01  7.09679225e-02\n",
      "  1.00026341e+00  9.25549843e-01  4.98857669e-03  9.78552112e-01\n",
      " -7.44501568e-02  1.92949461e-01  1.54975411e+00 -7.44501568e-02\n",
      "  2.58928807e-01]\n",
      "Data Kept Original Form, But need to scale back to meters\n",
      "predicted result: \n",
      " [[ 0.05972357 -0.09881868  0.74932784  0.14169486 -0.11084895  0.02577299\n",
      "   0.00285528 -0.00327418 -0.00420627  0.7611988   0.8887555   0.5051637\n",
      "   1.2145363   0.49869257]]\n",
      "true value: \n",
      " [ 7.54568390e-02 -9.44154233e-02  7.57723470e-01  1.57611297e-01\n",
      " -9.69769961e-02  2.95040008e-02 -6.58784032e-08 -1.66662077e-07\n",
      " -2.62211977e-08  7.75881409e-01  8.85915919e-01  4.99999987e-01\n",
      "  1.19999972e+00  4.99999979e-01]\n",
      "diff: \n",
      " [[0.01573327 0.00440326 0.00839563 0.01591644 0.01387195 0.00373101\n",
      "  0.00285535 0.00327402 0.00420625 0.01468259 0.00283958 0.00516374\n",
      "  0.01453659 0.00130741]]\n"
     ]
    }
   ],
   "source": [
    "#Show Prediction Result for Training\n",
    "from sklearn import preprocessing\n",
    "\n",
    "datapoint_num = 0\n",
    "y_pred_temp = model.predict(np.array([x_train[datapoint_num]]))\n",
    "\n",
    "print(x_train[datapoint_num])\n",
    "\n",
    "#Recover to original format\n",
    "if trainingset[\"PreProcessMode\"] == \"OriginalForm\":\n",
    "    print(\"Data Kept Original Form, But need to scale back to meters\")\n",
    "    y_pred_originalform = y_pred_temp/trainingset[\"VectorScaleFactor\"]\n",
    "    y_true_originalform = y_train[datapoint_num]/trainingset[\"VectorScaleFactor\"]\n",
    "elif trainingset[\"PreProcessMode\"] == \"Standarization\" or trainingset[\"PreProcessMode\"] == \"MaxAbs\":\n",
    "    y_pred_originalform = dataset[\"Scaler_Y\"].inverse_transform(y_pred_temp)\n",
    "    y_true_originalform = dataset[\"Scaler_Y\"].inverse_transform(np.array([y_train[datapoint_num]]))\n",
    "else:\n",
    "    raise Exception(\"Unknow Pre Process Mode\")\n",
    "\n",
    "\n",
    "print(\"predicted result: \\n\",y_pred_originalform)\n",
    "print(\"true value: \\n\",y_true_originalform)\n",
    "print(\"diff: \\n\", np.absolute(y_pred_originalform - y_true_originalform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Kept Original Form, But need to scale back to meters\n",
      "[0.00067656 0.00101201 0.00112928 ... 0.45006923 0.47856934 0.53938979]\n",
      "Error Mean:  0.03733334300899411\n",
      "Error Std 0.04330228678185821\n",
      "[0.24102132 0.24137335 0.24182331 0.24316393 0.24332637 0.24365182\n",
      " 0.24668106 0.24700251 0.24898679 0.25279794 0.25339893 0.25415384\n",
      " 0.25588098 0.25590281 0.25636081 0.25688869 0.25971265 0.26120646\n",
      " 0.26295693 0.26384636 0.26829131 0.26905188 0.27131759 0.27291363\n",
      " 0.27468513 0.27502441 0.27535585 0.27558434 0.27708511 0.27786392\n",
      " 0.27787672 0.27868898 0.27900402 0.2805483  0.2829845  0.2858935\n",
      " 0.2892192  0.29202585 0.29285031 0.29440779 0.29673732 0.29894487\n",
      " 0.29931701 0.29995029 0.30025065 0.30272978 0.30639164 0.31046129\n",
      " 0.31249759 0.31970695 0.32164882 0.32333746 0.32432776 0.32757561\n",
      " 0.32978586 0.33034119 0.33281027 0.33450736 0.33666167 0.33698496\n",
      " 0.33844771 0.3422011  0.3441785  0.34935293 0.35235847 0.3569117\n",
      " 0.35732643 0.35805905 0.36194364 0.36724471 0.36727558 0.36748831\n",
      " 0.36837684 0.37279413 0.37452849 0.3746287  0.37631192 0.37680954\n",
      " 0.37825413 0.38143109 0.38604429 0.39339912 0.39343071 0.39487368\n",
      " 0.39687642 0.39898734 0.40481255 0.40741578 0.40833553 0.41026465\n",
      " 0.41151847 0.41203712 0.41965931 0.42028473 0.42620919 0.42701208\n",
      " 0.44842462 0.45006923 0.47856934 0.53938979]\n",
      "[12 22  1  5 29 22 11 10 13 22 28 26 20 10 17  3 14  0  9  3 11  3  9 11\n",
      " 28 10 17 17 29 27 20 17 20 28 20 22 22 22 18 10 22 10 28 20 19 10 14 12\n",
      "  4 20  5 17 22 27  5 16 21 20  3  4  8 22 15 22 10  9 26 21 10 19 16 16\n",
      " 17 12 28  2 11  5 20 26 10 10 21  5 15 13 18 10 22 28 21 12 26  3 15 28\n",
      " 15 15 18 18]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  1.,  1.,  5.,  2.,  5.,  0.,  0.,  1.,  3., 11.,  4.,  4.,\n",
       "         2.,  2.,  5.,  3.,  6.,  4.,  2.,  8.,  4., 11.,  0.,  0.,  0.,\n",
       "         4.,  2.,  7.,  2.]),\n",
       " array([ 0.        ,  0.96666667,  1.93333333,  2.9       ,  3.86666667,\n",
       "         4.83333333,  5.8       ,  6.76666667,  7.73333333,  8.7       ,\n",
       "         9.66666667, 10.63333333, 11.6       , 12.56666667, 13.53333333,\n",
       "        14.5       , 15.46666667, 16.43333333, 17.4       , 18.36666667,\n",
       "        19.33333333, 20.3       , 21.26666667, 22.23333333, 23.2       ,\n",
       "        24.16666667, 25.13333333, 26.1       , 27.06666667, 28.03333333,\n",
       "        29.        ]),\n",
       " <BarContainer object of 30 artists>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Error Stat with Training Set\n",
    "import matplotlib.pyplot as plt\n",
    "y_pred_train = model.predict(x_train)\n",
    "\n",
    "if trainingset[\"PreProcessMode\"] == \"OriginalForm\":\n",
    "    print(\"Data Kept Original Form, But need to scale back to meters\")\n",
    "    y_pred_train_originalform = y_pred_train/trainingset[\"VectorScaleFactor\"]\n",
    "    y_true_train_originalform = y_train/trainingset[\"VectorScaleFactor\"]\n",
    "elif trainingset[\"PreProcessMode\"] == \"Standarization\" or trainingset[\"PreProcessMode\"] == \"MaxAbs\":\n",
    "    print(\"PreProcessing of: \", trainingset[\"PreProcessMode\"])\n",
    "    y_pred_train_originalform = trainingset[\"Scaler_Y\"].inverse_transform(y_pred_train)\n",
    "    y_true_train_originalform = trainingset[\"Scaler_Y\"].inverse_transform(y_train)\n",
    "else:\n",
    "    raise Exception(\"Unknow Pre Process Mode\")\n",
    "\n",
    "#Compute Error\n",
    "#err = np.linalg.norm(y_true_train_originalform[:,-3:]-y_pred_train_originalform[:,-3:], axis=1)\n",
    "err = np.linalg.norm(y_true_train_originalform[:,-3:]-y_pred_train_originalform[:,-3:], axis=1)\n",
    "\n",
    "#Plot Histogram\n",
    "fig=plt.figure();   ax = fig.gca()\n",
    "plt.hist(err, bins=50, density = True, range = (0.0, 0.375))\n",
    "ax.set_xlabel(\"Normalised Error\")\n",
    "ax.set_xlim([-0.025,0.375])\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "ax.set_ylim([-1,50])\n",
    "\n",
    "#### Sort the error\n",
    "\n",
    "err_sorted = np.sort(err)\n",
    "print(err_sorted[-12000:])  # print the 100 biggest error\n",
    "\n",
    "print(\"Error Mean: \", err_sorted.mean())\n",
    "print(\"Error Std\", err_sorted.std())\n",
    "\n",
    "##Plot prediction on the initial dataset\n",
    "err_initdata=err[0:12000+1]\n",
    "\n",
    "err_initdata_sorted = np.sort(err_initdata)\n",
    "print(err_initdata_sorted[-100:])  # print the 100 biggest error\n",
    "\n",
    "err_initdata_idx_sorted = np.argsort(err_initdata)\n",
    "print(err_initdata_idx_sorted[-100:]%30)\n",
    "selected_err=err_initdata_idx_sorted[-100:]%30\n",
    "fig=plt.figure();   ax = fig.gca()\n",
    "plt.hist(selected_err, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Kept Original Form, But need to scale back to meters\n",
      "[0.01072788 0.01221412 0.01239479 ... 1.55160101 1.81022735 2.47876817]\n",
      "Error Mean:  0.06999967026231561\n",
      "Error Std 0.07594938683781671\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEKCAYAAAAVaT4rAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAATxElEQVR4nO3dfbRldX3f8fcnAwaDIhAudCpOBgmN9QkMNyhikiqQhZp2MEuNiWknDassGyPaaCKtWY22ecC2MQnG2M5CdGwwCVkJAbURZ00EtaAy4CBQUJSApbCYQQefRR6+/ePsK5fhPuw7c/e5597f+7XWWWfvffbv7O/dDJ+zz2/v89upKiRJ7fiBlS5AkjReBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMOGPLNk9wOfAN4CHiwqqaTHA78JbARuB14ZVXtGbIOSdIjxnHE/8KqOqGqprv5c4HtVXUcsL2blySNyUp09WwCtnbTW4EzV6AGSWpWhvzlbpJ/APYABfyPqtqS5L6qOnTWOnuq6rA52p4NnA1w8MEHn/i0pz1tsDolaS269tpr762qqb2XD9rHD5xSVXclORLYluSWvg2raguwBWB6erp27NgxVI2StCYluWOu5YN29VTVXd3zLuAS4CTgniTru6LWA7uGrEGS9GiDBX+Sg5M8cWYa+BngRuAyYHO32mbg0qFqkCQ91pBdPUcBlySZ2c4HquojSa4BLk5yFvBl4BUD1iBJ2stgwV9VtwHHz7H8K8CpQ21XkrQwf7krSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTGDB3+SdUk+m+RD3fzhSbYlubV7PmzoGiRJjxjHEf/rgZtnzZ8LbK+q44Dt3bwkaUwGDf4kRwMvBS6YtXgTsLWb3gqcOWQNkqRHG/qI/4+A3wQenrXsqKq6G6B7PnKuhknOTrIjyY7du3cPXKYktWOw4E/ys8Cuqrp2X9pX1Zaqmq6q6ampqWWuTpLadcCA730K8C+SvAQ4CDgkyZ8B9yRZX1V3J1kP7BqwBknSXgY74q+qf19VR1fVRuBVwN9X1S8BlwGbu9U2A5cOVYMk6bFW4jr+84DTk9wKnN7NS5LGZMiunu+rqiuAK7rprwCnjmO7kqTH8pe7ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUmMGCP8lBST6T5PokNyV5W7f88CTbktzaPR82VA2SpMca8oj/fuBFVXU8cAJwRpLnAecC26vqOGB7Ny9JGpNewZ+RX0ryH7v5DUlOWqhNjXyzmz2wexSwCdjaLd8KnLkvhUuS9k3fI/4/BU4GfqGb/wbwrsUaJVmXZCewC9hWVZ8GjqqquwG65yOXWrQkad/1Df7nVtVrge8CVNUe4HGLNaqqh6rqBOBo4KQkz+xbWJKzk+xIsmP37t19m0mSFtE3+B9Iso5RVw1JpoCH+26kqu4DrgDOAO5Jsr57n/WMvg3M1WZLVU1X1fTU1FTfTUmSFtE3+M8HLgGOTPK7wCeB31uoQZKpJId2048HTgNuAS4DNnerbQYuXXrZkqR9dUCflarqoiTXAqcCAc6sqpsXabYe2Np9U/gB4OKq+lCSq4GLk5wFfBl4xb6XL0laql7Bn+RwRl0yfz5r2YFV9cB8barqc8Bz5lj+FUYfIJKkFdC3q+c6YDfwBeDWbvofklyX5MShipMkLb++wf8R4CVVdURV/TDwYuBi4FcZXeopSVol+gb/dFVdPjNTVR8FfqqqPgX84CCVSZIG0auPH/hqkjcDf9HN/zywpztx2/uyTknSyut7xP+LjH6E9beMLr/c0C1bB7xykMokSYPoeznnvcDr5nn5i8tXjiRpaH0v55wCfhN4BnDQzPKqetFAdUmSBtK3q+ciRr+6PQZ4G3A7cM1ANUmSBtQ3+H+4qt4DPFBVV1bVrwDPG7AuSdJA+l7VM/ML3buTvBS4i9HJXknSKtM3+H8nyZOANwLvBA4B3jBUUZKk4fQN/j1V9TXga8ALAZKcMlhVkqTB9O3jf2fPZZKkCbfgEX+Sk4HnA1NJfn3WS4cw+vGWJGmVWayr53HAE7r1njhr+deBlw9VlCRpOAsGf1VdCVyZ5H1VdceYapIkDajvyd0fTLIF2Di7jb/claTVp2/w/xXw34ELgIeGK0eSNLS+wf9gVb170EokSWPR93LODyb51STrkxw+8xi0MknSIPoe8W/unn9j1rICnrq85UiShtZ3PP5jhi5EkjQevbp6kvxQkt/qruwhyXFJfnbY0iRJQ+jbx/9e4HuMfsULcCfwO4NUJEkaVN/gP7aq/gvd8MxV9R0gg1UlSRpM3+D/XpLHMzqhS5JjgfsHq0qSNJi+V/X8NvAR4ClJLgJOAX55qKIkScPpe1XPtiTXMbrdYoDXV9W9g1YmSRpE36t6Xsbo17sfrqoPAQ8mOXPQyiRJg+jbx//b3R24AKiq+xh1/0iSVpm+wT/Xen3PD0iSJkjf4N+R5B1Jjk3y1CR/CFw7ZGGSpGH0Df7XMfoB118CFwPfAV47VFGSpOEs2l2TZB1waVWdNoZ6JEkDW/SIv6oeAr6d5ElLeeMkT0nysSQ3J7kpyeu75Ycn2Zbk1u75sH2sXZK0D/qeoP0ucEOSbcC3ZhZW1TkLtHkQeGNVXZfkicC1XftfBrZX1XlJzgXOBd68T9VLkpasb/B/uHv0VlV3A3d3099IcjPwZGAT8M+61bYCV2DwS9LY9P3l7tZurJ4NVfX5pW4kyUbgOcCngaO6DwWq6u4kR87T5mzgbIANGzYsdZOSpHn0/eXuPwd2MhqvhyQnJLmsZ9snAH8NvKGqvt63sKraUlXTVTU9NTXVt5kkaRF9u3reCpzEqFuGqtqZZNG7ciU5kFHoX1RVf9MtvifJ+u5ofz2wa8lVr3Ibz52/1+z28146xkoktajvdfwPzh6yoVMLNUgS4D3AzVX1jlkvXcYj9/DdDFzaswZJ0jLoe8R/Y5JfBNYlOQ44B7hqkTanAP+S0dVAO7tl/wE4D7g4yVnAl4FXLLlqSdI+6xv8rwPewujmKx8ALmeRWy9W1SeZ/y5dp/YtUJK0vBYM/iQHAa8BfhS4ATi5qh4cR2GSpGEsdsS/ldF9dj8BvBj4p8AbBq5pzVjoJK4krZTFgv/pVfUsgCTvAT4zfEmSpCEtdlXPAzMTdvFI0tqw2BH/8UlmfnQV4PHdfICqqkMGrU6StOwWDP6qWjeuQiRJ49H3B1ySpDXC4JekxnjD9Akz3yWgjuEjabl4xC9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjHI9/lXCcfknLxSN+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5Ia43X8y2C+a+wlaRJ5xC9JjRks+JNcmGRXkhtnLTs8ybYkt3bPhw21fUnS3Ibs6nkf8CfA+2ctOxfYXlXnJTm3m3/zgDWseQ7lIGmpBjvir6qPA1/da/EmYGs3vRU4c6jtS5LmNu4+/qOq6m6A7vnI+VZMcnaSHUl27N69e2wFStJaN7End6tqS1VNV9X01NTUSpcjSWvGuIP/niTrAbrnXWPeviQ1b9zBfxmwuZveDFw65u1LUvOGvJzzz4GrgR9LcmeSs4DzgNOT3Aqc3s1LksZosMs5q+oX5nnp1KG2KUla3MSe3JUkDcPgl6TGGPyS1BiDX5IaY/BLUmMcj3+NWugeAQ7gJrXNI35JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhrjdfwN8gbtUts84pekxhj8ktQYg1+SGmPwS1JjPLmr7/Okr9QGj/glqTEe8fe00DDHkrSaeMQvSY0x+CWpMXb1aFGe9JXWFo/4JakxBr8kNcauHu0zb+gurU4e8UtSYzzi1yA8ISxNLoNfY+UHgrTyDH5NBM8XSONj8Gvi+S1BWl4Gv1YtPxCkfbMiwZ/kDOCPgXXABVV13krUobVpOQfU80NEa9HYgz/JOuBdwOnAncA1SS6rqv8z7lqkxfghorVoJY74TwK+WFW3AST5C2ATYPBrTRvH0N7zfbis5LYX2r4fhitjJYL/ycD/nTV/J/DcFahjTo67r9VsJf/97su2/f9tZaxE8GeOZfWYlZKzgbMBNmzYMHRN3+cRiKS1Im+fe/lKDNlwJ/CUWfNHA3ftvVJVbamq6aqanpqaGltxkrTWrUTwXwMcl+SYJI8DXgVctgJ1SFKTxt7VU1UPJvk14HJGl3NeWFU3jbsOSWpVqh7TvT5xkuwG7ljmtz0CuHeZ33MI1rl8VkONYJ3LreU6f6SqHtNXviqCfwhJdlTV9ErXsRjrXD6roUawzuVmnY/lePyS1BiDX5Ia03Lwb1npAnqyzuWzGmoE61xu1rmXZvv4JalVLR/xS1KTDH5JasyaC/4kZyT5fJIvJjl3jteT5Pzu9c8l+fG+bSeoztuT3JBkZ5IdK1zn05JcneT+JG9aStsJqnOS9ueru//en0tyVZLj+7adoDrHsj971Lipq29nkh1JXtC37QTVOcy+rKo182D0S+AvAU8FHgdcDzx9r3VeAvwdo8Hingd8um/bSaize+124IgJ2Z9HAj8B/C7wpqW0nYQ6J3B/Ph84rJt+8QT/+5yzznHtz541PoFHzmM+G7hlQvflnHUOuS/X2hH/98f6r6rvATNj/c+2CXh/jXwKODTJ+p5tJ6HOcVq0zqraVVXXAA8ste2E1DlOfeq8qqr2dLOfYjSIYa+2E1LnuPSp8ZvVpSdwMI+MAjxp+3K+Ogez1oJ/rrH+n9xznT5tl8v+1AmjfxgfTXJtN3z1UPZnn0za/lzIpO7Psxh969uXtvtjf+qE8ezPXjUmeVmSW4APA7+ylLYTUCcMtC/X2s3W+4z1P986ve4TsEz2p06AU6rqriRHAtuS3FJVH1/WChevYci2S7W/25q4/ZnkhYwCdaa/dyL35xx1wnj2Z68aq+oS4JIkPwX8Z+C0vm2Xyf7UCQPty7V2xN9nrP/51ul1n4Blsj91UlUzz7uASxh9nVypOodou1T7ta1J259Jng1cAGyqqq8spe0E1Dmu/bmk/dGF5bFJjlhq2/20P3UOty+HOKGxUg9G32BuA47hkRMpz9hrnZfy6JOmn+nbdkLqPBh44qzpq4AzVqrOWeu+lUef3J2o/blAnRO1P4ENwBeB5+/r37jCdY5lf/as8Ud55KTpjwP/r/v/adL25Xx1DrYvl/0PXekHo6thvsDoTPpbumWvAV7TTQd4V/f6DcD0Qm0nrU5GVwdc3z1umoA6/xGjo5qvA/d104dM4P6cs84J3J8XAHuAnd1jx4T++5yzznHuzx41vrmrYSdwNfCCCd2Xc9Y55L50yAZJasxa6+OXJC3C4Jekxhj8ktQYg1+SGmPwS1JjDH5NrCSV5A9mzb8pyVvHXMMVSaa76f+V5ND9fL+NSW6cZ/l3ulEYZx7/an+2Jc1nrQ3ZoLXlfuDnkvx+Vd271MZJDqiqB5ermKp6yXK91zy+VFUnLLRCknVV9dB88/O0CaMfCD28PGVqtfOIX5PsQUb3If13e7+Q5EeSbO/GMd+eZEO3/H1J3pHkY8Dbu/l3J/lYktuS/HSSC5PcnOR9s97v3d1Y6DcledtcxXRjox+R5OAkH05yfZIbk/x89/qJSa7sBtS6fGY01W759UmuBl671J2Q5JtJ/lOSTwMnzzH/610dNyZ5Q9dmY/c3/ilwHY8eNkCNM/g16d4FvDrJk/Za/ieMhq1+NnARcP6s1/4JcFpVvbGbPwx4EaMPkA8Cfwg8A3hWkhO6dd5SVdOMxkP/6W4cmvmcAdxVVcdX1TOBjyQ5EHgn8PKqOhG4kNHY/wDvBc6pqpMX+VuP3aur5ye75QcDN1bVc6vqk7Pnge8A/xp4LqOhPf5Nkud07X6s20fPqao7Ftm2GmLwa6JV1deB9wPn7PXSycAHuun/yaNHh/yrvbo/Plijn6jfANxTVTd03R43ARu7dV6Z5Drgs4w+FJ6+QFk3AKcleXuSn6yqrzEK2WcyGkFxJ/BbwNHdB9ahVXXlrFrn86WqOmHW4xPd8oeAv5613uz5FwCXVNW3quqbwN8AMx8Yd9ToXg7So9jHr9Xgjxh1V7x3gXVmjz3yrb1eu797fnjW9Mz8AUmOAd4E/ERV7em6gA6ad0NVX0hyIqMxWH4/yUcZjZx4095H9d3J4P0dF+W7e32QzZ6fa9jfGXvvBwnwiF+rQFV9FbiY0bjvM64CXtVNvxr45H5s4hBGIfm1JEcxupXgvJL8Y+DbVfVnwH9jNKLi54GpJCd36xyY5BlVdV/3vjPfSF69H3XO5ePAmUl+KMnBwMuATyzSRo3ziF+rxR8AvzZr/hzgwiS/Aexm1M+9T6rq+iSfZdT1cxvwvxdp8izgvyZ5mNGtHP9tVX0vycuB87vunQMYfVO5qavtwiTfBi5f4H2P7bqJZlxYVefPt3JX+3XdN5TPdIsuqKrPJtm4yN+ghjk6pyQ1xq4eSWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5Ia8/8BDDEF6mhF0lwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Error Stat with Validation Set\n",
    "\n",
    "y_pred_valid = model.predict(x_valid)\n",
    "\n",
    "\n",
    "if validationset[\"PreProcessMode\"] == \"OriginalForm\":\n",
    "    print(\"Data Kept Original Form, But need to scale back to meters\")\n",
    "    y_pred_valid_originalform = y_pred_valid/validationset[\"VectorScaleFactor\"]\n",
    "    y_true_valid_originalform = y_valid/validationset[\"VectorScaleFactor\"]\n",
    "elif validationset[\"PreProcessMode\"] == \"Standarization\" or validationset[\"PreProcessMode\"] == \"MaxAbs\":\n",
    "    print(\"PreProcessing of: \", validationset[\"PreProcessMode\"])\n",
    "    y_pred_valid_originalform = validationset[\"Scaler_Y\"].inverse_transform(y_pred_valid)\n",
    "    y_true_valid_originalform = validationset[\"Scaler_Y\"].inverse_transform(y_valid)\n",
    "else:\n",
    "    raise Exception(\"Unknow Pre Process Mode\")\n",
    "\n",
    "#Compute Error\n",
    "err = np.linalg.norm(y_true_valid_originalform-y_pred_valid_originalform, axis=1)\n",
    "\n",
    "#Plot Histogram\n",
    "fig=plt.figure();   ax = fig.gca()\n",
    "plt.hist(err, bins=50, density = True, range = (0.0, 0.375))\n",
    "ax.set_xlabel(\"Normalised Error\")\n",
    "ax.set_xlim([-0.025,0.375])\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "ax.set_ylim([-1,50])\n",
    "\n",
    "#### Sort the error\n",
    "\n",
    "err_sorted = np.sort(err)\n",
    "print(err_sorted)  # print the 100 biggest error\n",
    "\n",
    "print(\"Error Mean: \", err_sorted.mean())\n",
    "print(\"Error Std\", err_sorted.std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Kept Original Form, But need to scale back to meters\n",
      "[0.01072788 0.01221412 0.01239479 ... 1.55160101 1.81022735 2.47876817]\n",
      "Error Mean:  0.06999967026231561\n",
      "Error Std 0.07594938683781671\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Error Stat with Test Set\n",
    "\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "if testset[\"PreProcessMode\"] == \"OriginalForm\":\n",
    "    print(\"Data Kept Original Form, But need to scale back to meters\")\n",
    "    y_pred_test_originalform = y_pred_test/testset[\"VectorScaleFactor\"]\n",
    "    y_true_test_originalform = y_test/testset[\"VectorScaleFactor\"]\n",
    "elif testset[\"PreProcessMode\"] == \"Standarization\" or testset[\"PreProcessMode\"] == \"MaxAbs\":\n",
    "    print(\"PreProcessing of: \", validationset[\"PreProcessMode\"])\n",
    "    y_pred_test_originalform = validationset[\"Scaler_Y\"].inverse_transform(y_pred_test)\n",
    "    y_true_test_originalform = validationset[\"Scaler_Y\"].inverse_transform(y_test)\n",
    "else:\n",
    "    raise Exception(\"Unknow Pre Process Mode\")\n",
    "\n",
    "#Compute Error\n",
    "err = np.linalg.norm(y_pred_test_originalform-y_true_test_originalform, axis=1)\n",
    "\n",
    "#Plot Histogram\n",
    "fig=plt.figure();   ax = fig.gca()\n",
    "plt.hist(err, bins=50, density = True, range = (0.0, 0.375))\n",
    "ax.set_xlabel(\"Normalised Error\")\n",
    "ax.set_xlim([-0.025,0.375])\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "ax.set_ylim([-1,50])\n",
    "\n",
    "#### Sort the error\n",
    "\n",
    "err_sorted = np.sort(err)\n",
    "print(err_sorted)  # print the 100 biggest error\n",
    "\n",
    "print(\"Error Mean: \", err_sorted.mean())\n",
    "print(\"Error Std\", err_sorted.std())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a501000252d127e7c27d83f75df0a57bca228f59033b739034a7cde4260d0152"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
